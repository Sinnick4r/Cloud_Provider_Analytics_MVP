{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dba1fa0ce6b94872b5feb657d55a6306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bbf9738e70648c992d54bc53635203e",
              "IPY_MODEL_7a74f98d7c7a4e0493eb4a279b9f9aae",
              "IPY_MODEL_d6ae08be5ae2452b9ca58a5edfca29a1"
            ],
            "layout": "IPY_MODEL_9456c27eefcc4f6aa7dfb35e9baa3adc"
          }
        },
        "6bbf9738e70648c992d54bc53635203e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47955ae520dc4514bcd358abf2f6c9b9",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd2f3c01fc647ac82d95755efe14cd4",
            "value": "Procesando Archivos: 100%"
          }
        },
        "7a74f98d7c7a4e0493eb4a279b9f9aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b44ca157094a2ea861a1d5e335052d",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_253a9936314f4fe48edba77eef2907b3",
            "value": 7
          }
        },
        "d6ae08be5ae2452b9ca58a5edfca29a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f724b5df5e0f4c62a5bc2e970d2571f0",
            "placeholder": "​",
            "style": "IPY_MODEL_4a16ca1605ab4d0fb67a3854d0e4bf77",
            "value": " 7/7 [00:17&lt;00:00,  1.53s/tablas]"
          }
        },
        "9456c27eefcc4f6aa7dfb35e9baa3adc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47955ae520dc4514bcd358abf2f6c9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd2f3c01fc647ac82d95755efe14cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96b44ca157094a2ea861a1d5e335052d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253a9936314f4fe48edba77eef2907b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f724b5df5e0f4c62a5bc2e970d2571f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a16ca1605ab4d0fb67a3854d0e4bf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10903c2371044d25804b401aa6cb6b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_925f118ca75b47ff81e370b235ddcfb6",
              "IPY_MODEL_3430ea27cbd34811acb052ed48d94a40",
              "IPY_MODEL_ae98d49192cb420cb3c29572dcaa0b20"
            ],
            "layout": "IPY_MODEL_d47da7ff849b4fd6b1aa073cc7a55de1"
          }
        },
        "925f118ca75b47ff81e370b235ddcfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ff39f3201b422a8e05977dc39a8fb6",
            "placeholder": "​",
            "style": "IPY_MODEL_fdcfd506f9424609abfc29f1ce011b26",
            "value": "Subiendo org_daily_usage_by_service: 100%"
          }
        },
        "3430ea27cbd34811acb052ed48d94a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1870fd8469bc4f4c8f45d705e2d18239",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e3ecb2be7254fbe84bacbe69ba8fe73",
            "value": 727
          }
        },
        "ae98d49192cb420cb3c29572dcaa0b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95d0b255c9c4893893cf8277e593752",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ba54ba546841b88f13500d1cbeff68",
            "value": " 727/727 [00:43&lt;00:00, 17.08rows/s]"
          }
        },
        "d47da7ff849b4fd6b1aa073cc7a55de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ff39f3201b422a8e05977dc39a8fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdcfd506f9424609abfc29f1ce011b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1870fd8469bc4f4c8f45d705e2d18239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3ecb2be7254fbe84bacbe69ba8fe73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f95d0b255c9c4893893cf8277e593752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ba54ba546841b88f13500d1cbeff68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5979a468e1b34e23b1acc074eb5f1796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf45724e343c43ea93abc95907dde768",
              "IPY_MODEL_33d637ccac444ab595cc5c1753d28515",
              "IPY_MODEL_2a26cd63eef14ab5b1c18e920ab5b66c"
            ],
            "layout": "IPY_MODEL_9d4b3990e5ad4f9a9809e367ee6cf16e"
          }
        },
        "bf45724e343c43ea93abc95907dde768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8cb8eabede405a9fc8b58866975489",
            "placeholder": "​",
            "style": "IPY_MODEL_8851bf2e774f42da8a5b29f81c845421",
            "value": "Subiendo org_daily_support_metrics: 100%"
          }
        },
        "33d637ccac444ab595cc5c1753d28515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f30cfbcde94980a314fe719b85a91b",
            "max": 944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae070afceed24589a822fe9e8bfad8c3",
            "value": 944
          }
        },
        "2a26cd63eef14ab5b1c18e920ab5b66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8261d50c577a41f5849fd1a1d8dcef92",
            "placeholder": "​",
            "style": "IPY_MODEL_a49e443bc57a4814a7ff8f549274e847",
            "value": " 944/944 [00:55&lt;00:00, 17.04rows/s]"
          }
        },
        "9d4b3990e5ad4f9a9809e367ee6cf16e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8cb8eabede405a9fc8b58866975489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8851bf2e774f42da8a5b29f81c845421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3f30cfbcde94980a314fe719b85a91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae070afceed24589a822fe9e8bfad8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8261d50c577a41f5849fd1a1d8dcef92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49e443bc57a4814a7ff8f549274e847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd1abff492f8410fa5ec5e332b8f9687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e235b6ab225449f092ce23bceab4935c",
              "IPY_MODEL_793d04c5a53a4e17a36adfbf131235ff",
              "IPY_MODEL_5e651c839caa455db7075feae03ae999"
            ],
            "layout": "IPY_MODEL_c12de88866d64b8da11a886cdaa61a80"
          }
        },
        "e235b6ab225449f092ce23bceab4935c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7af572ae32f40b0aaf32cd3375cde0c",
            "placeholder": "​",
            "style": "IPY_MODEL_0c027d96a3914838b4229cf86f841b5d",
            "value": "Subiendo org_daily_genai_usage: 100%"
          }
        },
        "793d04c5a53a4e17a36adfbf131235ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8666b7ea4b384f88bf4c2dec8560ed02",
            "max": 77,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c80a8fd49ba42ab9b8fe2e386a931c4",
            "value": 77
          }
        },
        "5e651c839caa455db7075feae03ae999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f72e13ad49405094651e2bf525ce81",
            "placeholder": "​",
            "style": "IPY_MODEL_6fab7253367d4e0ba51c7617d50ad158",
            "value": " 77/77 [00:04&lt;00:00, 17.03rows/s]"
          }
        },
        "c12de88866d64b8da11a886cdaa61a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7af572ae32f40b0aaf32cd3375cde0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c027d96a3914838b4229cf86f841b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8666b7ea4b384f88bf4c2dec8560ed02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c80a8fd49ba42ab9b8fe2e386a931c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38f72e13ad49405094651e2bf525ce81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fab7253367d4e0ba51c7617d50ad158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **2do parcial - MVP TECNICO**\n",
        "\n",
        "# Materia: Mineria de datos II\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Pipelines\n",
        "\n",
        "**(1) Batch**\n",
        "\n",
        "Landing ----batch---->Bronze (csv)--->Silver---> Gold ---> Serving (cassandra)\n",
        "\n",
        "**(2) Stream**\n",
        "\n",
        "Landing ----speed----> Bronze (jsonl)--->Silver --> gold (stream) --->Serving (Cassandra)\n",
        "\n",
        "**(3) Queries de cassandra**\n",
        "---\n",
        "\n",
        "Resumen de la implementación\n",
        "\n",
        "*Cada celda (con excepcion de los demos) corresponde a un archivo .py que eventualmente va a estar en el repo final al moment ode la entrega final.\n",
        "\n",
        "Por eso, se usaron parches como:\n",
        "\n",
        "\n",
        "```\n",
        "try:\n",
        "    from cassandra_utils import get_cassandra_session, KEYSPACE\n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "```\n",
        "En el archivo .py solo va a estar la llamada a cassandra_utils, pero como en el colab no es necesario, epuse ese parchecito temporal solo al efecto de la dentrega de este MVP.\n",
        "\n",
        "\n",
        "Este notebook contiene un end-to-end que incluye:\n",
        "\n",
        "    *implementacion de left anti joins para manejo de cuarentena (evitando duplicidad de errores) y estrategias de escritura segura.\n",
        "\n",
        "    *reglas de de negocio activas (costos negativos, integridad referencial) y desvío automático a zona de Quarantine.\n",
        "\n",
        "    *ptimizaciones Spark: Configuracion de shuffle.partitions para entorno local/Colab y uso de broadcast joins.\n",
        "\n",
        "    -*streaming con watermarking, dedupe y checkpointing para tolerancia a fallos.\n",
        "\n",
        "    *serving Layer: conexin a AstraDB (Cassandra) con modelado Query-First.\n",
        "\n",
        "\n",
        "Laburo completo aca ----->[Repositorio GitHub (Código + Readme + Diagramas) ](https://github.com/Sinnick4r/Cloud_Provider_Analytics_MVP)\n",
        "\n"
      ],
      "metadata": {
        "id": "X0ApXM5Cdb7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFIG.PY\n",
        "\n",
        "Funciones respecto a archivos y directorios\n"
      ],
      "metadata": {
        "id": "QhvkQcDIUZHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#por si no estan insalados en la ejecucion de colab, voy a lo seguro\n",
        "!pip install cassandra-driver\n",
        "!pip install astrapy\n",
        "!pip install Plotly\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "xoFQX0L9WjOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cUEIwMsZ5wJ8"
      },
      "outputs": [],
      "source": [
        "# config.py\n",
        "from __future__ import annotations\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from typing import Final\n",
        "from datetime import datetime\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "\n",
        "# integracion con google drive que estuve usando, se puede poner true o false\n",
        "\n",
        "USE_GOOGLE_DRIVE: Final[bool] = False\n",
        "GOOGLE_DRIVE_PROJECT_SUBDIR: Final[str] = \"Mineria de datos II/Proyecto Cloud Provider Analysis\"\n",
        "\n",
        "\n",
        "\n",
        "def get_project_root() -> Path:\n",
        "    \"\"\"\n",
        "    Devuelve la raíz del proyecto.\n",
        "    - so USE_GOOGLE_DRIVE es true, monta gdrive en Colab y usa la carpeta indicada.\n",
        "    - si es Ffalse, usa el directorio actual (repo descomprimido).\n",
        "    \"\"\"\n",
        "    if USE_GOOGLE_DRIVE:\n",
        "        try:\n",
        "            from google.colab import drive as gdrive\n",
        "        except ImportError as exc:\n",
        "            raise RuntimeError(\n",
        "                \"USE_GOOGLE_DRIVE=True pero no esamos en colab.\"\n",
        "            ) from exc\n",
        "\n",
        "        gdrive.mount(\"/content/drive\")\n",
        "        return (Path(\"/content/drive/MyDrive\") / GOOGLE_DRIVE_PROJECT_SUBDIR).resolve()\n",
        "\n",
        "    return Path(\".\").resolve()\n",
        "\n",
        "#aca van loss directorios de todo el proyecto\n",
        "\n",
        "PROJECT_ROOT: Final[Path] = get_project_root()\n",
        "DATA_DIR: Final[Path] = PROJECT_ROOT / \"data\"\n",
        "DATALAKE_ROOT: Final[Path] = PROJECT_ROOT / \"datalake\"\n",
        "\n",
        "LANDING_PATH: Final[Path] = DATALAKE_ROOT / \"landing\"\n",
        "BRONZE_PATH: Final[Path] = DATALAKE_ROOT / \"bronze\"\n",
        "SILVER_PATH: Final[Path] = DATALAKE_ROOT / \"silver\"\n",
        "GOLD_PATH: Final[Path] = DATALAKE_ROOT / \"gold\"\n",
        "QUARANTINE_PATH: Final[Path] = DATALAKE_ROOT / \"quarantine\"\n",
        "\n",
        "RAW_ZIP_NAME: Final[str] = \"cloud_provider_challenge_dataset_v1.zip\"\n",
        "\n",
        "\n",
        "# sesion de spark\n",
        "\n",
        "def create_spark(app_name: str = \"CloudProviderAnalytics_Pipeline\") -> SparkSession:\n",
        "    spark = (\n",
        "        SparkSession.builder\n",
        "        .appName(app_name)\n",
        "        .master(\"local[*]\")\n",
        "        .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
        "        .getOrCreate()\n",
        "    )\n",
        "    spark.sparkContext.setLogLevel(\"WARN\")\n",
        "    return spark\n",
        "\n",
        "\n",
        "# utils de archivos/directorios\n",
        "\n",
        "def ensure_dirs() -> None:\n",
        "# Crea la estructura del datalake si no existe.\n",
        "    for path in (LANDING_PATH, BRONZE_PATH, SILVER_PATH, GOLD_PATH, QUARANTINE_PATH):\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def unpack_raw_dataset() -> None:\n",
        "\n",
        "    #descomprime el zip del datalake\n",
        "    zip_path = DATA_DIR / RAW_ZIP_NAME\n",
        "\n",
        "    if not zip_path.exists():\n",
        "        print(f\"[WARN] No se encontró el ZIP de datos en {zip_path}. Saltando unpack.\")\n",
        "        return\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "        zf.extractall(PROJECT_ROOT)\n",
        "    print(f\"[OK] Dataset descomprimido en {PROJECT_ROOT / 'datalake' / 'landing'}\")\n",
        "\n",
        "\n",
        "'''\n",
        "esta funcion log la hice para otro proyecto hace mucho, la uso aca solo para que\n",
        "el resultado de la consola sea visualmente mas agradable en el ideo de presentacion\n",
        "'''\n",
        "def log(msg: str, level: str = \"INFO\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\", # Azul\n",
        "        \"WARN\": \"\\033[93m\", # Amarillo\n",
        "        \"ERR\":  \"\\033[91m\", # Rojo\n",
        "        \"OK\":   \"\\033[92m\", # Verde\n",
        "        \"RUN\":   \"\\033[96m\", # Cyan\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    color = colors.get(level, colors[\"RESET\"])\n",
        "    print(f\"{color}[{timestamp}] [{level}] {msg}{colors['RESET']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# schemas.py\n",
        "\n",
        "Schemas estaticos para spark"
      ],
      "metadata": {
        "id": "x4RBex6bUnvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# schemas.py\n",
        "\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Final\n",
        "from pyspark.sql import types as T\n",
        "\n",
        "\n",
        "# Esquemascsv y json totalmente manuales despeus de chequearlos\n",
        "\n",
        "customers_orgs_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_name\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"industry\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"hq_region\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"plan_tier\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"is_enterprise\", T.BooleanType(), nullable=True),\n",
        "    T.StructField(\"signup_date\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"sales_rep\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"lifecycle_stage\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"marketing_source\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"nps_score\", T.DoubleType(), nullable=True),\n",
        "])\n",
        "\n",
        "users_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"user_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"email\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"role\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"active\", T.BooleanType(), nullable=True),\n",
        "    T.StructField(\"created_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"last_login\", T.DateType(), nullable=True),\n",
        "])\n",
        "\n",
        "resources_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"resource_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"service\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"region\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"created_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"state\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"tags_json\", T.StringType(), nullable=True),\n",
        "])\n",
        "\n",
        "support_tickets_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"ticket_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"category\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"severity\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"created_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"resolved_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"csat\", T.DoubleType(), nullable=True),\n",
        "    T.StructField(\"sla_breached\", T.BooleanType(), nullable=True),\n",
        "])\n",
        "\n",
        "marketing_touches_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"touch_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"campaign\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"channel\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"timestamp\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"clicked\", T.BooleanType(), nullable=True),\n",
        "    T.StructField(\"converted\", T.BooleanType(), nullable=True),\n",
        "])\n",
        "\n",
        "nps_surveys_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"survey_date\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"nps_score\", T.DoubleType(), nullable=True),\n",
        "    T.StructField(\"comment\", T.StringType(), nullable=True),\n",
        "])\n",
        "\n",
        "billing_monthly_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"invoice_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"month\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"subtotal\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"credits\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"taxes\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"currency\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"exchange_rate_to_usd\", T.DoubleType(), nullable=True),\n",
        "])\n",
        "\n",
        "\n",
        "usage_events_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"event_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"timestamp\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"resource_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"service\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"region\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"metric\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"value\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"unit\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"cost_usd_increment\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"schema_version\", T.IntegerType(), nullable=True),\n",
        "    T.StructField(\"carbon_kg\", T.DoubleType(), nullable=True),\n",
        "])\n"
      ],
      "metadata": {
        "id": "123EkT026xiE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# io_utils.py\n",
        "\n",
        "Funciones de lecto-escritura de CSV y Parquet"
      ],
      "metadata": {
        "id": "gxijlygHUw6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# io_utils.py\n",
        "\n",
        "from __future__ import annotations\n",
        "from pathlib import Path\n",
        "from typing import Final\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import types as T\n",
        "\n",
        "\n",
        "# helpers de rutas genéricos\n",
        "\n",
        "def zone_path(zone_root: Path, table_name: str) -> Path:\n",
        "    \"\"\"\n",
        "    Devuelve la ruta completa a una tabla dentro de una zona del datalake.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return (zone_root / table_name).resolve()\n",
        "\n",
        "\n",
        "def add_audit_columns(df: DataFrame) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Enriquece un DataFrame con columnas técnicas de auditoría:\n",
        "    - ingest_ts: Timestamp de ingestión\n",
        "    - source_file: Nombre del archivo origen\n",
        "    \"\"\"\n",
        "    return df.withColumn(\"ingest_ts\", F.current_timestamp()) \\\n",
        "             .withColumn(\"source_file\", F.input_file_name())\n",
        "\n",
        "\n",
        "def read_csv(\n",
        "    spark: SparkSession,\n",
        "    path: Path,\n",
        "    schema: T.StructType,\n",
        "    header: bool = True,\n",
        ") -> DataFrame:\n",
        "\n",
        "    return (\n",
        "        spark.read\n",
        "        .option(\"header\", str(header).lower())\n",
        "        .schema(schema)\n",
        "        .csv(str(path))\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def write_parquet(\n",
        "    df: DataFrame,\n",
        "    base_path: Path,\n",
        "    partition_cols: list[str] | None = None,\n",
        "    mode: str = \"overwrite\",\n",
        ") -> None:\n",
        "\n",
        "    writer = df.write.mode(mode)\n",
        "    if partition_cols:\n",
        "        writer = writer.partitionBy(*partition_cols)\n",
        "    writer.parquet(str(base_path))\n",
        "\n",
        "\n",
        "def read_parquet(spark, base_path, partition_glob: str | None = None):\n",
        "\n",
        "    #lee un Parquet\n",
        "    #si no hay partition_glob lee la ruta / si hay artition_glob usa basePath y patron\n",
        "\n",
        "    base_path = Path(base_path)\n",
        "    base_str = str(base_path)\n",
        "\n",
        "    if partition_glob:\n",
        "        return (\n",
        "            spark.read\n",
        "                 .option(\"basePath\", base_str)\n",
        "                 .parquet(f\"{base_str}/{partition_glob}\")\n",
        "        )\n",
        "\n",
        "    return spark.read.parquet(base_str)\n"
      ],
      "metadata": {
        "id": "bAWzeQUf8ho2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# audit.py\n",
        "\n",
        "Funciones de chequeo de Quality de cada fase"
      ],
      "metadata": {
        "id": "AoA1xFZ9U7Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# audit.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "# Esto solo esta en el colab, en el codigo definitivo solo se importa\n",
        "try:\n",
        "    from config import BRONZE_PATH, SILVER_PATH, GOLD_PATH, QUARANTINE_PATH\n",
        "    from io_utils import read_parquet, zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    BRONZE_PATH = _m.BRONZE_PATH\n",
        "    SILVER_PATH = _m.SILVER_PATH\n",
        "    GOLD_PATH = _m.GOLD_PATH\n",
        "    QUARANTINE_PATH = _m.QUARANTINE_PATH\n",
        "    read_parquet = _m.read_parquet\n",
        "    zone_path = _m.zone_path\n",
        "\n",
        "\n",
        "def audit_bronze_layer(spark: SparkSession, table_name: str, pk_col: str) -> None:\n",
        "\n",
        "    # se chequea vol, uni de PK y el llenado con ingest_ts\n",
        "\n",
        "    print(f\"\\n chequeo Bronze: {table_name}\")\n",
        "\n",
        "    path = zone_path(BRONZE_PATH, table_name)\n",
        "    try:\n",
        "        df = read_parquet(spark, path)\n",
        "    except AnalysisException:\n",
        "        print(f\"[ERR] no se encontro la tabla en {path}\")\n",
        "        return\n",
        "\n",
        "    # Vol\n",
        "    count_total = df.count()\n",
        "\n",
        "    # Uni\n",
        "    count_distinct = df.select(pk_col).distinct().count()\n",
        "    duplicates = count_total - count_distinct\n",
        "\n",
        "    # ingest_ts\n",
        "    if \"ingest_ts\" in df.columns:\n",
        "        null_tech = df.filter(F.col(\"ingest_ts\").isNull()).count()\n",
        "    else:\n",
        "        null_tech = \"falta columna ingest_ts\"\n",
        "\n",
        "    print(f\"registros totales: {count_total}\")\n",
        "    print(f\"duplicados en PK ({pk_col}): {duplicates}\")\n",
        "    print(f\"nulos en ingest_ts: {null_tech}\")\n",
        "\n",
        "    # Resulktado\n",
        "    if duplicates == 0 and (isinstance(null_tech, int) and null_tech == 0):\n",
        "        print(\"Resultado: todo ok!!\")\n",
        "    else:\n",
        "        print(\"Resultado: revisar data por posibles duplicados \")\n",
        "\n",
        "\n",
        "def audit_silver_quality(spark: SparkSession) -> None:\n",
        "\n",
        "    #Chequea el resultado del proceso Silver Batch, calculando un ratio entre registros en Silver vs Cuarentena\n",
        "    print(f\"\\n Chequeop Silver:\")\n",
        "\n",
        "    path_good = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    path_bad  = zone_path(QUARANTINE_PATH, \"usage_events_quarantine\")\n",
        "\n",
        "    # contar buenos\n",
        "    try:\n",
        "        good_df = read_parquet(spark, path_good)\n",
        "        count_good = good_df.count()\n",
        "    except AnalysisException:\n",
        "        count_good = 0\n",
        "\n",
        "    # contar malos\n",
        "    try:\n",
        "        bad_df = read_parquet(spark, path_bad)\n",
        "        count_bad = bad_df.count()\n",
        "        has_bad = True\n",
        "    except AnalysisException:\n",
        "        count_bad = 0\n",
        "        has_bad = False\n",
        "\n",
        "    total = count_good + count_bad\n",
        "    if total == 0:\n",
        "        print(\"[WARN] No hay datos procesados en Silver ni cuarentena.\")\n",
        "        return\n",
        "\n",
        "    bad_ratio = (count_bad / total) * 100\n",
        "\n",
        "    print(f\"Total: {total}\")\n",
        "    print(f\"Aceptados (Silver): {count_good}\")\n",
        "    print(f\"Rechazados (cuarentena): {count_bad} ({bad_ratio:.2f}%)\")\n",
        "\n",
        "    if bad_ratio == 0:\n",
        "        print(\"CALIDAD: PERFECTA\")\n",
        "    elif bad_ratio < 5:\n",
        "        print(\"CALIDAD: ACEPTABLE\")\n",
        "    else:\n",
        "        print(\"CALIDAD: CRÍTICA (>5% Rechazo). Revisar reglas de negocio.\")\n",
        "\n",
        "    if has_bad:\n",
        "        print(\"ejemplo de rechazo:\")\n",
        "        bad_df.select(\"event_id\", \"quarantine_reason\").show(1, truncate=False)\n",
        "\n",
        "\n",
        "def audit_gold_layer(spark: SparkSession, table_name: str, check_col: str = \"daily_cost_usd\") -> None:\n",
        "\n",
        "    #Audita un Mart Gold verificando reglas de negocio para serving layer: Vol, Integridad y KPIs\n",
        "    print(f\"\\n Chequeo Gold: {table_name}\")\n",
        "\n",
        "    path = zone_path(GOLD_PATH, table_name)\n",
        "    try:\n",
        "        # Intentamos leer con wildcards para atrapar cualquier partición (event_date, ticket_date, etc.)\n",
        "        # El truco es usar recursiveFileLookup o simplemente leer la carpeta raíz\n",
        "        df = spark.read.option(\"basePath\", str(path)).parquet(str(path / \"*\"))\n",
        "    except AnalysisException:\n",
        "        try:\n",
        "            # Fallback: leer la raíz directa (a veces funciona mejor en local)\n",
        "            df = spark.read.parquet(str(path))\n",
        "        except AnalysisException:\n",
        "            print(f\"   [ERR] No se encontró el mart en {path}\")\n",
        "            return\n",
        "\n",
        "    count_total = df.count()\n",
        "\n",
        "    # Regla: Costos Negativos\n",
        "    neg_costs = df.filter(F.col(check_col) < 0).count()\n",
        "\n",
        "    print(f\"registros Totales (Agregados): {count_total}\")\n",
        "    print(f\"Costos Negativos detectados: {neg_costs}\")\n",
        "\n",
        "def audit_quarantine(spark: SparkSession):\n",
        "    print(f\"\\nCalidad de Datos (Silver Batch)\")\n",
        "\n",
        "    path_good = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    path_bad  = zone_path(QUARANTINE_PATH, \"usage_events_quarantine\")\n",
        "\n",
        "    # conteo de datos buenos\n",
        "    try:\n",
        "        good_df = read_parquet(spark, path_good)\n",
        "        count_good = good_df.count()\n",
        "    except AnalysisException:\n",
        "        count_good = 0\n",
        "        print(\"[WARN] No hay data en Silver.\")\n",
        "\n",
        "    # conteo  malos\n",
        "    try:\n",
        "        bad_df = read_parquet(spark, path_bad)\n",
        "        count_bad = bad_df.count()\n",
        "        has_bad_data = True\n",
        "    except AnalysisException:\n",
        "        count_bad = 0\n",
        "        has_bad_data = False\n",
        "        print(\"[INFO] No hay data en cuarentena\")\n",
        "\n",
        "    # ratio\n",
        "    total = count_good + count_bad\n",
        "    if total == 0:\n",
        "        print(\"[ERR] No hay data procesada\")\n",
        "        return\n",
        "\n",
        "    bad_ratio = (count_bad / total) * 100\n",
        "\n",
        "    print(f\"\\n Estadisticas:\")\n",
        "    print(f\"Total Procesado: {total}\")\n",
        "    print(f\"Aceptados (Silver): {count_good} ({(100 - bad_ratio):.2f}%)\")\n",
        "    print(f\"Rechazados (Quarantine): {count_bad} ({bad_ratio:.2f}%)\")\n",
        "\n",
        "    print(\"\\nresultado:\")\n",
        "\n",
        "    if bad_ratio == 0:\n",
        "        print(\"Satifactorio - sin datos rechazados\")\n",
        "    elif bad_ratio < 5:\n",
        "        print(\"Aceptable- rechazo  bajo y esperado.\")\n",
        "    else:\n",
        "        print(\"malo -demasiada data rechazada (>5%)\")\n",
        "\n",
        "    # muestra errores\n",
        "    if has_bad_data:\n",
        "        print(\"\\n Muestra de registros en Cuarentena (top 5):\")\n",
        "        cols_to_show = [\"event_id\", \"cost_usd_increment\", \"org_id\", \"quarantine_reason\"]\n",
        "        actual_cols = [c for c in cols_to_show if c in bad_df.columns]\n",
        "        bad_df.select(*actual_cols).show(5, truncate=False)\n",
        "\n",
        "\n",
        "def audit_speed_layer_results(spark: SparkSession):\n",
        "\n",
        "    #aca se chequea que la Speed Layer haya persistido datos en disco.\n",
        "    #Se ejecuta despues de parar el stream.\n",
        "\n",
        "    print(f\"\\n cheque de Speed Layer ---\")\n",
        "    path = zone_path(GOLD_PATH, \"org_daily_usage_by_service_speed\")\n",
        "\n",
        "    try:\n",
        "        df = read_parquet(spark, path, partition_glob=\"*\")\n",
        "        total_rows = df.count()\n",
        "\n",
        "        print(f\"Ruta: {path}, Total acumulado en disco: {total_rows}\")\n",
        "\n",
        "        if total_rows > 0:\n",
        "          print(\"funcionando todo OK (Datos persistidos correctamente)\")\n",
        "          df.show(3, truncate=False)\n",
        "        else:\n",
        "          print(\"vacio - dejar el stream corriendo mas tiempo\")\n",
        "    except Exception as e:\n",
        "       print(f\"[ERR] No se pudo leer la Speed Layer: {e}\")\n",
        "\n",
        "def run_full_bronze_audit(spark: SparkSession):\n",
        "    log(\"Iniciando Auditoría completa de capa Bronze...\", \"RUN\")\n",
        "\n",
        "    # Mapa de Tabla -> Columna Clave (PK) para chequear unicidad\n",
        "    # Basado en tus schemas.py\n",
        "    tables_to_audit = [\n",
        "        (\"customers_orgs\", \"org_id\"),\n",
        "        (\"users\", \"user_id\"),\n",
        "        (\"resources\", \"resource_id\"),\n",
        "        (\"support_tickets\", \"ticket_id\"),\n",
        "        (\"marketing_touches\", \"touch_id\"),\n",
        "        (\"billing_monthly\", \"invoice_id\"),\n",
        "        # Nota: nps_surveys puede tener varias encuestas por org,\n",
        "        # así que 'org_id' podría dar duplicados (lo cual es correcto funcionalmente)\n",
        "        (\"nps_surveys\", \"org_id\")\n",
        "    ]\n",
        "\n",
        "    for table_name, pk in tables_to_audit:\n",
        "        # Llamamos a tu función de audit.py\n",
        "        audit_bronze_layer(spark, table_name, pk_col=pk)\n",
        "\n",
        "    log(\"Auditoría Bronze finalizada.\", \"OK\")\n",
        "\n",
        "def run_full_silver_audit(spark: SparkSession):\n",
        "    log(\"Iniciando Auditoría de Calidad Silver...\", \"RUN\")\n",
        "\n",
        "    # 1. Auditoría de Calidad (Ratio Quarantine)\n",
        "    audit_silver_quality(spark)\n",
        "\n",
        "    # 2. Auditoría de la tabla de Cuarentena (Muestreo)\n",
        "    audit_quarantine(spark)\n",
        "\n",
        "    log(\"Auditoría Silver finalizada.\", \"OK\")\n",
        "\n",
        "def run_full_gold_audit(spark: SparkSession):\n",
        "    log(\"Iniciando Auditoría de Marts Gold...\", \"RUN\")\n",
        "\n",
        "    # Lista de tuplas: (Nombre Tabla, Columna a validar)\n",
        "    marts_to_audit = [\n",
        "        (\"org_daily_usage_by_service\", \"daily_cost_usd\"),   # FinOps\n",
        "        (\"org_daily_support_metrics\",  \"total_tickets\"),    # Soporte (No queremos tickets negativos)\n",
        "        (\"org_daily_genai_usage\",      \"genai_daily_cost\")  # GenAI\n",
        "    ]\n",
        "\n",
        "    for table, col in marts_to_audit:\n",
        "        audit_gold_layer(spark, table, check_col=col)\n",
        "\n",
        "    log(\"Auditoría Gold finalizada.\", \"OK\")"
      ],
      "metadata": {
        "id": "-HWtT_Wua_KS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bronze_batch.py\n",
        "\n",
        "Ingesta de datos de la Capa Batch"
      ],
      "metadata": {
        "id": "zs4hDdBBVD_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bronze_batch.py\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "\n",
        "\n",
        "try:\n",
        "    from config import LANDING_PATH, BRONZE_PATH\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        LANDING_PATH = _m.LANDING_PATH\n",
        "        BRONZE_PATH = _m.BRONZE_PATH\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar config, hay que corre primero la celda 'config.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "# importacion de squemas\n",
        "\n",
        "try:\n",
        "    from schemas import (\n",
        "        customers_orgs_schema,\n",
        "        users_schema,\n",
        "        resources_schema,\n",
        "        support_tickets_schema,\n",
        "        marketing_touches_schema,\n",
        "        nps_surveys_schema,\n",
        "        billing_monthly_schema,\n",
        "    )\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m  # type: ignore[import]\n",
        "    try:\n",
        "        customers_orgs_schema = _m.customers_orgs_schema\n",
        "        users_schema = _m.users_schema\n",
        "        resources_schema = _m.resources_schema\n",
        "        support_tickets_schema = _m.support_tickets_schema\n",
        "        marketing_touches_schema = _m.marketing_touches_schema\n",
        "        nps_surveys_schema = _m.nps_surveys_schema\n",
        "        billing_monthly_schema = _m.billing_monthly_schema\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar schemas, hayque correr primero la celda 'schemas.py'\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "#  importacion de todo lo qe es IO desde io_utils\n",
        "\n",
        "try:\n",
        "    from io_utils import read_csv, write_parquet, zone_path, add_audit_columns\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        read_csv = _m.read_csv\n",
        "        write_parquet = _m.write_parquet\n",
        "        zone_path = _m.zone_path\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar io_utils, hay que correr antes primero la celda 'io_utils.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "# helper interno para leer .csv\n",
        "\n",
        "def _read_landing_csv(\n",
        "    spark: SparkSession,\n",
        "    file_name: str,\n",
        "    schema,\n",
        ") -> Optional[DataFrame]:\n",
        "\n",
        "    csv_path = LANDING_PATH / file_name\n",
        "    if not csv_path.exists():\n",
        "        print(f\"[WARN] CSV no encontrado en landing: {csv_path}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"[INFO] Leyendo {csv_path}\")\n",
        "    return read_csv(spark, csv_path, schema)\n",
        "\n",
        "\n",
        "# Ingesta\n",
        "\n",
        "def ingest_customers_orgs_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"customers_orgs.csv\", customers_orgs_schema)\n",
        "    if df is None: return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"customers_orgs\")\n",
        "    write_parquet(df, dest, partition_cols=[\"hq_region\"])\n",
        "    print(f\"[OK] Bronze customers_orgs -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_users_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"users.csv\", users_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"users\")\n",
        "    write_parquet(df, dest, partition_cols=[\"role\"])\n",
        "    print(f\"[OK] Bronze users -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_resources_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"resources.csv\", resources_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"resources\")\n",
        "    write_parquet(df, dest, partition_cols=[\"region\"])\n",
        "    print(f\"[OK] Bronze resources -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_support_tickets_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"support_tickets.csv\", support_tickets_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"support_tickets\")\n",
        "    write_parquet(df, dest, partition_cols=[\"severity\"])\n",
        "    print(f\"[OK] Bronze support_tickets -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_marketing_touches_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"marketing_touches.csv\", marketing_touches_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"marketing_touches\")\n",
        "    write_parquet(df, dest, partition_cols=[\"channel\"])\n",
        "    print(f\"[OK] Bronze marketing_touches -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_nps_surveys_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"nps_surveys.csv\", nps_surveys_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"nps_surveys\")\n",
        "    write_parquet(df, dest, partition_cols=[\"survey_date\"])\n",
        "    print(f\"[OK] Bronze nps_surveys -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_billing_monthly_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"billing_monthly.csv\", billing_monthly_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"billing_monthly\")\n",
        "    write_parquet(df, dest, partition_cols=[\"month\"])\n",
        "    print(f\"[OK] Bronze billing_monthly -> {dest}\")\n",
        "\n",
        "\n",
        "# orrquestador de Bronze batch\n",
        "\n",
        "def run_bronze_batch(spark: SparkSession) -> None:\n",
        "  print(\"\\n[BATCH] Iniciando Ingesta a Bronze (7 Maestros)...\")\n",
        "  '''\n",
        "    ingest_customers_orgs_to_bronze(spark)\n",
        "    ingest_users_to_bronze(spark)\n",
        "    ingest_resources_to_bronze(spark)\n",
        "    ingest_support_tickets_to_bronze(spark)\n",
        "    ingest_marketing_touches_to_bronze(spark)\n",
        "    ingest_nps_surveys_to_bronze(spark)\n",
        "    ingest_billing_monthly_to_bronze(spark)\n",
        "    '''\n",
        "  tasks = [\n",
        "    (ingest_customers_orgs_to_bronze, \"Customers\"),\n",
        "    (ingest_users_to_bronze, \"Users\"),\n",
        "    (ingest_resources_to_bronze, \"Resources\"),\n",
        "    (ingest_support_tickets_to_bronze, \"Support Tickets\"),\n",
        "    (ingest_marketing_touches_to_bronze, \"Marketing\"),\n",
        "    (ingest_nps_surveys_to_bronze, \"NPS Surveys\"),\n",
        "    (ingest_billing_monthly_to_bronze, \"Billing\")\n",
        "    ]\n",
        "  # Use barra de progreso de tqdm para hacer visualmente mas atractivo¿a la ejecucion\n",
        "  for func, name in tqdm(tasks, desc=\"Procesando Archivos\", unit=\"tablas\"):\n",
        "    func(spark)\n",
        "    time.sleep(0.1)\n",
        "  log(\"Capa Bronze finalizada correctamente\", \"OK\")"
      ],
      "metadata": {
        "id": "kY96k5ph9koG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bronze_stream.py\n",
        "\n",
        "Ingesta de fdatos para el Stream de la capa Speed\n"
      ],
      "metadata": {
        "id": "qkM2ckNzAU6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # bronze_stream.py\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "\n",
        "try:\n",
        "    from config import LANDING_PATH, BRONZE_PATH\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        LANDING_PATH = _m.LANDING_PATH\n",
        "        BRONZE_PATH = _m.BRONZE_PATH\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar config, hay que correr primero la celda 'config.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "try:\n",
        "    from schemas import usage_events_schema\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        usage_events_schema = _m.usage_events_schema\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar schemas, hay que correr primero la celda 'schemas.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    from io_utils import zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        zone_path = _m.zone_path\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar io_utils hay qeu ejecutar primero la celda 'io_utils.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "# -creacion de DF de streaming\n",
        "\n",
        "def create_usage_events_stream(spark: SparkSession) -> DataFrame:\n",
        "\n",
        "    src_dir = LANDING_PATH / \"usage_events_stream\"\n",
        "\n",
        "    return (\n",
        "        spark.readStream\n",
        "        .schema(usage_events_schema)\n",
        "        .option(\"maxFilesPerTrigger\", 1)\n",
        "        .json(str(src_dir))\n",
        "    )\n",
        "\n",
        "\n",
        "def transform_usage_events_bronze(df_stream: DataFrame) -> DataFrame:\n",
        "\n",
        "    # Transformaciones :'timestamp' a 'event_ts', 'event_date' (date),  watermark y dedupe por event_id\n",
        "\n",
        "    df = (\n",
        "        df_stream\n",
        "        .withColumn(\"event_ts\", F.to_timestamp(\"timestamp\"))\n",
        "        .withColumn(\"event_date\", F.to_date(\"event_ts\"))\n",
        "    )\n",
        "\n",
        "    df = (\n",
        "      df\n",
        "      .withWatermark(\"event_ts\", \"1 day\")\n",
        "      .dropDuplicates([\"event_id\"])\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "  # Arranca el streaming desde usage_events_stream en Landing\n",
        "\n",
        "def start_usage_events_to_bronze(spark: SparkSession):\n",
        "\n",
        "    df_stream = create_usage_events_stream(spark)\n",
        "    df_bronze = transform_usage_events_bronze(df_stream)\n",
        "\n",
        "    dest_path = zone_path(BRONZE_PATH, \"usage_events\")\n",
        "    checkpoint_path = BRONZE_PATH / \"_checkpoints\" / \"usage_events\"\n",
        "\n",
        "    query = (\n",
        "        df_bronze\n",
        "        .writeStream\n",
        "        .format(\"parquet\")\n",
        "        .option(\"checkpointLocation\", str(checkpoint_path))\n",
        "        .option(\"path\", str(dest_path))\n",
        "        .partitionBy(\"event_date\")\n",
        "        .outputMode(\"append\")\n",
        "        .start()\n",
        "    )\n",
        "\n",
        "    print(f\"[INFO] Streaming usage_events -> {dest_path}\")\n",
        "    print(f\"[INFO] Checkpoints en {checkpoint_path}\")\n",
        "    return query"
      ],
      "metadata": {
        "id": "rQ8EQ1tKDDEV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# silver.py\n",
        "\n",
        "Tratamiento de datos para su pasarlos a la fase gold"
      ],
      "metadata": {
        "id": "2TbvgqJtVvKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# silver.py\n",
        "\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# parche de imports para colab de nuevo, esto en el PY final no va a estar\n",
        "try:\n",
        "    from config import BRONZE_PATH, SILVER_PATH, QUARANTINE_PATH\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    BRONZE_PATH = _m.BRONZE_PATH\n",
        "    SILVER_PATH = _m.SILVER_PATH\n",
        "    QUARANTINE_PATH = _m.QUARANTINE_PATH\n",
        "\n",
        "try:\n",
        "    from io_utils import read_parquet, write_parquet, zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    read_parquet = _m.read_parquet\n",
        "    write_parquet = _m.write_parquet\n",
        "    zone_path = _m.zone_path\n",
        "\n",
        "\n",
        "\n",
        "def read_bronze_usage_events(spark: SparkSession) -> DataFrame:\n",
        "    return read_parquet(spark, zone_path(BRONZE_PATH, \"usage_events\"), partition_glob=\"event_date=*\")\n",
        "\n",
        "def read_bronze_customers_orgs(spark: SparkSession) -> DataFrame:\n",
        "    return read_parquet(spark, zone_path(BRONZE_PATH, \"customers_orgs\"))\n",
        "\n",
        "# -impieza, Joins y cuarentena\n",
        "\n",
        "def run_silver_batch(spark: SparkSession) -> None:\n",
        "\n",
        "    print(\"[INFO] Iniciando Silver...\")\n",
        "\n",
        "    usage_df = read_bronze_usage_events(spark)\n",
        "    orgs_df = read_bronze_customers_orgs(spark)\n",
        "\n",
        "    orgs_sel = orgs_df.select(\n",
        "        \"org_id\", \"org_name\", \"hq_region\", \"plan_tier\", \"is_enterprise\"\n",
        "    )\n",
        "\n",
        "    # Join broadcast) // se usa broadcast porque orgs es chica comparada con eventos\n",
        "    enriched_df = usage_df.join(F.broadcast(orgs_sel), on=\"org_id\", how=\"left\")\n",
        "\n",
        "    # Reglas:\n",
        "    # 1: El costo no puede ser negativo (permitimos 0 o mayor, o -0.00...1 errores de float y decimal, pero defino corte en -0.01 para mayor seguridad)\n",
        "    # 2: tiene tener org_id (el join lo mantiene, pero se valida que no sea nulo si era inner logic)\n",
        "    dq_condition = (F.col(\"cost_usd_increment\") >= -0.01) & (F.col(\"org_id\").isNotNull())\n",
        "\n",
        "    # split\n",
        "    good_df = enriched_df.filter(dq_condition)\n",
        "    bad_df = enriched_df.filter(~dq_condition)\n",
        "\n",
        "    if not bad_df.rdd.isEmpty():\n",
        "        # A. Preparar datos fallidos actuales\n",
        "        bad_df = bad_df.withColumn(\"quarantine_reason\", F.lit(\"cost_negative_or_null_org\"))\n",
        "\n",
        "        quarantine_dest = zone_path(QUARANTINE_PATH, \"usage_events_quarantine\")\n",
        "\n",
        "        #  se verifica si ya existe para no duplicar\n",
        "        try:\n",
        "            existing_quarantine = read_parquet(spark, quarantine_dest)\n",
        "\n",
        "            # C. aca hago el left anti join para no tener dupes en cuarentena\n",
        "            unique_bad_df = bad_df.join(\n",
        "                existing_quarantine,\n",
        "                on=\"event_id\",\n",
        "                how=\"left_anti\"\n",
        "            )\n",
        "\n",
        "            new_errors_count = unique_bad_df.count()\n",
        "            if new_errors_count > 0:\n",
        "                print(f\"[WARN] Nuevos registros invalidos detectados: {new_errors_count}\")\n",
        "                write_parquet(unique_bad_df, quarantine_dest, mode=\"append\")\n",
        "            else:\n",
        "                print(f\"[WARN] Errores detectados ya existian en cuarentena\")\n",
        "\n",
        "        except Exception:\n",
        "            # si no hay archivo, se crea\n",
        "            print(f\"[WARN] Creando cuarentena por primera vez\")\n",
        "            write_parquet(bad_df, quarantine_dest, mode=\"append\")\n",
        "\n",
        "    # escritura de Silver limpio\n",
        "    silver_dest = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    good_df = good_df.withColumnRenamed(\"service\", \"service_name\")\n",
        "\n",
        "    write_parquet(\n",
        "        good_df,\n",
        "        silver_dest,\n",
        "        partition_cols=[\"event_date\"],\n",
        "        mode=\"overwrite\"\n",
        "    )\n",
        "    print(f\"[OK] Silver Batch completado, todo ok -> {silver_dest}\")"
      ],
      "metadata": {
        "id": "tUJAJo1OSDp1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gold.py\n",
        "\n",
        "Creacion de los marts de negocios para ser subidos a Cassandra"
      ],
      "metadata": {
        "id": "P1IadKcRV4LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gold.py\n",
        "import pandas as pd\n",
        "\n",
        "from __future__ import annotations\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# parche de imports para colab de nuevo, esto en el PY final no va a estar\n",
        "try:\n",
        "    from config import SILVER_PATH, GOLD_PATH, BRONZE_PATH\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    SILVER_PATH = _m.SILVER_PATH\n",
        "    GOLD_PATH = _m.GOLD_PATH\n",
        "    BRONZE_PATH = _m.BRONZE_PATH\n",
        "\n",
        "try:\n",
        "    from io_utils import read_parquet, write_parquet, zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    read_parquet = _m.read_parquet\n",
        "    write_parquet = _m.write_parquet\n",
        "    zone_path = _m.zone_path\n",
        "\n",
        "try:\n",
        "    from bronze_stream import create_usage_events_stream, transform_usage_events_bronze\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    create_usage_events_stream = _m.create_usage_events_stream\n",
        "    transform_usage_events_bronze = _m.transform_usage_events_bronze\n",
        "\n",
        "\n",
        "# Gold de Batch, en las proximas funcioens se generan losmarts de Finopsl, Support y Genai\n",
        "\n",
        "def build_gold_finops_mart(spark: SparkSession) -> DataFrame:\n",
        "\n",
        "\n",
        "    silver_path = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    silver_df = read_parquet(spark, silver_path)\n",
        "\n",
        "    # agregaciones\n",
        "    aggregated_df = (\n",
        "        silver_df\n",
        "        .groupBy(\"org_id\", \"org_name\", \"service_name\", \"event_date\", \"hq_region\", \"plan_tier\")\n",
        "        .agg(\n",
        "            F.sum(\"cost_usd_increment\").alias(\"daily_cost_usd\"),\n",
        "            F.sum(\n",
        "                F.when(F.col(\"metric\") == \"requests\", F.col(\"value\")).otherwise(0.0)\n",
        "            ).alias(\"daily_requests\"),\n",
        "            F.sum(\"carbon_kg\").alias(\"daily_carbon_kg\")\n",
        "        )\n",
        "    )\n",
        "\n",
        "    #KPIs\n",
        "    gold_df = (\n",
        "        aggregated_df\n",
        "        .withColumn(\n",
        "            \"cost_per_request\",\n",
        "            F.when(F.col(\"daily_requests\") > 0,\n",
        "                   F.col(\"daily_cost_usd\") / F.col(\"daily_requests\")).otherwise(None)\n",
        "        )\n",
        "        .withColumn(\n",
        "            \"carbon_per_dollar\",\n",
        "            F.when(F.col(\"daily_cost_usd\") > 0,\n",
        "                   F.col(\"daily_carbon_kg\") / F.col(\"daily_cost_usd\")).otherwise(None)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return gold_df\n",
        "\n",
        "def run_gold_batch_finops_mart(spark: SparkSession) -> None:\n",
        "    df = build_gold_finops_mart(spark)\n",
        "    dest = zone_path(GOLD_PATH, \"org_daily_usage_by_service\")\n",
        "    write_parquet(df, dest, partition_cols=[\"event_date\"], mode=\"overwrite\")\n",
        "    print(f\"[OK] Gold Batch (FinOps) -> {dest}\")\n",
        "\n",
        "\n",
        "def build_gold_support_mart(spark: SparkSession) -> DataFrame:\n",
        "    tickets_path = zone_path(BRONZE_PATH, \"support_tickets\")\n",
        "    tickets_df = read_parquet(spark, tickets_path, partition_glob=\"severity=*\")\n",
        "    orgs_path = zone_path(BRONZE_PATH, \"customers_orgs\")\n",
        "    orgs_df = read_parquet(spark, orgs_path).select(\"org_id\", \"org_name\")\n",
        "\n",
        "    metrics_df = (\n",
        "        tickets_df\n",
        "        .groupBy(\"org_id\", \"created_at\")\n",
        "        .agg(\n",
        "            F.count(\"ticket_id\").alias(\"total_tickets\"),\n",
        "            # FIX: Pasamos a lower() antes de comparar\n",
        "            F.sum(F.when(F.lower(F.col(\"severity\")) == \"critical\", 1).otherwise(0)).alias(\"critical_tickets\"),\n",
        "            F.sum(F.when(F.col(\"sla_breached\") == True, 1).otherwise(0)).alias(\"sla_breached_count\"),\n",
        "            F.avg(\"csat\").alias(\"avg_csat\")\n",
        "        )\n",
        "        .withColumnRenamed(\"created_at\", \"ticket_date\")\n",
        "    )\n",
        "    return metrics_df.join(orgs_df, on=\"org_id\", how=\"left\").withColumn(\n",
        "        \"sla_breach_rate\",\n",
        "        F.when(F.col(\"total_tickets\") > 0, F.round(F.col(\"sla_breached_count\") / F.col(\"total_tickets\"), 4)).otherwise(0.0)\n",
        "    )\n",
        "\n",
        "def run_gold_support_batch(spark: SparkSession) -> None:\n",
        "    df = build_gold_support_mart(spark)\n",
        "    dest = zone_path(GOLD_PATH, \"org_daily_support_metrics\")\n",
        "    write_parquet(df, dest, partition_cols=[\"ticket_date\"], mode=\"overwrite\")\n",
        "    print(f\"[OK] Gold Batch (Support FIX) -> {dest}\")\n",
        "\n",
        "def build_gold_genai_mart(spark: SparkSession) -> DataFrame:\n",
        "    silver_path = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    df = read_parquet(spark, silver_path)\n",
        "\n",
        "    genai_df = (\n",
        "        df\n",
        "        .filter(F.lower(F.col(\"service_name\")).contains(\"genai\"))\n",
        "        .groupBy(\"org_id\", \"org_name\", \"event_date\", \"service_name\")\n",
        "        .agg(\n",
        "            F.sum(\"cost_usd_increment\").alias(\"genai_daily_cost\"),\n",
        "            F.sum(\n",
        "                F.when(F.col(\"metric\") == \"requests\", F.col(\"value\")).otherwise(0)\n",
        "            ).alias(\"genai_requests_count\")\n",
        "        )\n",
        "    )\n",
        "    return genai_df\n",
        "\n",
        "def run_gold_genai_batch(spark: SparkSession) -> None:\n",
        "    df = build_gold_genai_mart(spark)\n",
        "    dest = zone_path(GOLD_PATH, \"org_daily_genai_usage\")\n",
        "    write_parquet(df, dest, partition_cols=[\"event_date\"], mode=\"overwrite\")\n",
        "    print(f\"[OK] Gold Batch (GenAI final) -> {dest}\")\n",
        "\n",
        "\n",
        "def run_full_gold_batch(spark: SparkSession) -> None:\n",
        "  run_gold_batch_finops_mart(spark)\n",
        "  run_gold_support_batch(spark)\n",
        "  run_gold_genai_batch(spark)\n",
        "\n",
        "\n",
        "# SPEED GOLD: Streaming Directo a Gold\n",
        "\n",
        "def start_gold_speed_stream(spark: SparkSession):\n",
        "\n",
        "    # Speed Layer: Lee stream yvuelca a Gold\n",
        "    # se usa cache de  Orgs para evitar I/O repetitivo y Coalesce(1) para evitar el problema de tener muchos archivos chicos en Gold.\n",
        "\n",
        "    print(\"[INFO] Comenzando Speed Layer...\")\n",
        "\n",
        "    # Stream\n",
        "    raw_stream = create_usage_events_stream(spark)\n",
        "    stream_bronze = transform_usage_events_bronze(raw_stream)\n",
        "\n",
        "    #  cacheo de Orgs\n",
        "\n",
        "    orgs_df = read_parquet(spark, zone_path(BRONZE_PATH, \"customers_orgs\"))\n",
        "    orgs_sel = orgs_df.select(\"org_id\", \"org_name\", \"hq_region\", \"plan_tier\")\n",
        "    orgs_sel.cache()\n",
        "    print(f\"[INFO] Dimensión Organizaciones cacheada: {orgs_sel.count()} registros.\")\n",
        "\n",
        "\n",
        "    dest_speed = zone_path(GOLD_PATH, \"org_daily_usage_by_service_speed\")\n",
        "\n",
        "    def process_microbatch(batch_df: DataFrame, batch_id: int):\n",
        "\n",
        "        if batch_df.rdd.isEmpty():\n",
        "            return\n",
        "\n",
        "        # metricas\n",
        "        input_count = batch_df.count()\n",
        "\n",
        "        # procesado\n",
        "        enriched = batch_df.join(F.broadcast(orgs_sel), on=\"org_id\", how=\"left\")\n",
        "\n",
        "        # data quality\n",
        "        valid_stream = enriched.filter(F.col(\"cost_usd_increment\") >= -0.01)\n",
        "        valid_count = valid_stream.count()\n",
        "        dropped_count = input_count - valid_count\n",
        "\n",
        "        # aregaciones\n",
        "        agg_batch = (\n",
        "            valid_stream\n",
        "            .groupBy(\"org_id\", \"org_name\", \"service\", \"event_date\")\n",
        "            .agg(\n",
        "                F.sum(\"cost_usd_increment\").alias(\"daily_cost_usd\"),\n",
        "                F.sum(F.when(F.col(\"metric\") == \"requests\", F.col(\"value\")).otherwise(0)).alias(\"daily_requests\"),\n",
        "                F.sum(\"carbon_kg\").alias(\"daily_carbon_kg\")\n",
        "            )\n",
        "            .withColumnRenamed(\"service\", \"service_name\")\n",
        "        )\n",
        "\n",
        "        # Append\n",
        "        (\n",
        "            agg_batch\n",
        "            .coalesce(1)\n",
        "            .write\n",
        "            .mode(\"append\")\n",
        "            .partitionBy(\"event_date\")\n",
        "            .parquet(str(dest_speed))\n",
        "        )\n",
        "\n",
        "        #  Logde quality para monitoreo ---\n",
        "\n",
        "        print(f\"[STREAM {batch_id}] Reporte \")\n",
        "        print(f\" Input: {input_count} eventos\")\n",
        "        print(f\"Validos: {valid_count}\")\n",
        "        if dropped_count > 0:\n",
        "            print(f\"Dropped (Cost < -0.01): {dropped_count} ({(dropped_count/input_count)*100:.1f}%)\")\n",
        "        print(f\"todo pasado a Gold de Speed layer\")\n",
        "\n",
        "    # Arranca Stream con outputMode(\"update\") para permitir agregacionesy con  foreachBatch manejando la salida final\n",
        "    query = (\n",
        "        stream_bronze\n",
        "        .writeStream\n",
        "        .foreachBatch(process_microbatch)\n",
        "        .outputMode(\"update\")\n",
        "        .trigger(processingTime=\"5 seconds\") # trigger para no saturar\n",
        "        .start()\n",
        "    )\n",
        "\n",
        "    print(f\"[INFO] Streaming ejecutandose -> {dest_speed}\")\n",
        "    return query"
      ],
      "metadata": {
        "id": "4wEDN8i8TvOF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cassandra_utils.puy\n",
        "\n",
        "Crea la instancia de cassandra conlas credenciales provistas en la carpeta /creds y agreaga las tablas al Keyspace asignado"
      ],
      "metadata": {
        "id": "Vm-aHP8JXvpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cassandra_utils.py\n",
        "\n",
        "import os\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# carga de credenciales\n",
        "load_dotenv(\"/content/creds/cred.env\", override=True)\n",
        "# config\n",
        "SECURE_BUNDLE_PATH = \"/content/creds/secure-connect-proyecto-cloud-analytics.zip\"\n",
        "ASTRA_DB_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
        "KEYSPACE = \"Cloud_analytics_db\"\n",
        "\n",
        "# funcines de implementacion de cassandra: tomar, crear e insertar\n",
        "def get_cassandra_session():\n",
        "\n",
        "    if not Path(SECURE_BUNDLE_PATH).exists():\n",
        "        raise FileNotFoundError(f\"Falta el Secure Connect Bundle en: {SECURE_BUNDLE_PATH}\")\n",
        "\n",
        "    if not ASTRA_DB_TOKEN:\n",
        "        raise RuntimeError(\"No se encontro ASTRA_DB_APPLICATION_TOKEN en cred.env\")\n",
        "\n",
        "    cloud_config = {\n",
        "        'secure_connect_bundle': SECURE_BUNDLE_PATH\n",
        "    }\n",
        "\n",
        "    auth_provider = PlainTextAuthProvider(\"token\", ASTRA_DB_TOKEN)\n",
        "\n",
        "    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\n",
        "    session = cluster.connect()\n",
        "    return session\n",
        "\n",
        "def create_schema(session):\n",
        "    print(f\"[CASSANDRA] Creando esquema en keyspace '{KEYSPACE}'...\")\n",
        "\n",
        "    # 1. Tabla FinOps (Ya existía)\n",
        "    ddl_finops = f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS \"{KEYSPACE}\".org_daily_usage_by_service (\n",
        "        org_id text,\n",
        "        usage_date date,\n",
        "        service_name text,\n",
        "        daily_cost_usd double,\n",
        "        daily_requests double,\n",
        "        daily_carbon_kg double,\n",
        "        cost_per_request double,\n",
        "        carbon_per_dollar double,\n",
        "        PRIMARY KEY ((org_id), usage_date, service_name)\n",
        "    ) WITH CLUSTERING ORDER BY (usage_date DESC, service_name ASC);\n",
        "    \"\"\"\n",
        "    session.execute(ddl_finops)\n",
        "\n",
        "    # 2. NUEVA: Tabla de Soporte (Support Mart)\n",
        "    # PK: org_id (partition), ticket_date (clustering) para ver evolución temporal\n",
        "    ddl_support = f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS \"{KEYSPACE}\".org_daily_support_metrics (\n",
        "        org_id text,\n",
        "        ticket_date date,\n",
        "        total_tickets int,\n",
        "        critical_tickets int,\n",
        "        sla_breached_count int,\n",
        "        avg_csat double,\n",
        "        sla_breach_rate double,\n",
        "        PRIMARY KEY ((org_id), ticket_date)\n",
        "    ) WITH CLUSTERING ORDER BY (ticket_date DESC);\n",
        "    \"\"\"\n",
        "    session.execute(ddl_support)\n",
        "\n",
        "    # 3. NUEVA: Tabla de GenAI (Product Mart)\n",
        "    # PK: org_id (partition), event_date + service (clustering)\n",
        "    ddl_genai = f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS \"{KEYSPACE}\".org_daily_genai_usage (\n",
        "        org_id text,\n",
        "        event_date date,\n",
        "        service_name text,\n",
        "        genai_daily_cost double,\n",
        "        genai_requests_count double,\n",
        "        PRIMARY KEY ((org_id), event_date, service_name)\n",
        "    ) WITH CLUSTERING ORDER BY (event_date DESC);\n",
        "    \"\"\"\n",
        "    session.execute(ddl_genai)\n",
        "\n",
        "    print(\"[CASSANDRA] Esquema verificado: 3 Tablas listas.\")\n",
        "\n",
        "def insert_batch_to_cassandra(rows: list[dict]):\n",
        "    if not rows:\n",
        "        return\n",
        "    session = get_cassandra_session()\n",
        "\n",
        "    query = f\"\"\"\n",
        "    INSERT INTO \"{KEYSPACE}\".org_daily_usage_by_service (\n",
        "        org_id, usage_date, service_name,\n",
        "        daily_cost_usd, daily_requests, daily_carbon_kg,\n",
        "        cost_per_request, carbon_per_dollar\n",
        "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "    prepared = session.prepare(query)\n",
        "\n",
        "    for row in rows:\n",
        "        session.execute(prepared, (\n",
        "            row[\"org_id\"],\n",
        "            row[\"event_date\"],\n",
        "            row[\"service_name\"],\n",
        "            row[\"daily_cost_usd\"],\n",
        "            row[\"daily_requests\"],\n",
        "            row[\"daily_carbon_kg\"],\n",
        "            row[\"cost_per_request\"],\n",
        "            row[\"carbon_per_dollar\"]\n",
        "        ))\n",
        "\n",
        "    session.shutdown()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qjupavh5XsCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cassandra_loader.py\n",
        "\n",
        "Carga todas las tablas generadas en Gold"
      ],
      "metadata": {
        "id": "5IWMv1hwXaLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cassandra_loader.py\n",
        "\n",
        "from pyspark.sql import DataFrame\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def upload_full_gold_layer(spark: SparkSession):\n",
        "    \"\"\"\n",
        "    Carga TODAS las tablas Gold (FinOps, Support, GenAI) a Cassandra.\n",
        "    Maneja el renombrado de columnas para coincidir con el esquema de DB.\n",
        "    \"\"\"\n",
        "    print(\"\\n[SERVING] Iniciando carga masiva a AstraDB...\")\n",
        "\n",
        "    # Este try es para asegurear idempotencia\n",
        "    try:\n",
        "        session = get_cassandra_session()\n",
        "        create_schema(session)\n",
        "        session.shutdown()\n",
        "    except Exception as e:\n",
        "        print(f\"[ERR] Error creando esquema: {e}\")\n",
        "        return\n",
        "\n",
        "    #helper interno de carga\n",
        "    def load_df_to_cassandra(df: DataFrame, table_name: str, columns_map: list[str]):\n",
        "\n",
        "        try:\n",
        "            count = df.count()\n",
        "            print(f\"   -> cargando tabla '{table_name}' ({count} registros)...\")\n",
        "\n",
        "            rows = df.collect()\n",
        "            data_dicts = [row.asDict() for row in rows]\n",
        "\n",
        "            if not data_dicts:\n",
        "                print(f\"      [WARN] No hay datos para {table_name}.\")\n",
        "                return\n",
        "\n",
        "            session = get_cassandra_session()\n",
        "\n",
        "            # query\n",
        "            cols_str = \", \".join(columns_map)\n",
        "            bind_markers = \", \".join([\"?\"] * len(columns_map))\n",
        "            query = f'INSERT INTO \"{KEYSPACE}\".{table_name} ({cols_str}) VALUES ({bind_markers})'\n",
        "            prepared = session.prepare(query)\n",
        "\n",
        "            # upsert\n",
        "            for row_data in tqdm(data_dicts, desc=f\"Subiendo {table_name}\", unit=\"rows\"):\n",
        "                values = []\n",
        "                for col in columns_map:\n",
        "                    # Obtenemos el valor. Si la columna no existe en el DF, inserta None.\n",
        "                    val = row_data.get(col)\n",
        "                    values.append(val)\n",
        "\n",
        "                session.execute(prepared, values)\n",
        "\n",
        "            session.shutdown()\n",
        "            print(f\"      [OK] Carga completada.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      [ERR] Falló carga de {table_name}. Detalles: {e}\")\n",
        "\n",
        "\n",
        "    # carga de finops(org_daily_usage_by_service)\n",
        "    path_finops = zone_path(GOLD_PATH, \"org_daily_usage_by_service\")\n",
        "    df_finops = read_parquet(spark, path_finops, partition_glob=\"*\")\n",
        "    df_finops = df_finops.withColumnRenamed(\"event_date\", \"usage_date\")\n",
        "\n",
        "    load_df_to_cassandra(\n",
        "        df_finops,\n",
        "        \"org_daily_usage_by_service\",\n",
        "        [\"org_id\", \"usage_date\", \"service_name\", \"daily_cost_usd\", \"daily_requests\", \"daily_carbon_kg\", \"cost_per_request\", \"carbon_per_dollar\"]\n",
        "    )\n",
        "\n",
        "    # cargade support (org_daily_support_metrics)\n",
        "    path_support = zone_path(GOLD_PATH, \"org_daily_support_metrics\")\n",
        "    df_support = read_parquet(spark, path_support, partition_glob=\"*\")\n",
        "\n",
        "    load_df_to_cassandra(\n",
        "        df_support,\n",
        "        \"org_daily_support_metrics\",\n",
        "        [\"org_id\", \"ticket_date\", \"total_tickets\", \"critical_tickets\", \"sla_breached_count\", \"avg_csat\", \"sla_breach_rate\"]\n",
        "    )\n",
        "\n",
        "    #  carga de genai (org_daily_genai_usage) ---\n",
        "    path_genai = zone_path(GOLD_PATH, \"org_daily_genai_usage\")\n",
        "    df_genai = read_parquet(spark, path_genai, partition_glob=\"*\")\n",
        "\n",
        "    load_df_to_cassandra(\n",
        "        df_genai,\n",
        "        \"org_daily_genai_usage\",\n",
        "        [\"org_id\", \"event_date\", \"service_name\", \"genai_daily_cost\", \"genai_requests_count\"]\n",
        "    )\n",
        "def upload_gold_to_cassandra(spark: SparkSession):\n",
        "\n",
        "    # la carga  gold en Cassandra\n",
        "    print(\"\\n[SERVING] Iniciando carga a Cassandra...\")\n",
        "\n",
        "    try:\n",
        "        session = get_cassandra_session()\n",
        "        create_schema(session)\n",
        "        session.shutdown()\n",
        "    except Exception as e:\n",
        "        print(f\"[ERR] Error conectando a Cassandra: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    gold_df = read_parquet(spark, zone_path(GOLD_PATH, \"org_daily_usage_by_service\"), partition_glob=\"event_date=*\")\n",
        "\n",
        "    # convierte a python con el driver\n",
        "\n",
        "    print(f\"[SERVING] Leyendo {gold_df.count()} filas de Gold...\")\n",
        "    rows = gold_df.collect()\n",
        "    data_to_insert = [row.asDict() for row in rows]\n",
        "\n",
        "    insert_batch_to_cassandra(data_to_insert)\n",
        "    print(f\"[SERVING] Carga completada. {len(data_to_insert)} registros insertados.\")\n",
        "\n",
        "\n",
        "def write_stream_to_cassandra(batch_df, batch_id):\n",
        "    #funcion para usar en .foreachBatch del Streaming.\n",
        "\n",
        "    if batch_df.rdd.isEmpty(): return\n",
        "    rows = batch_df.collect()\n",
        "    data = [row.asDict() for row in rows]\n",
        "\n",
        "    # upsert\n",
        "    insert_batch_to_cassandra(data)\n",
        "    print(f\"[CASSANDRA STREAM] Batch {batch_id} cargado ({len(data)} filas).\")"
      ],
      "metadata": {
        "id": "o5KrZ9GVoqnu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo de Batch Layer → Gold"
      ],
      "metadata": {
        "id": "YnGKPv-va_h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "ensure_dirs()\n",
        "unpack_raw_dataset()\n",
        "spark = create_spark()\n",
        "\n",
        "log(\"PROJECT_ROOT: {PROJECT_ROOT}\", \"INFO\")\n",
        "log(f\"Spark version: {spark.version}\", \"INFO\")\n",
        "log(\"Generando Bronze Batch (Maestros)...\", \"RUN\")\n",
        "ensure_dirs()\n",
        "unpack_raw_dataset()\n",
        "spark = create_spark()\n",
        "run_bronze_batch(spark)\n",
        "\n",
        "log(\"Generando Bronze Stream (Eventos)...\", \"RUN\")\n",
        "query = start_usage_events_to_bronze(spark)\n",
        "\n",
        "time.sleep(15) # esto es solo para asegurrar en el demo que se procesen datos\n",
        "query.stop()\n",
        "log(\"Stream procesado.\", \"OK\")\n",
        "\n",
        "log(\"Generando Silver...\", \"RUN\")\n",
        "run_silver_batch(spark)\n",
        "log(\"Silver finalizado\", \"OK\")\n",
        "log(\"ejecuntando proceso Gold...\", \"RUN\")\n",
        "run_full_gold_batch(spark)\n",
        "log(\"proceso Gold finalizado\", \"OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692,
          "referenced_widgets": [
            "dba1fa0ce6b94872b5feb657d55a6306",
            "6bbf9738e70648c992d54bc53635203e",
            "7a74f98d7c7a4e0493eb4a279b9f9aae",
            "d6ae08be5ae2452b9ca58a5edfca29a1",
            "9456c27eefcc4f6aa7dfb35e9baa3adc",
            "47955ae520dc4514bcd358abf2f6c9b9",
            "4cd2f3c01fc647ac82d95755efe14cd4",
            "96b44ca157094a2ea861a1d5e335052d",
            "253a9936314f4fe48edba77eef2907b3",
            "f724b5df5e0f4c62a5bc2e970d2571f0",
            "4a16ca1605ab4d0fb67a3854d0e4bf77"
          ]
        },
        "id": "QAY_yxGBug5y",
        "outputId": "0c81c2c9-650c-4090-9423-1c4aba8c99e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Dataset descomprimido en /content/datalake/landing\n",
            "\u001b[94m[2025-12-02 22:10:26] [INFO] PROJECT_ROOT: {PROJECT_ROOT}\u001b[0m\n",
            "\u001b[94m[2025-12-02 22:10:26] [INFO] Spark version: 3.5.1\u001b[0m\n",
            "\u001b[96m[2025-12-02 22:10:26] [RUN] 1. Generando Bronze Batch (Maestros)...\u001b[0m\n",
            "[OK] Dataset descomprimido en /content/datalake/landing\n",
            "\n",
            "[BATCH] Iniciando Ingesta a Bronze (7 Maestros)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Procesando Archivos:   0%|          | 0/7 [00:00<?, ?tablas/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dba1fa0ce6b94872b5feb657d55a6306"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Leyendo /content/datalake/landing/customers_orgs.csv\n",
            "[OK] Bronze customers_orgs -> /content/datalake/bronze/customers_orgs\n",
            "[INFO] Leyendo /content/datalake/landing/users.csv\n",
            "[OK] Bronze users -> /content/datalake/bronze/users\n",
            "[INFO] Leyendo /content/datalake/landing/resources.csv\n",
            "[OK] Bronze resources -> /content/datalake/bronze/resources\n",
            "[INFO] Leyendo /content/datalake/landing/support_tickets.csv\n",
            "[OK] Bronze support_tickets -> /content/datalake/bronze/support_tickets\n",
            "[INFO] Leyendo /content/datalake/landing/marketing_touches.csv\n",
            "[OK] Bronze marketing_touches -> /content/datalake/bronze/marketing_touches\n",
            "[INFO] Leyendo /content/datalake/landing/nps_surveys.csv\n",
            "[OK] Bronze nps_surveys -> /content/datalake/bronze/nps_surveys\n",
            "[INFO] Leyendo /content/datalake/landing/billing_monthly.csv\n",
            "[OK] Bronze billing_monthly -> /content/datalake/bronze/billing_monthly\n",
            "\u001b[92m[2025-12-02 22:10:45] [OK] Capa Bronze finalizada correctamente\u001b[0m\n",
            "\u001b[96m[2025-12-02 22:10:45] [RUN] 2. Generando Bronze Stream (Eventos)...\u001b[0m\n",
            "[INFO] Streaming usage_events -> /content/datalake/bronze/usage_events\n",
            "[INFO] Checkpoints en /content/datalake/bronze/_checkpoints/usage_events\n",
            "\u001b[92m[2025-12-02 22:11:01] [OK] Stream procesado.\u001b[0m\n",
            "\u001b[96m[2025-12-02 22:11:01] [RUN] 3. Generando Silver...\u001b[0m\n",
            "[INFO] Iniciando Silver...\n",
            "[WARN] Creando cuarentena por primera vez\n",
            "[OK] Silver Batch completado, todo ok -> /content/datalake/silver/usage_events_enriched\n",
            "\u001b[92m[2025-12-02 22:11:18] [OK] Silver finalizado\u001b[0m\n",
            "\u001b[96m[2025-12-02 22:11:18] [RUN] 4. ejecuntando proceso Gold...\u001b[0m\n",
            "[OK] Gold Batch (FinOps) -> /content/datalake/gold/org_daily_usage_by_service\n",
            "[OK] Gold Batch (Support FIX) -> /content/datalake/gold/org_daily_support_metrics\n",
            "[OK] Gold Batch (GenAI Final) -> /content/datalake/gold/org_daily_genai_usage\n",
            "\u001b[92m[2025-12-02 22:11:31] [OK] proceso Gold finalizado\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chequeo de Quality de las tres fases"
      ],
      "metadata": {
        "id": "1XrCg9qiWCJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chequeo de quality\n",
        "log(\"Haciendo quality control...\", \"RUN\")\n",
        "run_full_bronze_audit(spark)\n",
        "run_full_silver_audit(spark)\n",
        "run_full_gold_audit(spark)\n",
        "log(\"Fin demo Batch Layer (Bronze CSV → Silver → Gold)\", \"OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeNRXd79G-Ho",
        "outputId": "c80b88e7-8a9b-47db-dcfc-3d7a9b9d8142"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m[2025-12-02 22:11:31] [RUN] Haciendo quality control...\u001b[0m\n",
            "\u001b[96m[2025-12-02 22:11:31] [RUN] Iniciando Auditoría completa de capa Bronze...\u001b[0m\n",
            "\n",
            " chequeo Bronze: customers_orgs\n",
            "registros totales: 80\n",
            "duplicados en PK (org_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: Todo ok\n",
            "\n",
            " chequeo Bronze: users\n",
            "registros totales: 800\n",
            "duplicados en PK (user_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: Todo ok\n",
            "\n",
            " chequeo Bronze: resources\n",
            "registros totales: 400\n",
            "duplicados en PK (resource_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: Todo ok\n",
            "\n",
            " chequeo Bronze: support_tickets\n",
            "registros totales: 1000\n",
            "duplicados en PK (ticket_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: Todo ok\n",
            "\n",
            " chequeo Bronze: marketing_touches\n",
            "registros totales: 1500\n",
            "duplicados en PK (touch_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: Todo ok\n",
            "\n",
            " chequeo Bronze: billing_monthly\n",
            "registros totales: 240\n",
            "duplicados en PK (invoice_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: Todo ok\n",
            "\n",
            " chequeo Bronze: nps_surveys\n",
            "registros totales: 92\n",
            "duplicados en PK (org_id): 32\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: Revisar data por posibles duplicados o falta de metadatos\n",
            "\u001b[92m[2025-12-02 22:11:37] [OK] Auditoría Bronze finalizada.\u001b[0m\n",
            "\u001b[96m[2025-12-02 22:11:37] [RUN] Iniciando Auditoría de Calidad Silver...\u001b[0m\n",
            "\n",
            " Chequeop Silver:\n",
            "Total: 758\n",
            "Aceptados (Silver): 755\n",
            "Rechazados (cuarentena): 3 (0.40%)\n",
            "CALIDAD: ACEPTABLE\n",
            "ejemplo de rechazo:\n",
            "+----------------+-------------------------+\n",
            "|event_id        |quarantine_reason        |\n",
            "+----------------+-------------------------+\n",
            "|evt_faubjbtabmwl|cost_negative_or_null_org|\n",
            "+----------------+-------------------------+\n",
            "only showing top 1 row\n",
            "\n",
            "\n",
            "Calidad de Datos (Silver Batch)\n",
            "\n",
            " Estadisticas:\n",
            "Total Procesado: 758\n",
            "Aceptados (Silver): 755 (99.60%)\n",
            "Rechazados (Quarantine): 3 (0.40%)\n",
            "\n",
            "resultado:\n",
            "Aceptable- rechazo  bajo y esperado.\n",
            "\n",
            " Muestra de registros en Cuarentena (top 5):\n",
            "+----------------+------------------+------------+-------------------------+\n",
            "|event_id        |cost_usd_increment|org_id      |quarantine_reason        |\n",
            "+----------------+------------------+------------+-------------------------+\n",
            "|evt_faubjbtabmwl|-0.0602           |org_cvs4f8cg|cost_negative_or_null_org|\n",
            "|evt_qniow8ymxwd6|-0.2446           |org_i7p5tb94|cost_negative_or_null_org|\n",
            "|evt_bbmth9hzpa6e|-0.3656           |org_n9j2qp89|cost_negative_or_null_org|\n",
            "+----------------+------------------+------------+-------------------------+\n",
            "\n",
            "\u001b[92m[2025-12-02 22:11:44] [OK] Auditoría Silver finalizada.\u001b[0m\n",
            "\u001b[96m[2025-12-02 22:11:44] [RUN] Iniciando Auditoría de Marts Gold...\u001b[0m\n",
            "\n",
            " Chequeo Gold: org_daily_usage_by_service\n",
            "registros Totales (Agregados): 727\n",
            "Costos Negativos detectados: 0\n",
            "\n",
            " Chequeo Gold: org_daily_support_metrics\n",
            "registros Totales (Agregados): 944\n",
            "Costos Negativos detectados: 0\n",
            "\n",
            " Chequeo Gold: org_daily_genai_usage\n",
            "registros Totales (Agregados): 77\n",
            "Costos Negativos detectados: 0\n",
            "\u001b[92m[2025-12-02 22:11:48] [OK] Auditoría Gold finalizada.\u001b[0m\n",
            "\u001b[92m[2025-12-02 22:11:48] [OK] Fin demo Batch Layer (Bronze CSV → Silver → Gold)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo de Speed Layer → Gold\n",
        "\n",
        "En un despliegue real, el pipeline de streaming se ejecutaría como servicio/orquestación aparte"
      ],
      "metadata": {
        "id": "szSUhws8Zj4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEMO Speed → Gold\n",
        "import time\n",
        "\n",
        "query_speed_gold = start_gold_speed_stream(spark)\n",
        "\n",
        "print(\"Streaming Speed → Gold\")\n",
        "print(f\"ID: {query_speed_gold.id}\")\n",
        "print(f\"Nombre: {query_speed_gold.name}\")\n",
        "print(f\"Activo: {query_speed_gold.isActive}\")\n",
        "\n",
        "\n",
        "# pausa para dejar que procese\n",
        "\n",
        "time.sleep(15)\n",
        "\n",
        "print(\" Progreso del streaming\")\n",
        "print(query_speed_gold.lastProgress)\n",
        "\n",
        "print(\"aparando stream...\")\n",
        "\n",
        "'''\n",
        "El try que viene lo hice por si el stream se para mientras esta procesando algo y tira error java.lang.InterruptedException\n",
        "ese error que no para la ejecucion del colab y solo pasa aca porque el stream se para un momento arbitrario.\n",
        "en un deploy real no se haria.\n",
        "\n",
        "'''\n",
        "if query_speed_gold.isActive:\n",
        "    query_speed_gold.stop()\n",
        "    try:\n",
        "        query_speed_gold.awaitTermination(timeout=2)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "audit_speed_layer_results(spark)\n",
        "print(\"Streaming Speed → Gold parado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S94XmoANYnJC",
        "outputId": "040fee9d-8ace-4669-d17f-c4d4d3684087"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Comenzando Speed Layer...\n",
            "[INFO] Dimensión Organizaciones cacheada: 80 registros.\n",
            "[INFO] Streaming ejecutandose -> /content/datalake/gold/org_daily_usage_by_service_speed\n",
            "Streaming Speed → Gold\n",
            "ID: 5cb673d3-9408-4260-8f47-e80a32a7d161\n",
            "Nombre: None\n",
            "Activo: True\n",
            "[STREAM 0] Reporte \n",
            " Input: 360 eventos\n",
            "Validos: 359\n",
            "Dropped (Cost < -0.01): 1 (0.3%)\n",
            "todo pasado a Gold de Speed layer\n",
            "[STREAM 1] Reporte \n",
            " Input: 360 eventos\n",
            "Validos: 358\n",
            "Dropped (Cost < -0.01): 2 (0.6%)\n",
            "todo pasado a Gold de Speed layer\n",
            "[STREAM 2] Reporte \n",
            " Input: 11 eventos\n",
            "Validos: 11\n",
            "todo pasado a Gold de Speed layer\n",
            "[STREAM 3] Reporte \n",
            " Input: 7 eventos\n",
            "Validos: 7\n",
            "todo pasado a Gold de Speed layer\n",
            " Progreso del streaming\n",
            "{'id': '5cb673d3-9408-4260-8f47-e80a32a7d161', 'runId': 'de517849-55ac-4753-9cd0-2364eab3806e', 'name': None, 'timestamp': '2025-12-02T22:12:00.000Z', 'batchId': 3, 'numInputRows': 360, 'inputRowsPerSecond': 119.76047904191617, 'processedRowsPerSecond': 215.8273381294964, 'durationMs': {'addBatch': 1537, 'commitOffsets': 40, 'getBatch': 9, 'latestOffset': 32, 'queryPlanning': 17, 'triggerExecution': 1668, 'walCommit': 29}, 'eventTime': {'avg': '2025-08-02T03:04:24.833Z', 'max': '2025-08-31T23:51:00.000Z', 'min': '2025-07-03T00:48:00.000Z', 'watermark': '2025-08-30T23:51:00.000Z'}, 'stateOperators': [{'operatorName': 'dedupe', 'numRowsTotal': 2410, 'numRowsUpdated': 25, 'allUpdatesTimeMs': 145, 'numRowsRemoved': 0, 'allRemovalsTimeMs': 2, 'commitTimeMs': 805, 'memoryUsedBytes': 481296, 'numRowsDroppedByWatermark': 1142, 'numShufflePartitions': 13, 'numStateStoreInstances': 13, 'customMetrics': {'loadedMapCacheHitCount': 74, 'loadedMapCacheMissCount': 40, 'numDroppedDuplicateRows': 0, 'stateOnCurrentVersionSizeBytes': 445792}}], 'sources': [{'description': 'FileStreamSource[file:/content/datalake/landing/usage_events_stream]', 'startOffset': {'logOffset': 2}, 'endOffset': {'logOffset': 3}, 'latestOffset': None, 'numInputRows': 360, 'inputRowsPerSecond': 119.76047904191617, 'processedRowsPerSecond': 215.8273381294964}], 'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}}\n",
            "aparando stream...\n",
            "\n",
            " cheque de Speed Layer ---\n",
            "Ruta: /content/datalake/gold/org_daily_usage_by_service_speed, Total acumulado en disco: 727\n",
            "funcionando todo OK (Datos persistidos correctamente)\n",
            "+------------+---------------+------------+--------------+--------------+---------------+----------+\n",
            "|org_id      |org_name       |service_name|daily_cost_usd|daily_requests|daily_carbon_kg|event_date|\n",
            "+------------+---------------+------------+--------------+--------------+---------------+----------+\n",
            "|org_pnsm43d8|Delta Labs 70  |compute     |11.6645       |130.0000      |0.026          |2025-08-13|\n",
            "|org_dhylurtp|Nimbus Cloud 76|compute     |11.9243       |133.0000      |0.0266         |2025-08-13|\n",
            "|org_5iqvnb4g|Gamma Labs 73  |networking  |0.0092        |0.0000        |2.05E-4        |2025-08-13|\n",
            "+------------+---------------+------------+--------------+--------------+---------------+----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "Streaming Speed → Gold parado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DEMO - Carga de datos a Cassandra"
      ],
      "metadata": {
        "id": "-JZbvhzQWt-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload_full_gold_layer(spark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "10903c2371044d25804b401aa6cb6b10",
            "925f118ca75b47ff81e370b235ddcfb6",
            "3430ea27cbd34811acb052ed48d94a40",
            "ae98d49192cb420cb3c29572dcaa0b20",
            "d47da7ff849b4fd6b1aa073cc7a55de1",
            "c5ff39f3201b422a8e05977dc39a8fb6",
            "fdcfd506f9424609abfc29f1ce011b26",
            "1870fd8469bc4f4c8f45d705e2d18239",
            "1e3ecb2be7254fbe84bacbe69ba8fe73",
            "f95d0b255c9c4893893cf8277e593752",
            "f6ba54ba546841b88f13500d1cbeff68",
            "5979a468e1b34e23b1acc074eb5f1796",
            "bf45724e343c43ea93abc95907dde768",
            "33d637ccac444ab595cc5c1753d28515",
            "2a26cd63eef14ab5b1c18e920ab5b66c",
            "9d4b3990e5ad4f9a9809e367ee6cf16e",
            "ee8cb8eabede405a9fc8b58866975489",
            "8851bf2e774f42da8a5b29f81c845421",
            "a3f30cfbcde94980a314fe719b85a91b",
            "ae070afceed24589a822fe9e8bfad8c3",
            "8261d50c577a41f5849fd1a1d8dcef92",
            "a49e443bc57a4814a7ff8f549274e847",
            "fd1abff492f8410fa5ec5e332b8f9687",
            "e235b6ab225449f092ce23bceab4935c",
            "793d04c5a53a4e17a36adfbf131235ff",
            "5e651c839caa455db7075feae03ae999",
            "c12de88866d64b8da11a886cdaa61a80",
            "a7af572ae32f40b0aaf32cd3375cde0c",
            "0c027d96a3914838b4229cf86f841b5d",
            "8666b7ea4b384f88bf4c2dec8560ed02",
            "5c80a8fd49ba42ab9b8fe2e386a931c4",
            "38f72e13ad49405094651e2bf525ce81",
            "6fab7253367d4e0ba51c7617d50ad158"
          ]
        },
        "id": "wDIovXdfoyH9",
        "outputId": "3aac2ac2-69c3-48a0-88f8-0cf9f676d173"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SERVING] Iniciando carga masiva a AstraDB...\n",
            "[CASSANDRA] Creando esquema en keyspace 'Cloud_analytics_db'...\n",
            "[CASSANDRA] Esquema verificado: 3 Tablas listas.\n",
            "   -> Cargando tabla 'org_daily_usage_by_service' (727 registros)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Subiendo org_daily_usage_by_service:   0%|          | 0/727 [00:00<?, ?rows/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10903c2371044d25804b401aa6cb6b10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      [OK] Carga completada.\n",
            "   -> Cargando tabla 'org_daily_support_metrics' (944 registros)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Subiendo org_daily_support_metrics:   0%|          | 0/944 [00:00<?, ?rows/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5979a468e1b34e23b1acc074eb5f1796"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      [OK] Carga completada.\n",
            "   -> Cargando tabla 'org_daily_genai_usage' (77 registros)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Subiendo org_daily_genai_usage:   0%|          | 0/77 [00:00<?, ?rows/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd1abff492f8410fa5ec5e332b8f9687"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      [OK] Carga completada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMO - Queries de Cassandra"
      ],
      "metadata": {
        "id": "I1KxlShlW4NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cassandra_queries.py\n",
        "import datetime\n",
        "\n",
        "def run_final_business_queries():\n",
        "    print(\"\\n queries de negocios\\n\")\n",
        "    session = get_cassandra_session()\n",
        "\n",
        "    # aca elije una org al azar para poder ejecutar multiples veces y asi mostrar que funciona\n",
        "\n",
        "    rows = session.execute(f'SELECT org_id FROM \"{KEYSPACE}\".org_daily_usage_by_service LIMIT 1000')\n",
        "    all_orgs = list(set([r.org_id for r in rows]))\n",
        "    TARGET_ORG = (random.sample(all_orgs, 1))[0]\n",
        "\n",
        "    print(f\"organizacion: {TARGET_ORG}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # QUERY 1: costos y requests diarios por org/servicio\n",
        "    print(\"\\n1. [FinOps] costos y requests de los ultimos 7 días\")\n",
        "    query_1 = f\"\"\"\n",
        "        SELECT usage_date, service_name, daily_cost_usd, daily_requests\n",
        "        FROM \"{KEYSPACE}\".org_daily_usage_by_service\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        LIMIT 10\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_1)\n",
        "    print(f\"{'fecha':<12} | {'servicio':<15} | {'costo ($)':<10} | {'requests'}\")\n",
        "    for r in rows:\n",
        "        print(f\"{str(r.usage_date):<12} | {r.service_name:<15} | {r.daily_cost_usd:<10.2f} | {int(r.daily_requests)}\")\n",
        "\n",
        "\n",
        "    # QUERY 2: top de servicios por costo acumulado de las últimas 2 semanas\n",
        "\n",
        "    # aca se traen los datos de la partición y suman en client-side agg\n",
        "    print(\"\\n2. [FinOps] Top 3 Servicios más costosos (acumulado)\")\n",
        "    query_2 = f\"\"\"\n",
        "        SELECT service_name, daily_cost_usd\n",
        "        FROM \"{KEYSPACE}\".org_daily_usage_by_service\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_2)\n",
        "\n",
        "    cost_map = {}\n",
        "    for r in rows:\n",
        "        cost_map[r.service_name] = cost_map.get(r.service_name, 0.0) + r.daily_cost_usd\n",
        "\n",
        "    sorted_services = sorted(cost_map.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "    print(f\"{'servicio':<15} | {'costo total ($)'}\")\n",
        "    for svc, cost in sorted_services:\n",
        "        print(f\"{svc:<15} | {cost:.2f}\")\n",
        "\n",
        "\n",
        "    # QUERY 3:  evolucion tickets críticos y SLA breach ---\n",
        "    print(\"\\n3. [Soporte] historial de tickets criticos y SLA breaches\")\n",
        "    query_3 = f\"\"\"\n",
        "        SELECT ticket_date, critical_tickets, sla_breached_count\n",
        "        FROM \"{KEYSPACE}\".org_daily_support_metrics\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        LIMIT 5\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_3)\n",
        "\n",
        "    # fallback para lademo por si no existen tickets\n",
        "    if not rows:\n",
        "        print(\"(La org seleccionada no tiene tickets, probando query general...)\")\n",
        "        # NOTA: Esto es solo para demo, en prod usaríamos Partition Key siempre\n",
        "        rows = session.execute(f'SELECT org_id, ticket_date, critical_tickets FROM \"{KEYSPACE}\".org_daily_support_metrics LIMIT 5')\n",
        "\n",
        "    print(f\"{'fecha':<12} | {'criticos':<8} | {'SLA breached'}\")\n",
        "    for r in rows:\n",
        "        # Manejo flexible por si saltó al fallback\n",
        "        d_date = str(getattr(r, 'ticket_date', 'N/A'))\n",
        "        print(f\"{d_date:<12} | {r.critical_tickets:<8} | {getattr(r, 'sla_breached_count', '-')}\")\n",
        "\n",
        "\n",
        "    # QUERY 4: entrada mensual estimada\n",
        "    '''\n",
        "    Esto lo pondra la gente de finanzas, pero asumo que la\n",
        "    entrada es la suma de costos + impuestos . Le meti 21% por IVA como ejemplo\n",
        "    '''\n",
        "    print(\"\\n4. [Finanzas] entrada mensual estimado (+IVA)\")\n",
        "    # uso los datos de la query 2 para no hacer otra\n",
        "    total_net = sum(cost_map.values())\n",
        "    total_gross = total_net * 1.21\n",
        "    print(f\"total neto:      ${total_net:.2f}\")\n",
        "    print(f\"total bruto (est): ${total_gross:.2f}\")\n",
        "\n",
        "\n",
        "    # QUERY 5: consumo GenAI (Tokens/Requests) ---\n",
        "    # Tome a los requests como tokens de uso de IA\n",
        "    print(\"\\n5. [Producto] consumo de GenAI\")\n",
        "    query_5 = f\"\"\"\n",
        "        SELECT event_date, service_name, genai_requests_count, genai_daily_cost\n",
        "        FROM \"{KEYSPACE}\".org_daily_genai_usage\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        LIMIT 5\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_5)\n",
        "\n",
        "    # Fallback si no tiene GenAI\n",
        "    if not rows:\n",
        "         rows = session.execute(f'SELECT org_id, event_date, genai_requests_count FROM \"{KEYSPACE}\".org_daily_genai_usage LIMIT 5')\n",
        "    print(f\"{'fecha':<12} | {'modelo/serv':<12} | {'requests':<10} | {'costo ($)'}\")\n",
        "    for r in rows:\n",
        "        s_name = getattr(r, 'service_name', 'genai')\n",
        "        cost = getattr(r, 'genai_daily_cost', 0.0)\n",
        "        print(f\"{str(r.event_date):<12} | {s_name:<12} | {int(r.genai_requests_count):<10} | {cost:.2f}\")\n",
        "\n",
        "    session.shutdown()\n",
        "\n",
        "\n",
        "run_final_business_queries()"
      ],
      "metadata": {
        "id": "L555sppu2hJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f3b5f6-b362-4c76-c41b-cae2274eea4b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " queries de negocios\n",
            "\n",
            "organizacion: org_i3qk2iag\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. [FinOps] costos y requests de los ultimos 7 días\n",
            "fecha        | servicio        | costo ($)  | requests\n",
            "2025-08-31   | genai           | 1.95       | 0\n",
            "2025-08-31   | storage         | 0.03       | 0\n",
            "2025-08-22   | genai           | 0.16       | 0\n",
            "2025-08-13   | compute         | 0.80       | 0\n",
            "2025-08-12   | compute         | 8.05       | 113\n",
            "2025-08-04   | genai           | 14.68      | 122\n",
            "2025-08-01   | storage         | 0.08       | 0\n",
            "2025-07-23   | storage         | 2.20       | 125\n",
            "2025-07-19   | genai           | 0.50       | 0\n",
            "2025-07-14   | storage         | 0.00       | 0\n",
            "\n",
            "2. [FinOps] Top 3 Servicios más costosos (acumulado)\n",
            "servicio        | costo total ($)\n",
            "genai           | 17.29\n",
            "compute         | 8.85\n",
            "storage         | 2.31\n",
            "\n",
            "3. [Soporte] historial de tickets criticos y SLA breaches\n",
            "fecha        | criticos | SLA breached\n",
            "2025-08-19   | 0        | 0\n",
            "2025-08-14   | 0        | 0\n",
            "2025-07-28   | 0        | 0\n",
            "2025-07-19   | 0        | 0\n",
            "2025-07-17   | 0        | 0\n",
            "\n",
            "4. [Finanzas] entrada mensual estimado (+IVA)\n",
            "total neto:      $28.45\n",
            "total bruto (est): $34.43\n",
            "\n",
            "5. [Producto] consumo de GenAI\n",
            "fecha        | modelo/serv  | requests   | costo ($)\n",
            "2025-08-31   | genai        | 0          | 1.95\n",
            "2025-08-22   | genai        | 0          | 0.16\n",
            "2025-08-04   | genai        | 122        | 14.68\n",
            "2025-07-19   | genai        | 0          | 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMO - Posible Dashboard"
      ],
      "metadata": {
        "id": "0bI4YPakW8Qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "\n",
        "# --- FUNCION DE DATOS ---\n",
        "def get_premium_dashboard_data(org_id, date_start, date_end):\n",
        "    print(f\"[UI] Creando Dashboard de: {org_id}...\")\n",
        "\n",
        "    # validacion de fechas\n",
        "    if not date_start or not date_end:\n",
        "        date_start = \"2020-01-01\"\n",
        "        date_end = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "    session = get_cassandra_session()\n",
        "\n",
        "    # FINOPS\n",
        "    q_finops = f\"SELECT usage_date, service_name, daily_cost_usd FROM \\\"{KEYSPACE}\\\".org_daily_usage_by_service WHERE org_id = '{org_id}'\"\n",
        "    rows_finops = list(session.execute(q_finops))\n",
        "\n",
        "    # procesamiento en pandas\n",
        "    if rows_finops:\n",
        "        df_finops = pd.DataFrame([r._asdict() for r in rows_finops])\n",
        "        df_finops['usage_date'] = pd.to_datetime(df_finops['usage_date'].astype(str))\n",
        "        df_finops['daily_cost_usd'] = df_finops['daily_cost_usd'].astype(float)\n",
        "\n",
        "        #filtro de fecha\n",
        "        mask = (df_finops['usage_date'] >= pd.to_datetime(date_start)) & (df_finops['usage_date'] <= pd.to_datetime(date_end))\n",
        "        df_finops = df_finops.loc[mask]\n",
        "\n",
        "        # graf1: Area Chart acumulada (Plotly)\n",
        "        fig_finops_trend = px.area(df_finops, x=\"usage_date\", y=\"daily_cost_usd\", color=\"service_name\",\n",
        "                                   title=\"Evolución de costos por servicio\",\n",
        "                                   labels={\"daily_cost_usd\": \"Costo (USD)\", \"usage_date\": \"Fecha\"})\n",
        "\n",
        "        # graf2: Donut Chart\n",
        "        df_grouped = df_finops.groupby(\"service_name\")[\"daily_cost_usd\"].sum().reset_index()\n",
        "        fig_finops_dist = px.pie(df_grouped, values=\"daily_cost_usd\", names=\"service_name\", hole=0.4,\n",
        "                                 title=\"distribucion del Gasto Total\")\n",
        "    else:\n",
        "        fig_finops_trend = px.line(title=\"sin datos de costos\")\n",
        "        fig_finops_dist = px.pie(title=\"sin datos\")\n",
        "\n",
        "    # SUPPORT\n",
        "    q_supp = f\"SELECT ticket_date, total_tickets, sla_breached_count, critical_tickets FROM \\\"{KEYSPACE}\\\".org_daily_support_metrics WHERE org_id = '{org_id}'\"\n",
        "    rows_supp = list(session.execute(q_supp))\n",
        "\n",
        "    if rows_supp:\n",
        "        df_supp = pd.DataFrame([r._asdict() for r in rows_supp])\n",
        "        df_supp['ticket_date'] = pd.to_datetime(df_supp['ticket_date'].astype(str))\n",
        "\n",
        "        # Filtro fecha\n",
        "        mask = (df_supp['ticket_date'] >= pd.to_datetime(date_start)) & (df_supp['ticket_date'] <= pd.to_datetime(date_end))\n",
        "        df_supp = df_supp.loc[mask].sort_values(\"ticket_date\")\n",
        "\n",
        "        # Graf Combinado\n",
        "        fig_supp = go.Figure()\n",
        "        # graf total tickets\n",
        "        fig_supp.add_trace(go.Bar(x=df_supp['ticket_date'], y=df_supp['total_tickets'], name='Total Tickets', marker_color='lightblue'))\n",
        "        # graf SLA Breaches\n",
        "        fig_supp.add_trace(go.Scatter(x=df_supp['ticket_date'], y=df_supp['sla_breached_count'], name='SLA Breaches', line=dict(color='red', width=3)))\n",
        "\n",
        "        fig_supp.update_layout(title=\"Volumen de soporte vs calidad\", xaxis_title=\"Fecha\", yaxis_title=\"Cantidad\")\n",
        "    else:\n",
        "        fig_supp = px.bar(title=\"Sin datos de soporte\")\n",
        "\n",
        "    # GENAI\n",
        "\n",
        "    q_genai = f\"SELECT event_date, service_name, genai_daily_cost, genai_requests_count FROM \\\"{KEYSPACE}\\\".org_daily_genai_usage WHERE org_id = '{org_id}'\"\n",
        "    rows_genai = list(session.execute(q_genai))\n",
        "\n",
        "    if rows_genai:\n",
        "        df_genai = pd.DataFrame([r._asdict() for r in rows_genai])\n",
        "        df_genai['event_date'] = pd.to_datetime(df_genai['event_date'].astype(str))\n",
        "\n",
        "        # Filtro fecha\n",
        "        mask = (df_genai['event_date'] >= pd.to_datetime(date_start)) & (df_genai['event_date'] <= pd.to_datetime(date_end))\n",
        "        df_genai = df_genai.loc[mask]\n",
        "\n",
        "        # Scatter Plot: Relación Costo vs Requests\n",
        "        # Tamaño de burbuja = Costo\n",
        "        fig_genai = px.scatter(df_genai, x=\"event_date\", y=\"genai_requests_count\", size=\"genai_daily_cost\", color=\"service_name\",\n",
        "                               title=\"IA: requests vs costo\",\n",
        "                               labels={\"genai_requests_count\": \"Cant. Requests\", \"event_date\": \"Fecha\"})\n",
        "    else:\n",
        "        fig_genai = px.scatter(title=\"sin datos de GenAI\")\n",
        "\n",
        "    session.shutdown()\n",
        "\n",
        "    summary = f\"### analizando {org_id}\\ndesde {date_start} hasta {date_end}.\"\n",
        "\n",
        "    return summary, fig_finops_trend, fig_finops_dist, fig_supp, fig_genai\n",
        "\n",
        "\n",
        "# ui\n",
        "\n",
        "# Carga inicial de lista de orgs (si no existe)\n",
        "try:\n",
        "    if not unique_orgs: raise ValueError\n",
        "except:\n",
        "    print(\"[UI] cargando clientes...\")\n",
        "    session = get_cassandra_session()\n",
        "    rows = session.execute(f'SELECT org_id FROM \\\"{KEYSPACE}\\\".org_daily_usage_by_service LIMIT 300')\n",
        "    unique_orgs = sorted(list(set([r.org_id for r in rows])))\n",
        "    session.shutdown()\n",
        "\n",
        "# layout\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# 🚀 Cloud Analytics 360° Dashboard\")\n",
        "    gr.Markdown(\"Visión integral: Finanzas, Operaciones e Innovación.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # panel de control del dashboard\n",
        "        with gr.Column(scale=1, variant=\"panel\"):\n",
        "            gr.Markdown(\"### 🎛️ Filtros\")\n",
        "            dd_org = gr.Dropdown(choices=unique_orgs, label=\"cliente\", value=unique_orgs[0] if unique_orgs else None)\n",
        "            # selectores de fecha\n",
        "            date_start = gr.Textbox(label=\"Fecha Inicio (YYYY-MM-DD)\", value=\"2025-06-01\")\n",
        "            date_end = gr.Textbox(label=\"Fecha Fin (YYYY-MM-DD)\", value=\"2025-12-31\")\n",
        "\n",
        "            btn_run = gr.Button(\"actualizar\", variant=\"primary\")\n",
        "            lbl_status = gr.Markdown(\"Listo para consultar.\")\n",
        "\n",
        "        # Panel de grafsl\n",
        "        with gr.Column(scale=4):\n",
        "            with gr.Tabs():\n",
        "                with gr.TabItem(\"FinOps\"):\n",
        "                    with gr.Row():\n",
        "                        plot_finops_trend = gr.Plot(label=\"tendencia\")\n",
        "                        plot_finops_dist = gr.Plot(label=\"fistribucion\")\n",
        "\n",
        "                with gr.TabItem(\"Soporte & SLAs\"):\n",
        "                    plot_supp = gr.Plot(label=\"metricas de soporte\")\n",
        "                    gr.Markdown(\"*Nota: La línea roja indica incumplimientos de contrato (SLA Breaches).*\")\n",
        "\n",
        "                with gr.TabItem(\"GenAI \"):\n",
        "                    plot_genai = gr.Plot(label=\"consumo IA\")\n",
        "\n",
        "\n",
        "    btn_run.click(\n",
        "        fn=get_premium_dashboard_data,\n",
        "        inputs=[dd_org, date_start, date_end],\n",
        "        outputs=[lbl_status, plot_finops_trend, plot_finops_dist, plot_supp, plot_genai]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "dg5cIF3nStUx",
        "outputId": "734d41a4-f002-43d2-9c3d-c3dff757e657"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2986554430.py:109: DeprecationWarning:\n",
            "\n",
            "The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://65d21a64220c06f292.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://65d21a64220c06f292.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://65d21a64220c06f292.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}