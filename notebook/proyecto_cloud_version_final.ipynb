{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0ApXM5Cdb7s"
      },
      "source": [
        "# **MVP FINAL**\n",
        "\n",
        "# Materia: Mineria de datos II\n",
        "\n",
        "# Alumno: Emilio Gomez Lencina\n",
        "\n",
        "---\n",
        "\n",
        "# ***Pipelines***\n",
        "\n",
        "# (1) Batch\n",
        "\n",
        "Landing ----batch---->Bronze (csv)--->Silver---> Gold ---> Serving (cassandra)\n",
        "\n",
        "# (2) Stream\n",
        "\n",
        "Landing ----speed----> Bronze (jsonl)--->Silver --> gold (stream) --->Serving (Cassandra)\n",
        "\n",
        "# (3) Queries de cassandra\n",
        "---\n",
        "\n",
        "Resumen de la implementacion\n",
        "\n",
        "*Cada celda (con excepcion de los demos) corresponde a un archivo .py que eventualmente va a estar en el repo final al moment ode la entrega final.\n",
        "\n",
        "Por eso, se usaron parches como:\n",
        "\n",
        "```\n",
        "try:\n",
        "    from cassandra_utils import get_cassandra_session, KEYSPACE\n",
        "except ModuleNotFoundError:\n",
        "    pass\n",
        "```\n",
        "En el archivo .py solo va a estar la llamada a cassandra_utils, pero como en el colab no es necesario, epuse ese parchecito temporal solo al efecto de la dentrega de este MVP.\n",
        "\n",
        "---\n",
        "Este notebook contiene un end-to-end que incluye:\n",
        "\n",
        "    *implementacion de left anti joins para manejo de cuarentena (evitando duplicidad de errores) y estrategias de escritura segura.\n",
        "\n",
        "    *reglas de de negocio activas (costos negativos, integridad referencial) y desvío automático a zona de Quarantine.\n",
        "\n",
        "    *ptimizaciones Spark: Configuracion de shuffle.partitions para entorno local/Colab y uso de broadcast joins.\n",
        "\n",
        "    -*streaming con watermarking, dedupe y checkpointing para tolerancia a fallos.\n",
        "\n",
        "    *serving Layer: conexin a AstraDB (Cassandra) con modelado Query-First.\n",
        "\n",
        "\n",
        "Laburo completo aca ----->[Repositorio GitHub (Código + Readme + Diagramas) ](https://github.com/Sinnick4r/Cloud_Provider_Analytics_MVP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhvkQcDIUZHA"
      },
      "source": [
        "# CONFIG.PY\n",
        "\n",
        "Funciones respecto a archivos y directorios\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoFQX0L9WjOk",
        "outputId": "3a485815-4fe4-4130-9e4c-bd9ce4657a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.29.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting geomet>=1.1 (from cassandra-driver)\n",
            "  Downloading geomet-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from geomet>=1.1->cassandra-driver) (8.3.1)\n",
            "Downloading cassandra_driver-3.29.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geomet-1.1.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: geomet, cassandra-driver\n",
            "Successfully installed cassandra-driver-3.29.3 geomet-1.1.0\n",
            "Collecting astrapy\n",
            "  Downloading astrapy-2.1.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: deprecation~=2.1.0 in /usr/local/lib/python3.12/dist-packages (from astrapy) (2.1.0)\n",
            "Requirement already satisfied: h11>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from astrapy) (0.16.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (0.28.1)\n",
            "Collecting pymongo>=3 (from astrapy)\n",
            "  Downloading pymongo-4.15.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: toml<1.0.0,>=0.10.2 in /usr/local/lib/python3.12/dist-packages (from astrapy) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.12/dist-packages (from astrapy) (4.15.0)\n",
            "Collecting uuid6>=2024.1.12 (from astrapy)\n",
            "  Downloading uuid6-2025.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from deprecation~=2.1.0->astrapy) (25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (3.11)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (4.3.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3->astrapy)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy) (4.1.0)\n",
            "Downloading astrapy-2.1.0-py3-none-any.whl (333 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.5/333.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.15.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uuid6-2025.0.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uuid6, dnspython, pymongo, astrapy\n",
            "Successfully installed astrapy-2.1.0 dnspython-2.8.0 pymongo-4.15.5 uuid6-2025.0.1\n",
            "Requirement already satisfied: Plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from Plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from Plotly) (25.0)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "#por si no estan insalados en la ejecucion de colab, voy a lo seguro\n",
        "!pip install cassandra-driver\n",
        "!pip install astrapy\n",
        "!pip install Plotly\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cUEIwMsZ5wJ8"
      },
      "outputs": [],
      "source": [
        "# config.py\n",
        "from __future__ import annotations\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from typing import Final\n",
        "from datetime import datetime\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "\n",
        "# integracion con google drive que estuve usando, se puede poner true o false\n",
        "\n",
        "USE_GOOGLE_DRIVE: Final[bool] = False\n",
        "GOOGLE_DRIVE_PROJECT_SUBDIR: Final[str] = \"Mineria de datos II/Proyecto Cloud Provider Analysis\"\n",
        "\n",
        "\n",
        "\n",
        "def get_project_root() -> Path:\n",
        "    \"\"\"\n",
        "    Devuelve la raíz del proyecto.\n",
        "    - so USE_GOOGLE_DRIVE es true, monta gdrive en Colab y usa la carpeta indicada.\n",
        "    - si es Ffalse, usa el directorio actual (repo descomprimido).\n",
        "    \"\"\"\n",
        "    if USE_GOOGLE_DRIVE:\n",
        "        try:\n",
        "            from google.colab import drive as gdrive\n",
        "        except ImportError as exc:\n",
        "            raise RuntimeError(\n",
        "                \"USE_GOOGLE_DRIVE=True pero no esamos en colab.\"\n",
        "            ) from exc\n",
        "\n",
        "        gdrive.mount(\"/content/drive\")\n",
        "        return (Path(\"/content/drive/MyDrive\") / GOOGLE_DRIVE_PROJECT_SUBDIR).resolve()\n",
        "\n",
        "    return Path(\".\").resolve()\n",
        "\n",
        "#aca van loss directorios de todo el proyecto\n",
        "\n",
        "PROJECT_ROOT: Final[Path] = get_project_root()\n",
        "DATA_DIR: Final[Path] = PROJECT_ROOT / \"data\"\n",
        "DATALAKE_ROOT: Final[Path] = PROJECT_ROOT / \"datalake\"\n",
        "\n",
        "LANDING_PATH: Final[Path] = DATALAKE_ROOT / \"landing\"\n",
        "BRONZE_PATH: Final[Path] = DATALAKE_ROOT / \"bronze\"\n",
        "SILVER_PATH: Final[Path] = DATALAKE_ROOT / \"silver\"\n",
        "GOLD_PATH: Final[Path] = DATALAKE_ROOT / \"gold\"\n",
        "QUARANTINE_PATH: Final[Path] = DATALAKE_ROOT / \"quarantine\"\n",
        "\n",
        "RAW_ZIP_NAME: Final[str] = \"cloud_provider_challenge_dataset_v1.zip\"\n",
        "\n",
        "\n",
        "# sesion de spark\n",
        "\n",
        "def create_spark(app_name: str = \"CloudProviderAnalytics_Pipeline\") -> SparkSession:\n",
        "    spark = (\n",
        "        SparkSession.builder\n",
        "        .appName(app_name)\n",
        "        .master(\"local[*]\")\n",
        "        .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
        "        .getOrCreate()\n",
        "    )\n",
        "    spark.sparkContext.setLogLevel(\"WARN\")\n",
        "    return spark\n",
        "\n",
        "\n",
        "# utils de archivos/directorios\n",
        "\n",
        "def ensure_dirs() -> None:\n",
        "# Crea la estructura del datalake si no existe.\n",
        "    for path in (LANDING_PATH, BRONZE_PATH, SILVER_PATH, GOLD_PATH, QUARANTINE_PATH):\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def unpack_raw_dataset() -> None:\n",
        "\n",
        "    #descomprime el zip del datalake\n",
        "    zip_path = DATA_DIR / RAW_ZIP_NAME\n",
        "\n",
        "    if not zip_path.exists():\n",
        "        print(f\"[WARN] No se encontró el ZIP de datos en {zip_path}. Saltando unpack.\")\n",
        "        return\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
        "        zf.extractall(PROJECT_ROOT)\n",
        "    print(f\"[OK] Dataset descomprimido en {PROJECT_ROOT / 'datalake' / 'landing'}\")\n",
        "\n",
        "\n",
        "'''\n",
        "esta funcion log la hice para otro proyecto hace mucho, la uso aca solo para que\n",
        "el resultado de la consola sea visualmente mas agradable en el ideo de presentacion\n",
        "'''\n",
        "def log(msg: str, level: str = \"INFO\"):\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\", # Azul\n",
        "        \"WARN\": \"\\033[93m\", # Amarillo\n",
        "        \"ERR\":  \"\\033[91m\", # Rojo\n",
        "        \"OK\":   \"\\033[92m\", # Verde\n",
        "        \"RUN\":   \"\\033[96m\", # Cyan\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    color = colors.get(level, colors[\"RESET\"])\n",
        "    print(f\"{color}[{timestamp}] [{level}] {msg}{colors['RESET']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4RBex6bUnvi"
      },
      "source": [
        "# schemas.py\n",
        "\n",
        "Schemas estaticos para spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "123EkT026xiE"
      },
      "outputs": [],
      "source": [
        "# schemas.py\n",
        "\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Final\n",
        "from pyspark.sql import types as T\n",
        "\n",
        "\n",
        "# Esquemascsv y json totalmente manuales despeus de chequearlos\n",
        "\n",
        "customers_orgs_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_name\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"industry\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"hq_region\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"plan_tier\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"is_enterprise\", T.BooleanType(), nullable=True),\n",
        "    T.StructField(\"signup_date\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"sales_rep\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"lifecycle_stage\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"marketing_source\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"nps_score\", T.DoubleType(), nullable=True),\n",
        "])\n",
        "\n",
        "users_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"user_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"email\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"role\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"active\", T.BooleanType(), nullable=True),\n",
        "    T.StructField(\"created_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"last_login\", T.DateType(), nullable=True),\n",
        "])\n",
        "\n",
        "resources_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"resource_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"service\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"region\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"created_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"state\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"tags_json\", T.StringType(), nullable=True),\n",
        "])\n",
        "\n",
        "support_tickets_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"ticket_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"category\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"severity\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"created_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"resolved_at\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"csat\", T.DoubleType(), nullable=True),\n",
        "    T.StructField(\"sla_breached\", T.BooleanType(), nullable=True),\n",
        "])\n",
        "\n",
        "marketing_touches_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"touch_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"campaign\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"channel\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"timestamp\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"clicked\", T.BooleanType(), nullable=True),\n",
        "    T.StructField(\"converted\", T.BooleanType(), nullable=True),\n",
        "])\n",
        "\n",
        "nps_surveys_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"survey_date\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"nps_score\", T.DoubleType(), nullable=True),\n",
        "    T.StructField(\"comment\", T.StringType(), nullable=True),\n",
        "])\n",
        "\n",
        "billing_monthly_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"invoice_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"month\", T.DateType(), nullable=True),\n",
        "    T.StructField(\"subtotal\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"credits\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"taxes\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"currency\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"exchange_rate_to_usd\", T.DoubleType(), nullable=True),\n",
        "])\n",
        "\n",
        "\n",
        "usage_events_schema: Final[T.StructType] = T.StructType([\n",
        "    T.StructField(\"event_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"timestamp\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"org_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"resource_id\", T.StringType(), nullable=False),\n",
        "    T.StructField(\"service\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"region\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"metric\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"value\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"unit\", T.StringType(), nullable=True),\n",
        "    T.StructField(\"cost_usd_increment\", T.DecimalType(10,4), nullable=True),\n",
        "    T.StructField(\"schema_version\", T.IntegerType(), nullable=True),\n",
        "    T.StructField(\"carbon_kg\", T.DoubleType(), nullable=True),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxijlygHUw6g"
      },
      "source": [
        "# io_utils.py\n",
        "\n",
        "Funciones de lecto-escritura de CSV y Parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bAWzeQUf8ho2"
      },
      "outputs": [],
      "source": [
        "# io_utils.py\n",
        "\n",
        "from __future__ import annotations\n",
        "from pathlib import Path\n",
        "from typing import Final\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import types as T\n",
        "\n",
        "\n",
        "# helpers de rutas genéricos\n",
        "\n",
        "def zone_path(zone_root: Path, table_name: str) -> Path:\n",
        "    \"\"\"\n",
        "    Devuelve la ruta completa a una tabla dentro de una zona del datalake.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return (zone_root / table_name).resolve()\n",
        "\n",
        "\n",
        "def add_audit_columns(df: DataFrame) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Enriquece un DataFrame con columnas técnicas de auditoría:\n",
        "    - ingest_ts: Timestamp de ingestión\n",
        "    - source_file: Nombre del archivo origen\n",
        "    \"\"\"\n",
        "    return df.withColumn(\"ingest_ts\", F.current_timestamp()) \\\n",
        "             .withColumn(\"source_file\", F.input_file_name())\n",
        "\n",
        "\n",
        "def read_csv(\n",
        "    spark: SparkSession,\n",
        "    path: Path,\n",
        "    schema: T.StructType,\n",
        "    header: bool = True,\n",
        ") -> DataFrame:\n",
        "\n",
        "    return (\n",
        "        spark.read\n",
        "        .option(\"header\", str(header).lower())\n",
        "        .schema(schema)\n",
        "        .csv(str(path))\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def write_parquet(\n",
        "    df: DataFrame,\n",
        "    base_path: Path,\n",
        "    partition_cols: list[str] | None = None,\n",
        "    mode: str = \"overwrite\",\n",
        ") -> None:\n",
        "\n",
        "    writer = df.write.mode(mode)\n",
        "    if partition_cols:\n",
        "        writer = writer.partitionBy(*partition_cols)\n",
        "    writer.parquet(str(base_path))\n",
        "\n",
        "\n",
        "def read_parquet(spark, base_path, partition_glob: str | None = None):\n",
        "\n",
        "    #lee un Parquet\n",
        "    #si no hay partition_glob lee la ruta / si hay artition_glob usa basePath y patron\n",
        "\n",
        "    base_path = Path(base_path)\n",
        "    base_str = str(base_path)\n",
        "\n",
        "    if partition_glob:\n",
        "        return (\n",
        "            spark.read\n",
        "                 .option(\"basePath\", base_str)\n",
        "                 .parquet(f\"{base_str}/{partition_glob}\")\n",
        "        )\n",
        "\n",
        "    return spark.read.parquet(base_str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoA1xFZ9U7Fk"
      },
      "source": [
        "# audit.py\n",
        "\n",
        "Funciones de chequeo de Quality de cada fase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-HWtT_Wua_KS"
      },
      "outputs": [],
      "source": [
        "# audit.py\n",
        "from __future__ import annotations\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "\n",
        "# Esto solo esta en el colab, en el codigo definitivo solo se importa\n",
        "try:\n",
        "    from config import BRONZE_PATH, SILVER_PATH, GOLD_PATH, QUARANTINE_PATH\n",
        "    from io_utils import read_parquet, zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    BRONZE_PATH = _m.BRONZE_PATH\n",
        "    SILVER_PATH = _m.SILVER_PATH\n",
        "    GOLD_PATH = _m.GOLD_PATH\n",
        "    QUARANTINE_PATH = _m.QUARANTINE_PATH\n",
        "    read_parquet = _m.read_parquet\n",
        "    zone_path = _m.zone_path\n",
        "\n",
        "\n",
        "def audit_bronze_layer(spark: SparkSession, table_name: str, pk_col: str) -> None:\n",
        "\n",
        "    # se chequea vol, uni de PK y el llenado con ingest_ts\n",
        "\n",
        "    print(f\"\\n chequeo Bronze: {table_name}\")\n",
        "\n",
        "    path = zone_path(BRONZE_PATH, table_name)\n",
        "    try:\n",
        "        df = read_parquet(spark, path)\n",
        "    except AnalysisException:\n",
        "        print(f\"[ERR] no se encontro la tabla en {path}\")\n",
        "        return\n",
        "\n",
        "    # Vol\n",
        "    count_total = df.count()\n",
        "\n",
        "    # Uni\n",
        "    count_distinct = df.select(pk_col).distinct().count()\n",
        "    duplicates = count_total - count_distinct\n",
        "\n",
        "    # ingest_ts\n",
        "    if \"ingest_ts\" in df.columns:\n",
        "        null_tech = df.filter(F.col(\"ingest_ts\").isNull()).count()\n",
        "    else:\n",
        "        null_tech = \"falta columna ingest_ts\"\n",
        "\n",
        "    print(f\"registros totales: {count_total}\")\n",
        "    print(f\"duplicados en PK ({pk_col}): {duplicates}\")\n",
        "    print(f\"nulos en ingest_ts: {null_tech}\")\n",
        "\n",
        "    # Resulktado\n",
        "    if duplicates == 0 and (isinstance(null_tech, int) and null_tech == 0):\n",
        "        print(\"Resultado: todo ok!!\")\n",
        "    else:\n",
        "        print(\"Resultado: revisar data por posibles duplicados \")\n",
        "\n",
        "\n",
        "def audit_silver_quality(spark: SparkSession) -> None:\n",
        "\n",
        "    #Chequea el resultado del proceso Silver Batch, calculando un ratio entre registros en Silver vs Cuarentena\n",
        "    print(f\"\\n Chequeop Silver:\")\n",
        "\n",
        "    path_good = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    path_bad  = zone_path(QUARANTINE_PATH, \"usage_events_quarantine\")\n",
        "\n",
        "    # contar buenos\n",
        "    try:\n",
        "        good_df = read_parquet(spark, path_good)\n",
        "        count_good = good_df.count()\n",
        "    except AnalysisException:\n",
        "        count_good = 0\n",
        "\n",
        "    # contar malos\n",
        "    try:\n",
        "        bad_df = read_parquet(spark, path_bad)\n",
        "        count_bad = bad_df.count()\n",
        "        has_bad = True\n",
        "    except AnalysisException:\n",
        "        count_bad = 0\n",
        "        has_bad = False\n",
        "\n",
        "    total = count_good + count_bad\n",
        "    if total == 0:\n",
        "        print(\"[WARN] No hay datos procesados en Silver ni cuarentena.\")\n",
        "        return\n",
        "\n",
        "    bad_ratio = (count_bad / total) * 100\n",
        "\n",
        "    print(f\"Total: {total}\")\n",
        "    print(f\"Aceptados (Silver): {count_good}\")\n",
        "    print(f\"Rechazados (cuarentena): {count_bad} ({bad_ratio:.2f}%)\")\n",
        "\n",
        "    if bad_ratio == 0:\n",
        "        print(\"CALIDAD: PERFECTA\")\n",
        "    elif bad_ratio < 5:\n",
        "        print(\"CALIDAD: ACEPTABLE\")\n",
        "    else:\n",
        "        print(\"CALIDAD: CRÍTICA (>5% Rechazo). Revisar reglas de negocio.\")\n",
        "\n",
        "    if has_bad:\n",
        "        print(\"ejemplo de rechazo:\")\n",
        "        bad_df.select(\"event_id\", \"quarantine_reason\").show(1, truncate=False)\n",
        "\n",
        "\n",
        "def audit_gold_layer(spark: SparkSession, table_name: str, check_col: str = \"daily_cost_usd\") -> None:\n",
        "\n",
        "    #Audita un Mart Gold verificando reglas de negocio para serving layer: Vol, Integridad y KPIs\n",
        "    print(f\"\\n Chequeo Gold: {table_name}\")\n",
        "\n",
        "    path = zone_path(GOLD_PATH, table_name)\n",
        "    try:\n",
        "        # Intentamos leer con wildcards para atrapar cualquier partición (event_date, ticket_date, etc.)\n",
        "        # El truco es usar recursiveFileLookup o simplemente leer la carpeta raíz\n",
        "        df = spark.read.option(\"basePath\", str(path)).parquet(str(path / \"*\"))\n",
        "    except AnalysisException:\n",
        "        try:\n",
        "            # Fallback: leer la raíz directa (a veces funciona mejor en local)\n",
        "            df = spark.read.parquet(str(path))\n",
        "        except AnalysisException:\n",
        "            print(f\"   [ERR] No se encontró el mart en {path}\")\n",
        "            return\n",
        "\n",
        "    count_total = df.count()\n",
        "\n",
        "    # Regla: Costos Negativos\n",
        "    neg_costs = df.filter(F.col(check_col) < 0).count()\n",
        "\n",
        "    print(f\"registros Totales (Agregados): {count_total}\")\n",
        "    print(f\"Costos Negativos detectados: {neg_costs}\")\n",
        "\n",
        "def audit_quarantine(spark: SparkSession):\n",
        "    print(f\"\\nCalidad de Datos (Silver Batch)\")\n",
        "\n",
        "    path_good = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    path_bad  = zone_path(QUARANTINE_PATH, \"usage_events_quarantine\")\n",
        "\n",
        "    # conteo de datos buenos\n",
        "    try:\n",
        "        good_df = read_parquet(spark, path_good)\n",
        "        count_good = good_df.count()\n",
        "    except AnalysisException:\n",
        "        count_good = 0\n",
        "        print(\"[WARN] No hay data en Silver.\")\n",
        "\n",
        "    # conteo  malos\n",
        "    try:\n",
        "        bad_df = read_parquet(spark, path_bad)\n",
        "        count_bad = bad_df.count()\n",
        "        has_bad_data = True\n",
        "    except AnalysisException:\n",
        "        count_bad = 0\n",
        "        has_bad_data = False\n",
        "        print(\"[INFO] No hay data en cuarentena\")\n",
        "\n",
        "    # ratio\n",
        "    total = count_good + count_bad\n",
        "    if total == 0:\n",
        "        print(\"[ERR] No hay data procesada\")\n",
        "        return\n",
        "\n",
        "    bad_ratio = (count_bad / total) * 100\n",
        "\n",
        "    print(f\"\\n Estadisticas:\")\n",
        "    print(f\"Total Procesado: {total}\")\n",
        "    print(f\"Aceptados (Silver): {count_good} ({(100 - bad_ratio):.2f}%)\")\n",
        "    print(f\"Rechazados (Quarantine): {count_bad} ({bad_ratio:.2f}%)\")\n",
        "\n",
        "    print(\"\\nresultado:\")\n",
        "\n",
        "    if bad_ratio == 0:\n",
        "        print(\"Satifactorio - sin datos rechazados\")\n",
        "    elif bad_ratio < 5:\n",
        "        print(\"Aceptable- rechazo  bajo y esperado.\")\n",
        "    else:\n",
        "        print(\"malo -demasiada data rechazada (>5%)\")\n",
        "\n",
        "    # muestra errores\n",
        "    if has_bad_data:\n",
        "        print(\"\\n Muestra de registros en Cuarentena (top 5):\")\n",
        "        cols_to_show = [\"event_id\", \"cost_usd_increment\", \"org_id\", \"quarantine_reason\"]\n",
        "        actual_cols = [c for c in cols_to_show if c in bad_df.columns]\n",
        "        bad_df.select(*actual_cols).show(5, truncate=False)\n",
        "\n",
        "\n",
        "def audit_speed_layer_results(spark: SparkSession):\n",
        "\n",
        "    #aca se chequea que la Speed Layer haya persistido datos en disco.\n",
        "    #Se ejecuta despues de parar el stream.\n",
        "\n",
        "    print(f\"\\n cheque de Speed Layer ---\")\n",
        "    path = zone_path(GOLD_PATH, \"org_daily_usage_by_service_speed\")\n",
        "\n",
        "    try:\n",
        "        df = read_parquet(spark, path, partition_glob=\"*\")\n",
        "        total_rows = df.count()\n",
        "\n",
        "        print(f\"Ruta: {path}, Total acumulado en disco: {total_rows}\")\n",
        "\n",
        "        if total_rows > 0:\n",
        "          print(\"funcionando todo OK (Datos persistidos correctamente)\")\n",
        "          df.show(3, truncate=False)\n",
        "        else:\n",
        "          print(\"vacio - dejar el stream corriendo mas tiempo\")\n",
        "    except Exception as e:\n",
        "       print(f\"[ERR] No se pudo leer la Speed Layer: {e}\")\n",
        "\n",
        "def run_full_bronze_audit(spark: SparkSession):\n",
        "    log(\"Iniciando Auditoría completa de capa Bronze...\", \"RUN\")\n",
        "\n",
        "    # Mapa de Tabla -> Columna Clave (PK) para chequear unicidad\n",
        "    # Basado en tus schemas.py\n",
        "    tables_to_audit = [\n",
        "        (\"customers_orgs\", \"org_id\"),\n",
        "        (\"users\", \"user_id\"),\n",
        "        (\"resources\", \"resource_id\"),\n",
        "        (\"support_tickets\", \"ticket_id\"),\n",
        "        (\"marketing_touches\", \"touch_id\"),\n",
        "        (\"billing_monthly\", \"invoice_id\"),\n",
        "        # Nota: nps_surveys puede tener varias encuestas por org,\n",
        "        # así que 'org_id' podría dar duplicados (lo cual es correcto funcionalmente)\n",
        "        (\"nps_surveys\", \"org_id\")\n",
        "    ]\n",
        "\n",
        "    for table_name, pk in tables_to_audit:\n",
        "        # Llamamos a tu función de audit.py\n",
        "        audit_bronze_layer(spark, table_name, pk_col=pk)\n",
        "\n",
        "    log(\"Auditoría Bronze finalizada.\", \"OK\")\n",
        "\n",
        "def run_full_silver_audit(spark: SparkSession):\n",
        "    log(\"Iniciando Auditoría de Calidad Silver...\", \"RUN\")\n",
        "\n",
        "    # 1. Auditoría de Calidad (Ratio Quarantine)\n",
        "    audit_silver_quality(spark)\n",
        "\n",
        "    # 2. Auditoría de la tabla de Cuarentena (Muestreo)\n",
        "    audit_quarantine(spark)\n",
        "\n",
        "    log(\"Auditoría Silver finalizada.\", \"OK\")\n",
        "\n",
        "def run_full_gold_audit(spark: SparkSession):\n",
        "    log(\"Iniciando Auditoría de Marts Gold...\", \"RUN\")\n",
        "\n",
        "    # Lista de tuplas: (Nombre Tabla, Columna a validar)\n",
        "    marts_to_audit = [\n",
        "        (\"org_daily_usage_by_service\", \"daily_cost_usd\"),   # FinOps\n",
        "        (\"org_daily_support_metrics\",  \"total_tickets\"),    # Soporte (No queremos tickets negativos)\n",
        "        (\"org_daily_genai_usage\",      \"genai_daily_cost\")  # GenAI\n",
        "    ]\n",
        "\n",
        "    for table, col in marts_to_audit:\n",
        "        audit_gold_layer(spark, table, check_col=col)\n",
        "\n",
        "    log(\"Auditoría Gold finalizada.\", \"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs4hDdBBVD_A"
      },
      "source": [
        "# bronze_batch.py\n",
        "\n",
        "Ingesta de datos de la Capa Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kY96k5ph9koG"
      },
      "outputs": [],
      "source": [
        "# bronze_batch.py\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "\n",
        "\n",
        "try:\n",
        "    from config import LANDING_PATH, BRONZE_PATH\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        LANDING_PATH = _m.LANDING_PATH\n",
        "        BRONZE_PATH = _m.BRONZE_PATH\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar config, hay que corre primero la celda 'config.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "# importacion de squemas\n",
        "\n",
        "try:\n",
        "    from schemas import (\n",
        "        customers_orgs_schema,\n",
        "        users_schema,\n",
        "        resources_schema,\n",
        "        support_tickets_schema,\n",
        "        marketing_touches_schema,\n",
        "        nps_surveys_schema,\n",
        "        billing_monthly_schema,\n",
        "    )\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m  # type: ignore[import]\n",
        "    try:\n",
        "        customers_orgs_schema = _m.customers_orgs_schema\n",
        "        users_schema = _m.users_schema\n",
        "        resources_schema = _m.resources_schema\n",
        "        support_tickets_schema = _m.support_tickets_schema\n",
        "        marketing_touches_schema = _m.marketing_touches_schema\n",
        "        nps_surveys_schema = _m.nps_surveys_schema\n",
        "        billing_monthly_schema = _m.billing_monthly_schema\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar schemas, hayque correr primero la celda 'schemas.py'\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "#  importacion de todo lo qe es IO desde io_utils\n",
        "\n",
        "try:\n",
        "    from io_utils import read_csv, write_parquet, zone_path, add_audit_columns\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        read_csv = _m.read_csv\n",
        "        write_parquet = _m.write_parquet\n",
        "        zone_path = _m.zone_path\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar io_utils, hay que correr antes primero la celda 'io_utils.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "# helper interno para leer .csv\n",
        "\n",
        "def _read_landing_csv(\n",
        "    spark: SparkSession,\n",
        "    file_name: str,\n",
        "    schema,\n",
        ") -> Optional[DataFrame]:\n",
        "\n",
        "    csv_path = LANDING_PATH / file_name\n",
        "    if not csv_path.exists():\n",
        "        print(f\"[WARN] CSV no encontrado en landing: {csv_path}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"[INFO] Leyendo {csv_path}\")\n",
        "    return read_csv(spark, csv_path, schema)\n",
        "\n",
        "\n",
        "# Ingesta\n",
        "\n",
        "def ingest_customers_orgs_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"customers_orgs.csv\", customers_orgs_schema)\n",
        "    if df is None: return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"customers_orgs\")\n",
        "    write_parquet(df, dest, partition_cols=[\"hq_region\"])\n",
        "    print(f\"[OK] Bronze customers_orgs -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_users_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"users.csv\", users_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"users\")\n",
        "    write_parquet(df, dest, partition_cols=[\"role\"])\n",
        "    print(f\"[OK] Bronze users -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_resources_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"resources.csv\", resources_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"resources\")\n",
        "    write_parquet(df, dest, partition_cols=[\"region\"])\n",
        "    print(f\"[OK] Bronze resources -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_support_tickets_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"support_tickets.csv\", support_tickets_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"support_tickets\")\n",
        "    write_parquet(df, dest, partition_cols=[\"severity\"])\n",
        "    print(f\"[OK] Bronze support_tickets -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_marketing_touches_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"marketing_touches.csv\", marketing_touches_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"marketing_touches\")\n",
        "    write_parquet(df, dest, partition_cols=[\"channel\"])\n",
        "    print(f\"[OK] Bronze marketing_touches -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_nps_surveys_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"nps_surveys.csv\", nps_surveys_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"nps_surveys\")\n",
        "    write_parquet(df, dest, partition_cols=[\"survey_date\"])\n",
        "    print(f\"[OK] Bronze nps_surveys -> {dest}\")\n",
        "\n",
        "\n",
        "def ingest_billing_monthly_to_bronze(spark: SparkSession) -> None:\n",
        "    df = _read_landing_csv(spark, \"billing_monthly.csv\", billing_monthly_schema)\n",
        "    if df is None:\n",
        "        return\n",
        "    df = add_audit_columns(df)\n",
        "    dest = zone_path(BRONZE_PATH, \"billing_monthly\")\n",
        "    write_parquet(df, dest, partition_cols=[\"month\"])\n",
        "    print(f\"[OK] Bronze billing_monthly -> {dest}\")\n",
        "\n",
        "\n",
        "# orrquestador de Bronze batch\n",
        "\n",
        "def run_bronze_batch(spark: SparkSession) -> None:\n",
        "  print(\"\\n[BATCH] Iniciando Ingesta a Bronze (7 Maestros)...\")\n",
        "  '''\n",
        "    ingest_customers_orgs_to_bronze(spark)\n",
        "    ingest_users_to_bronze(spark)\n",
        "    ingest_resources_to_bronze(spark)\n",
        "    ingest_support_tickets_to_bronze(spark)\n",
        "    ingest_marketing_touches_to_bronze(spark)\n",
        "    ingest_nps_surveys_to_bronze(spark)\n",
        "    ingest_billing_monthly_to_bronze(spark)\n",
        "    '''\n",
        "  tasks = [\n",
        "    (ingest_customers_orgs_to_bronze, \"Customers\"),\n",
        "    (ingest_users_to_bronze, \"Users\"),\n",
        "    (ingest_resources_to_bronze, \"Resources\"),\n",
        "    (ingest_support_tickets_to_bronze, \"Support Tickets\"),\n",
        "    (ingest_marketing_touches_to_bronze, \"Marketing\"),\n",
        "    (ingest_nps_surveys_to_bronze, \"NPS Surveys\"),\n",
        "    (ingest_billing_monthly_to_bronze, \"Billing\")\n",
        "    ]\n",
        "  # Use barra de progreso de tqdm para hacer visualmente mas atractivo¿a la ejecucion\n",
        "  for func, name in tqdm(tasks, desc=\"Procesando Archivos\", unit=\"tablas\"):\n",
        "    func(spark)\n",
        "    time.sleep(0.1)\n",
        "  log(\"Capa Bronze finalizada correctamente\", \"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkM2ckNzAU6L"
      },
      "source": [
        "# bronze_stream.py\n",
        "\n",
        "Ingesta de fdatos para el Stream de la capa Speed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rQ8EQ1tKDDEV"
      },
      "outputs": [],
      "source": [
        " # bronze_stream.py\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "\n",
        "try:\n",
        "    from config import LANDING_PATH, BRONZE_PATH\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        LANDING_PATH = _m.LANDING_PATH\n",
        "        BRONZE_PATH = _m.BRONZE_PATH\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar config, hay que correr primero la celda 'config.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "try:\n",
        "    from schemas import usage_events_schema\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        usage_events_schema = _m.usage_events_schema\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar schemas, hay que correr primero la celda 'schemas.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    from io_utils import zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    try:\n",
        "        zone_path = _m.zone_path\n",
        "    except AttributeError as exc:\n",
        "        raise RuntimeError(\n",
        "            \"No se pudo importar io_utils hay qeu ejecutar primero la celda 'io_utils.py'.\"\n",
        "        ) from exc\n",
        "\n",
        "\n",
        "# -creacion de DF de streaming\n",
        "\n",
        "def create_usage_events_stream(spark: SparkSession) -> DataFrame:\n",
        "\n",
        "    src_dir = LANDING_PATH / \"usage_events_stream\"\n",
        "\n",
        "    return (\n",
        "        spark.readStream\n",
        "        .schema(usage_events_schema)\n",
        "        .option(\"maxFilesPerTrigger\", 1)\n",
        "        .json(str(src_dir))\n",
        "    )\n",
        "\n",
        "\n",
        "def transform_usage_events_bronze(df_stream: DataFrame) -> DataFrame:\n",
        "\n",
        "    # Transformaciones :'timestamp' a 'event_ts', 'event_date' (date),  watermark y dedupe por event_id\n",
        "\n",
        "    df = (\n",
        "        df_stream\n",
        "        .withColumn(\"event_ts\", F.to_timestamp(\"timestamp\"))\n",
        "        .withColumn(\"event_date\", F.to_date(\"event_ts\"))\n",
        "    )\n",
        "\n",
        "    df = (\n",
        "      df\n",
        "      .withWatermark(\"event_ts\", \"1 day\")\n",
        "      .dropDuplicates([\"event_id\"])\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "  # Arranca el streaming desde usage_events_stream en Landing\n",
        "\n",
        "def start_usage_events_to_bronze(spark: SparkSession):\n",
        "\n",
        "    df_stream = create_usage_events_stream(spark)\n",
        "    df_bronze = transform_usage_events_bronze(df_stream)\n",
        "\n",
        "    dest_path = zone_path(BRONZE_PATH, \"usage_events\")\n",
        "    checkpoint_path = BRONZE_PATH / \"_checkpoints\" / \"usage_events\"\n",
        "\n",
        "    query = (\n",
        "        df_bronze\n",
        "        .writeStream\n",
        "        .format(\"parquet\")\n",
        "        .option(\"checkpointLocation\", str(checkpoint_path))\n",
        "        .option(\"path\", str(dest_path))\n",
        "        .partitionBy(\"event_date\")\n",
        "        .outputMode(\"append\")\n",
        "        .start()\n",
        "    )\n",
        "\n",
        "    print(f\"[INFO] Streaming usage_events -> {dest_path}\")\n",
        "    print(f\"[INFO] Checkpoints en {checkpoint_path}\")\n",
        "    return query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TbvgqJtVvKI"
      },
      "source": [
        "# silver.py\n",
        "\n",
        "Tratamiento de datos para su pasarlos a la fase gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tUJAJo1OSDp1"
      },
      "outputs": [],
      "source": [
        "# silver.py\n",
        "\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# parche de imports para colab de nuevo, esto en el PY final no va a estar\n",
        "try:\n",
        "    from config import BRONZE_PATH, SILVER_PATH, QUARANTINE_PATH\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    BRONZE_PATH = _m.BRONZE_PATH\n",
        "    SILVER_PATH = _m.SILVER_PATH\n",
        "    QUARANTINE_PATH = _m.QUARANTINE_PATH\n",
        "\n",
        "try:\n",
        "    from io_utils import read_parquet, write_parquet, zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    read_parquet = _m.read_parquet\n",
        "    write_parquet = _m.write_parquet\n",
        "    zone_path = _m.zone_path\n",
        "\n",
        "\n",
        "\n",
        "def read_bronze_usage_events(spark: SparkSession) -> DataFrame:\n",
        "    return read_parquet(spark, zone_path(BRONZE_PATH, \"usage_events\"), partition_glob=\"event_date=*\")\n",
        "\n",
        "def read_bronze_customers_orgs(spark: SparkSession) -> DataFrame:\n",
        "    return read_parquet(spark, zone_path(BRONZE_PATH, \"customers_orgs\"))\n",
        "\n",
        "# -impieza, Joins y cuarentena\n",
        "\n",
        "def run_silver_batch(spark: SparkSession) -> None:\n",
        "\n",
        "    print(\"[INFO] Iniciando Silver...\")\n",
        "\n",
        "    usage_df = read_bronze_usage_events(spark)\n",
        "    orgs_df = read_bronze_customers_orgs(spark)\n",
        "\n",
        "    orgs_sel = orgs_df.select(\n",
        "        \"org_id\", \"org_name\", \"hq_region\", \"plan_tier\", \"is_enterprise\"\n",
        "    )\n",
        "\n",
        "    # Join broadcast) // se usa broadcast porque orgs es chica comparada con eventos\n",
        "    enriched_df = usage_df.join(F.broadcast(orgs_sel), on=\"org_id\", how=\"left\")\n",
        "\n",
        "    # Reglas:\n",
        "    # 1: El costo no puede ser negativo (permitimos 0 o mayor, o -0.00...1 errores de float y decimal, pero defino corte en -0.01 para mayor seguridad)\n",
        "    # 2: tiene tener org_id (el join lo mantiene, pero se valida que no sea nulo si era inner logic)\n",
        "    dq_condition = (F.col(\"cost_usd_increment\") >= -0.01) & (F.col(\"org_id\").isNotNull())\n",
        "\n",
        "    # split\n",
        "    good_df = enriched_df.filter(dq_condition)\n",
        "    bad_df = enriched_df.filter(~dq_condition)\n",
        "\n",
        "    if not bad_df.rdd.isEmpty():\n",
        "        # A. Preparar datos fallidos actuales\n",
        "        bad_df = bad_df.withColumn(\"quarantine_reason\", F.lit(\"cost_negative_or_null_org\"))\n",
        "\n",
        "        quarantine_dest = zone_path(QUARANTINE_PATH, \"usage_events_quarantine\")\n",
        "\n",
        "        #  se verifica si ya existe para no duplicar\n",
        "        try:\n",
        "            existing_quarantine = read_parquet(spark, quarantine_dest)\n",
        "\n",
        "            # C. aca hago el left anti join para no tener dupes en cuarentena\n",
        "            unique_bad_df = bad_df.join(\n",
        "                existing_quarantine,\n",
        "                on=\"event_id\",\n",
        "                how=\"left_anti\"\n",
        "            )\n",
        "\n",
        "            new_errors_count = unique_bad_df.count()\n",
        "            if new_errors_count > 0:\n",
        "                print(f\"[WARN] Nuevos registros invalidos detectados: {new_errors_count}\")\n",
        "                write_parquet(unique_bad_df, quarantine_dest, mode=\"append\")\n",
        "            else:\n",
        "                print(f\"[WARN] Errores detectados ya existian en cuarentena\")\n",
        "\n",
        "        except Exception:\n",
        "            # si no hay archivo, se crea\n",
        "            print(f\"[WARN] Creando cuarentena por primera vez\")\n",
        "            write_parquet(bad_df, quarantine_dest, mode=\"append\")\n",
        "\n",
        "    # escritura de Silver limpio\n",
        "    silver_dest = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    good_df = good_df.withColumnRenamed(\"service\", \"service_name\")\n",
        "\n",
        "    write_parquet(\n",
        "        good_df,\n",
        "        silver_dest,\n",
        "        partition_cols=[\"event_date\"],\n",
        "        mode=\"overwrite\"\n",
        "    )\n",
        "    print(f\"[OK] Silver Batch completado, todo ok -> {silver_dest}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1IadKcRV4LQ"
      },
      "source": [
        "# gold.py\n",
        "\n",
        "Creacion de los marts de negocios para ser subidos a Cassandra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4wEDN8i8TvOF"
      },
      "outputs": [],
      "source": [
        "#gold.py\n",
        "import pandas as pd\n",
        "\n",
        "from __future__ import annotations\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# parche de imports para colab de nuevo, esto en el PY final no va a estar\n",
        "try:\n",
        "    from config import SILVER_PATH, GOLD_PATH, BRONZE_PATH\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    SILVER_PATH = _m.SILVER_PATH\n",
        "    GOLD_PATH = _m.GOLD_PATH\n",
        "    BRONZE_PATH = _m.BRONZE_PATH\n",
        "\n",
        "try:\n",
        "    from io_utils import read_parquet, write_parquet, zone_path\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    read_parquet = _m.read_parquet\n",
        "    write_parquet = _m.write_parquet\n",
        "    zone_path = _m.zone_path\n",
        "\n",
        "try:\n",
        "    from bronze_stream import create_usage_events_stream, transform_usage_events_bronze\n",
        "except ModuleNotFoundError:\n",
        "    import __main__ as _m\n",
        "    create_usage_events_stream = _m.create_usage_events_stream\n",
        "    transform_usage_events_bronze = _m.transform_usage_events_bronze\n",
        "\n",
        "\n",
        "# Gold de Batch, en las proximas funcioens se generan losmarts de Finopsl, Support y Genai\n",
        "\n",
        "def build_gold_finops_mart(spark: SparkSession) -> DataFrame:\n",
        "\n",
        "\n",
        "    silver_path = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    silver_df = read_parquet(spark, silver_path)\n",
        "\n",
        "    # agregaciones\n",
        "    aggregated_df = (\n",
        "        silver_df\n",
        "        .groupBy(\"org_id\", \"org_name\", \"service_name\", \"event_date\", \"hq_region\", \"plan_tier\")\n",
        "        .agg(\n",
        "            F.sum(\"cost_usd_increment\").alias(\"daily_cost_usd\"),\n",
        "            F.sum(\n",
        "                F.when(F.col(\"metric\") == \"requests\", F.col(\"value\")).otherwise(0.0)\n",
        "            ).alias(\"daily_requests\"),\n",
        "            F.sum(\"carbon_kg\").alias(\"daily_carbon_kg\")\n",
        "        )\n",
        "    )\n",
        "\n",
        "    #KPIs\n",
        "    gold_df = (\n",
        "        aggregated_df\n",
        "        .withColumn(\n",
        "            \"cost_per_request\",\n",
        "            F.when(F.col(\"daily_requests\") > 0,\n",
        "                   F.col(\"daily_cost_usd\") / F.col(\"daily_requests\")).otherwise(None)\n",
        "        )\n",
        "        .withColumn(\n",
        "            \"carbon_per_dollar\",\n",
        "            F.when(F.col(\"daily_cost_usd\") > 0,\n",
        "                   F.col(\"daily_carbon_kg\") / F.col(\"daily_cost_usd\")).otherwise(None)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return gold_df\n",
        "\n",
        "def run_gold_batch_finops_mart(spark: SparkSession) -> None:\n",
        "    df = build_gold_finops_mart(spark)\n",
        "    dest = zone_path(GOLD_PATH, \"org_daily_usage_by_service\")\n",
        "    write_parquet(df, dest, partition_cols=[\"event_date\"], mode=\"overwrite\")\n",
        "    print(f\"[OK] Gold Batch (FinOps) -> {dest}\")\n",
        "\n",
        "\n",
        "def build_gold_support_mart(spark: SparkSession) -> DataFrame:\n",
        "    tickets_path = zone_path(BRONZE_PATH, \"support_tickets\")\n",
        "    tickets_df = read_parquet(spark, tickets_path, partition_glob=\"severity=*\")\n",
        "    orgs_path = zone_path(BRONZE_PATH, \"customers_orgs\")\n",
        "    orgs_df = read_parquet(spark, orgs_path).select(\"org_id\", \"org_name\")\n",
        "\n",
        "    metrics_df = (\n",
        "        tickets_df\n",
        "        .groupBy(\"org_id\", \"created_at\")\n",
        "        .agg(\n",
        "            F.count(\"ticket_id\").alias(\"total_tickets\"),\n",
        "            F.sum(F.when(F.lower(F.col(\"severity\")) == \"critical\", 1).otherwise(0)).alias(\"critical_tickets\"),\n",
        "            F.sum(F.when(F.col(\"sla_breached\") == True, 1).otherwise(0)).alias(\"sla_breached_count\"),\n",
        "            F.avg(\"csat\").alias(\"avg_csat\")\n",
        "        )\n",
        "        .withColumnRenamed(\"created_at\", \"ticket_date\")\n",
        "    )\n",
        "    return metrics_df.join(orgs_df, on=\"org_id\", how=\"left\").withColumn(\n",
        "        \"sla_breach_rate\",\n",
        "        F.when(F.col(\"total_tickets\") > 0, F.round(F.col(\"sla_breached_count\") / F.col(\"total_tickets\"), 4)).otherwise(0.0)\n",
        "    )\n",
        "\n",
        "def run_gold_support_batch(spark: SparkSession) -> None:\n",
        "    df = build_gold_support_mart(spark)\n",
        "    dest = zone_path(GOLD_PATH, \"org_daily_support_metrics\")\n",
        "    write_parquet(df, dest, partition_cols=[\"ticket_date\"], mode=\"overwrite\")\n",
        "    print(f\"[OK] Gold Batch (Support) -> {dest}\")\n",
        "\n",
        "def build_gold_genai_mart(spark: SparkSession) -> DataFrame:\n",
        "    silver_path = zone_path(SILVER_PATH, \"usage_events_enriched\")\n",
        "    df = read_parquet(spark, silver_path)\n",
        "\n",
        "    genai_df = (\n",
        "        df\n",
        "        .filter(F.lower(F.col(\"service_name\")).contains(\"genai\"))\n",
        "        .groupBy(\"org_id\", \"org_name\", \"event_date\", \"service_name\")\n",
        "        .agg(\n",
        "            F.sum(\"cost_usd_increment\").alias(\"genai_daily_cost\"),\n",
        "            F.sum(\n",
        "                F.when(F.col(\"metric\") == \"requests\", F.col(\"value\")).otherwise(0)\n",
        "            ).alias(\"genai_requests_count\")\n",
        "        )\n",
        "    )\n",
        "    return genai_df\n",
        "\n",
        "def run_gold_genai_batch(spark: SparkSession) -> None:\n",
        "    df = build_gold_genai_mart(spark)\n",
        "    dest = zone_path(GOLD_PATH, \"org_daily_genai_usage\")\n",
        "    write_parquet(df, dest, partition_cols=[\"event_date\"], mode=\"overwrite\")\n",
        "    print(f\"[OK] Gold Batch (GenAI) -> {dest}\")\n",
        "\n",
        "\n",
        "def run_full_gold_batch(spark: SparkSession) -> None:\n",
        "  run_gold_batch_finops_mart(spark)\n",
        "  run_gold_support_batch(spark)\n",
        "  run_gold_genai_batch(spark)\n",
        "\n",
        "\n",
        "# SPEED GOLD: Streaming Directo a Gold\n",
        "\n",
        "def start_gold_speed_stream(spark: SparkSession):\n",
        "\n",
        "    # Speed Layer: Lee stream yvuelca a Gold\n",
        "    # se usa cache de  Orgs para evitar I/O repetitivo y Coalesce(1) para evitar el problema de tener muchos archivos chicos en Gold.\n",
        "\n",
        "    print(\"[INFO] Comenzando Speed Layer...\")\n",
        "\n",
        "    # Stream\n",
        "    raw_stream = create_usage_events_stream(spark)\n",
        "    stream_bronze = transform_usage_events_bronze(raw_stream)\n",
        "\n",
        "    #  cacheo de Orgs\n",
        "\n",
        "    orgs_df = read_parquet(spark, zone_path(BRONZE_PATH, \"customers_orgs\"))\n",
        "    orgs_sel = orgs_df.select(\"org_id\", \"org_name\", \"hq_region\", \"plan_tier\")\n",
        "    orgs_sel.cache()\n",
        "    print(f\"[INFO] Dimensión Organizaciones cacheada: {orgs_sel.count()} registros.\")\n",
        "\n",
        "\n",
        "    dest_speed = zone_path(GOLD_PATH, \"org_daily_usage_by_service_speed\")\n",
        "\n",
        "    def process_microbatch(batch_df: DataFrame, batch_id: int):\n",
        "\n",
        "        if batch_df.rdd.isEmpty():\n",
        "            return\n",
        "\n",
        "        # metricas\n",
        "        input_count = batch_df.count()\n",
        "\n",
        "        # procesado\n",
        "        enriched = batch_df.join(F.broadcast(orgs_sel), on=\"org_id\", how=\"left\")\n",
        "\n",
        "        # data quality\n",
        "        valid_stream = enriched.filter(F.col(\"cost_usd_increment\") >= -0.01)\n",
        "        valid_count = valid_stream.count()\n",
        "        dropped_count = input_count - valid_count\n",
        "\n",
        "        # aregaciones\n",
        "        agg_batch = (\n",
        "            valid_stream\n",
        "            .groupBy(\"org_id\", \"org_name\", \"service\", \"event_date\")\n",
        "            .agg(\n",
        "                F.sum(\"cost_usd_increment\").alias(\"daily_cost_usd\"),\n",
        "                F.sum(F.when(F.col(\"metric\") == \"requests\", F.col(\"value\")).otherwise(0)).alias(\"daily_requests\"),\n",
        "                F.sum(\"carbon_kg\").alias(\"daily_carbon_kg\")\n",
        "            )\n",
        "            .withColumnRenamed(\"service\", \"service_name\")\n",
        "        )\n",
        "\n",
        "        # Append\n",
        "        (\n",
        "            agg_batch\n",
        "            .coalesce(1)\n",
        "            .write\n",
        "            .mode(\"append\")\n",
        "            .partitionBy(\"event_date\")\n",
        "            .parquet(str(dest_speed))\n",
        "        )\n",
        "\n",
        "        #  Logde quality para monitoreo ---\n",
        "\n",
        "        print(f\"[STREAM {batch_id}] Reporte \")\n",
        "        print(f\" Input: {input_count} eventos\")\n",
        "        print(f\"Validos: {valid_count}\")\n",
        "        if dropped_count > 0:\n",
        "            print(f\"Dropped (Cost < -0.01): {dropped_count} ({(dropped_count/input_count)*100:.1f}%)\")\n",
        "        print(f\"todo pasado a Gold de Speed layer\")\n",
        "\n",
        "    # Arranca Stream con outputMode(\"update\") para permitir agregacionesy con  foreachBatch manejando la salida final\n",
        "    query = (\n",
        "        stream_bronze\n",
        "        .writeStream\n",
        "        .foreachBatch(process_microbatch)\n",
        "        .outputMode(\"update\")\n",
        "        .trigger(processingTime=\"5 seconds\") # trigger para no saturar\n",
        "        .start()\n",
        "    )\n",
        "\n",
        "    print(f\"[INFO] Streaming ejecutandose -> {dest_speed}\")\n",
        "    return query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm-aHP8JXvpq"
      },
      "source": [
        "# cassandra_utils.puy\n",
        "\n",
        "Crea la instancia de cassandra conlas credenciales provistas en la carpeta /creds y agreaga las tablas al Keyspace asignado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qjupavh5XsCA"
      },
      "outputs": [],
      "source": [
        "# cassandra_utils.py\n",
        "\n",
        "import os\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# carga de credenciales\n",
        "load_dotenv(\"/content/creds/cred.env\", override=True)\n",
        "# config\n",
        "SECURE_BUNDLE_PATH = \"/content/creds/secure-connect-proyecto-cloud-analytics.zip\"\n",
        "ASTRA_DB_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
        "KEYSPACE = \"Cloud_analytics_db\"\n",
        "\n",
        "# funcines de implementacion de cassandra: tomar, crear e insertar\n",
        "def get_cassandra_session():\n",
        "\n",
        "    if not Path(SECURE_BUNDLE_PATH).exists():\n",
        "        raise FileNotFoundError(f\"Falta el Secure Connect Bundle en: {SECURE_BUNDLE_PATH}\")\n",
        "\n",
        "    if not ASTRA_DB_TOKEN:\n",
        "        raise RuntimeError(\"No se encontro ASTRA_DB_APPLICATION_TOKEN en cred.env\")\n",
        "\n",
        "    cloud_config = {\n",
        "        'secure_connect_bundle': SECURE_BUNDLE_PATH\n",
        "    }\n",
        "\n",
        "    auth_provider = PlainTextAuthProvider(\"token\", ASTRA_DB_TOKEN)\n",
        "\n",
        "    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\n",
        "    session = cluster.connect()\n",
        "    return session\n",
        "\n",
        "def create_schema(session):\n",
        "    print(f\"[CASSANDRA] Creando esquema en keyspace '{KEYSPACE}'...\")\n",
        "\n",
        "    # 1. Tabla FinOps (Ya existía)\n",
        "    ddl_finops = f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS \"{KEYSPACE}\".org_daily_usage_by_service (\n",
        "        org_id text,\n",
        "        usage_date date,\n",
        "        service_name text,\n",
        "        daily_cost_usd double,\n",
        "        daily_requests double,\n",
        "        daily_carbon_kg double,\n",
        "        cost_per_request double,\n",
        "        carbon_per_dollar double,\n",
        "        PRIMARY KEY ((org_id), usage_date, service_name)\n",
        "    ) WITH CLUSTERING ORDER BY (usage_date DESC, service_name ASC);\n",
        "    \"\"\"\n",
        "    session.execute(ddl_finops)\n",
        "\n",
        "    # 2. NUEVA: Tabla de Soporte (Support Mart)\n",
        "    # PK: org_id (partition), ticket_date (clustering) para ver evolución temporal\n",
        "    ddl_support = f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS \"{KEYSPACE}\".org_daily_support_metrics (\n",
        "        org_id text,\n",
        "        ticket_date date,\n",
        "        total_tickets int,\n",
        "        critical_tickets int,\n",
        "        sla_breached_count int,\n",
        "        avg_csat double,\n",
        "        sla_breach_rate double,\n",
        "        PRIMARY KEY ((org_id), ticket_date)\n",
        "    ) WITH CLUSTERING ORDER BY (ticket_date DESC);\n",
        "    \"\"\"\n",
        "    session.execute(ddl_support)\n",
        "\n",
        "    # 3. NUEVA: Tabla de GenAI (Product Mart)\n",
        "    # PK: org_id (partition), event_date + service (clustering)\n",
        "    ddl_genai = f\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS \"{KEYSPACE}\".org_daily_genai_usage (\n",
        "        org_id text,\n",
        "        event_date date,\n",
        "        service_name text,\n",
        "        genai_daily_cost double,\n",
        "        genai_requests_count double,\n",
        "        PRIMARY KEY ((org_id), event_date, service_name)\n",
        "    ) WITH CLUSTERING ORDER BY (event_date DESC);\n",
        "    \"\"\"\n",
        "    session.execute(ddl_genai)\n",
        "\n",
        "    print(\"[CASSANDRA] Esquema verificado: 3 Tablas listas.\")\n",
        "\n",
        "def insert_batch_to_cassandra(rows: list[dict]):\n",
        "    if not rows:\n",
        "        return\n",
        "    session = get_cassandra_session()\n",
        "\n",
        "    query = f\"\"\"\n",
        "    INSERT INTO \"{KEYSPACE}\".org_daily_usage_by_service (\n",
        "        org_id, usage_date, service_name,\n",
        "        daily_cost_usd, daily_requests, daily_carbon_kg,\n",
        "        cost_per_request, carbon_per_dollar\n",
        "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\"\n",
        "    prepared = session.prepare(query)\n",
        "\n",
        "    for row in rows:\n",
        "        session.execute(prepared, (\n",
        "            row[\"org_id\"],\n",
        "            row[\"event_date\"],\n",
        "            row[\"service_name\"],\n",
        "            row[\"daily_cost_usd\"],\n",
        "            row[\"daily_requests\"],\n",
        "            row[\"daily_carbon_kg\"],\n",
        "            row[\"cost_per_request\"],\n",
        "            row[\"carbon_per_dollar\"]\n",
        "        ))\n",
        "\n",
        "    session.shutdown()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IWMv1hwXaLQ"
      },
      "source": [
        "# cassandra_loader.py\n",
        "\n",
        "Carga todas las tablas generadas en Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o5KrZ9GVoqnu"
      },
      "outputs": [],
      "source": [
        "# cassandra_loader.py\n",
        "\n",
        "from pyspark.sql import DataFrame\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def upload_full_gold_layer(spark: SparkSession):\n",
        "    \"\"\"\n",
        "    Carga TODAS las tablas Gold (FinOps, Support, GenAI) a Cassandra.\n",
        "    Maneja el renombrado de columnas para coincidir con el esquema de DB.\n",
        "    \"\"\"\n",
        "    print(\"\\n[SERVING] Iniciando carga masiva a AstraDB...\")\n",
        "\n",
        "    # Este try es para asegurear idempotencia\n",
        "    try:\n",
        "        session = get_cassandra_session()\n",
        "        create_schema(session)\n",
        "        session.shutdown()\n",
        "    except Exception as e:\n",
        "        print(f\"[ERR] Error creando esquema: {e}\")\n",
        "        return\n",
        "\n",
        "    #helper interno de carga\n",
        "    def load_df_to_cassandra(df: DataFrame, table_name: str, columns_map: list[str]):\n",
        "\n",
        "        try:\n",
        "            count = df.count()\n",
        "            print(f\"   -> cargando tabla '{table_name}' ({count} registros)...\")\n",
        "\n",
        "            rows = df.collect()\n",
        "            data_dicts = [row.asDict() for row in rows]\n",
        "\n",
        "            if not data_dicts:\n",
        "                print(f\"      [WARN] No hay datos para {table_name}.\")\n",
        "                return\n",
        "\n",
        "            session = get_cassandra_session()\n",
        "\n",
        "            # query\n",
        "            cols_str = \", \".join(columns_map)\n",
        "            bind_markers = \", \".join([\"?\"] * len(columns_map))\n",
        "            query = f'INSERT INTO \"{KEYSPACE}\".{table_name} ({cols_str}) VALUES ({bind_markers})'\n",
        "            prepared = session.prepare(query)\n",
        "\n",
        "            # upsert\n",
        "            for row_data in tqdm(data_dicts, desc=f\"Subiendo {table_name}\", unit=\"rows\"):\n",
        "                values = []\n",
        "                for col in columns_map:\n",
        "                    # Obtenemos el valor. Si la columna no existe en el DF, inserta None.\n",
        "                    val = row_data.get(col)\n",
        "                    values.append(val)\n",
        "\n",
        "                session.execute(prepared, values)\n",
        "\n",
        "            session.shutdown()\n",
        "            print(f\"      [OK] Carga completada.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      [ERR] Falló carga de {table_name}. Detalles: {e}\")\n",
        "\n",
        "\n",
        "    # carga de finops(org_daily_usage_by_service)\n",
        "    path_finops = zone_path(GOLD_PATH, \"org_daily_usage_by_service\")\n",
        "    df_finops = read_parquet(spark, path_finops, partition_glob=\"*\")\n",
        "    df_finops = df_finops.withColumnRenamed(\"event_date\", \"usage_date\")\n",
        "\n",
        "    load_df_to_cassandra(\n",
        "        df_finops,\n",
        "        \"org_daily_usage_by_service\",\n",
        "        [\"org_id\", \"usage_date\", \"service_name\", \"daily_cost_usd\", \"daily_requests\", \"daily_carbon_kg\", \"cost_per_request\", \"carbon_per_dollar\"]\n",
        "    )\n",
        "\n",
        "    # cargade support (org_daily_support_metrics)\n",
        "    path_support = zone_path(GOLD_PATH, \"org_daily_support_metrics\")\n",
        "    df_support = read_parquet(spark, path_support, partition_glob=\"*\")\n",
        "\n",
        "    load_df_to_cassandra(\n",
        "        df_support,\n",
        "        \"org_daily_support_metrics\",\n",
        "        [\"org_id\", \"ticket_date\", \"total_tickets\", \"critical_tickets\", \"sla_breached_count\", \"avg_csat\", \"sla_breach_rate\"]\n",
        "    )\n",
        "\n",
        "    #  carga de genai (org_daily_genai_usage) ---\n",
        "    path_genai = zone_path(GOLD_PATH, \"org_daily_genai_usage\")\n",
        "    df_genai = read_parquet(spark, path_genai, partition_glob=\"*\")\n",
        "\n",
        "    load_df_to_cassandra(\n",
        "        df_genai,\n",
        "        \"org_daily_genai_usage\",\n",
        "        [\"org_id\", \"event_date\", \"service_name\", \"genai_daily_cost\", \"genai_requests_count\"]\n",
        "    )\n",
        "def upload_gold_to_cassandra(spark: SparkSession):\n",
        "\n",
        "    # la carga  gold en Cassandra\n",
        "    print(\"\\n[SERVING] Iniciando carga a Cassandra...\")\n",
        "\n",
        "    try:\n",
        "        session = get_cassandra_session()\n",
        "        create_schema(session)\n",
        "        session.shutdown()\n",
        "    except Exception as e:\n",
        "        print(f\"[ERR] Error conectando a Cassandra: {e}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    gold_df = read_parquet(spark, zone_path(GOLD_PATH, \"org_daily_usage_by_service\"), partition_glob=\"event_date=*\")\n",
        "\n",
        "    # convierte a python con el driver\n",
        "\n",
        "    print(f\"[SERVING] Leyendo {gold_df.count()} filas de Gold...\")\n",
        "    rows = gold_df.collect()\n",
        "    data_to_insert = [row.asDict() for row in rows]\n",
        "\n",
        "    insert_batch_to_cassandra(data_to_insert)\n",
        "    print(f\"[SERVING] Carga completada. {len(data_to_insert)} registros insertados.\")\n",
        "\n",
        "\n",
        "def write_stream_to_cassandra(batch_df, batch_id):\n",
        "    #funcion para usar en .foreachBatch del Streaming.\n",
        "\n",
        "    if batch_df.rdd.isEmpty(): return\n",
        "    rows = batch_df.collect()\n",
        "    data = [row.asDict() for row in rows]\n",
        "\n",
        "    # upsert\n",
        "    insert_batch_to_cassandra(data)\n",
        "    print(f\"[CASSANDRA STREAM] Batch {batch_id} cargado ({len(data)} filas).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnGKPv-va_h4"
      },
      "source": [
        "# Demo de Batch Layer → Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690,
          "referenced_widgets": [
            "3052d4e9309346b7baf4f87221f76078",
            "819bf30a317d41899b480e2e87dbc572",
            "a4b21664e8374b8e85671bf45d9061a1",
            "69cb5613a4764a2bb409937f06481957",
            "5c29043f72904c29a2512d3d245d2d95",
            "0cc424fca3524b01ba96bf68f295e53e",
            "ae6905d429fb42e8802671fe04291cd6",
            "712d789a5ab840cd8ed6401a705f6c67",
            "a0feaf5c47fb41dba2695f38114bbfea",
            "6edf298594694aa6987d6414e01ed56e",
            "4f936ed048a3471697813851b96615f4"
          ]
        },
        "id": "QAY_yxGBug5y",
        "outputId": "6d3fd70b-b8e4-431f-eada-7a5f50c333e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Dataset descomprimido en /content/datalake/landing\n",
            "\u001b[94m[2025-12-08 22:23:51] [INFO] PROJECT_ROOT: {PROJECT_ROOT}\u001b[0m\n",
            "\u001b[94m[2025-12-08 22:23:51] [INFO] Spark version: 3.5.1\u001b[0m\n",
            "\u001b[96m[2025-12-08 22:23:51] [RUN] Generando Bronze Batch (Maestros)...\u001b[0m\n",
            "[OK] Dataset descomprimido en /content/datalake/landing\n",
            "\n",
            "[BATCH] Iniciando Ingesta a Bronze (7 Maestros)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3052d4e9309346b7baf4f87221f76078",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Procesando Archivos:   0%|          | 0/7 [00:00<?, ?tablas/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Leyendo /content/datalake/landing/customers_orgs.csv\n",
            "[OK] Bronze customers_orgs -> /content/datalake/bronze/customers_orgs\n",
            "[INFO] Leyendo /content/datalake/landing/users.csv\n",
            "[OK] Bronze users -> /content/datalake/bronze/users\n",
            "[INFO] Leyendo /content/datalake/landing/resources.csv\n",
            "[OK] Bronze resources -> /content/datalake/bronze/resources\n",
            "[INFO] Leyendo /content/datalake/landing/support_tickets.csv\n",
            "[OK] Bronze support_tickets -> /content/datalake/bronze/support_tickets\n",
            "[INFO] Leyendo /content/datalake/landing/marketing_touches.csv\n",
            "[OK] Bronze marketing_touches -> /content/datalake/bronze/marketing_touches\n",
            "[INFO] Leyendo /content/datalake/landing/nps_surveys.csv\n",
            "[OK] Bronze nps_surveys -> /content/datalake/bronze/nps_surveys\n",
            "[INFO] Leyendo /content/datalake/landing/billing_monthly.csv\n",
            "[OK] Bronze billing_monthly -> /content/datalake/bronze/billing_monthly\n",
            "\u001b[92m[2025-12-08 22:24:11] [OK] Capa Bronze finalizada correctamente\u001b[0m\n",
            "\u001b[96m[2025-12-08 22:24:11] [RUN] Generando Bronze Stream (Eventos)...\u001b[0m\n",
            "[INFO] Streaming usage_events -> /content/datalake/bronze/usage_events\n",
            "[INFO] Checkpoints en /content/datalake/bronze/_checkpoints/usage_events\n",
            "\u001b[92m[2025-12-08 22:24:28] [OK] Stream procesado.\u001b[0m\n",
            "\u001b[96m[2025-12-08 22:24:28] [RUN] Generando Silver...\u001b[0m\n",
            "[INFO] Iniciando Silver...\n",
            "[WARN] Creando cuarentena por primera vez\n",
            "[OK] Silver Batch completado, todo ok -> /content/datalake/silver/usage_events_enriched\n",
            "\u001b[92m[2025-12-08 22:24:45] [OK] Silver finalizado\u001b[0m\n",
            "\u001b[96m[2025-12-08 22:24:45] [RUN] ejecuntando proceso Gold...\u001b[0m\n",
            "[OK] Gold Batch (FinOps) -> /content/datalake/gold/org_daily_usage_by_service\n",
            "[OK] Gold Batch (Support) -> /content/datalake/gold/org_daily_support_metrics\n",
            "[OK] Gold Batch (GenAI) -> /content/datalake/gold/org_daily_genai_usage\n",
            "\u001b[92m[2025-12-08 22:24:58] [OK] proceso Gold finalizado\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "ensure_dirs()\n",
        "unpack_raw_dataset()\n",
        "spark = create_spark()\n",
        "\n",
        "log(\"PROJECT_ROOT: {PROJECT_ROOT}\", \"INFO\")\n",
        "log(f\"Spark version: {spark.version}\", \"INFO\")\n",
        "log(\"Generando Bronze Batch (Maestros)...\", \"RUN\")\n",
        "ensure_dirs()\n",
        "unpack_raw_dataset()\n",
        "spark = create_spark()\n",
        "run_bronze_batch(spark)\n",
        "\n",
        "log(\"Generando Bronze Stream (Eventos)...\", \"RUN\")\n",
        "query = start_usage_events_to_bronze(spark)\n",
        "\n",
        "time.sleep(15) # esto es solo para asegurrar en el demo que se procesen datos\n",
        "query.stop()\n",
        "log(\"Stream procesado.\", \"OK\")\n",
        "\n",
        "log(\"Generando Silver...\", \"RUN\")\n",
        "run_silver_batch(spark)\n",
        "log(\"Silver finalizado\", \"OK\")\n",
        "log(\"ejecuntando proceso Gold...\", \"RUN\")\n",
        "run_full_gold_batch(spark)\n",
        "log(\"proceso Gold finalizado\", \"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XrCg9qiWCJ4"
      },
      "source": [
        "## Chequeo de Quality de las tres fases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YeNRXd79G-Ho",
        "outputId": "44af36d8-9532-4573-c0f6-62fe20c55e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[96m[2025-12-08 22:24:58] [RUN] Haciendo quality control...\u001b[0m\n",
            "\u001b[96m[2025-12-08 22:24:58] [RUN] Iniciando Auditoría completa de capa Bronze...\u001b[0m\n",
            "\n",
            " chequeo Bronze: customers_orgs\n",
            "registros totales: 80\n",
            "duplicados en PK (org_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: todo ok!!\n",
            "\n",
            " chequeo Bronze: users\n",
            "registros totales: 800\n",
            "duplicados en PK (user_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: todo ok!!\n",
            "\n",
            " chequeo Bronze: resources\n",
            "registros totales: 400\n",
            "duplicados en PK (resource_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: todo ok!!\n",
            "\n",
            " chequeo Bronze: support_tickets\n",
            "registros totales: 1000\n",
            "duplicados en PK (ticket_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: todo ok!!\n",
            "\n",
            " chequeo Bronze: marketing_touches\n",
            "registros totales: 1500\n",
            "duplicados en PK (touch_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: todo ok!!\n",
            "\n",
            " chequeo Bronze: billing_monthly\n",
            "registros totales: 240\n",
            "duplicados en PK (invoice_id): 0\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: todo ok!!\n",
            "\n",
            " chequeo Bronze: nps_surveys\n",
            "registros totales: 92\n",
            "duplicados en PK (org_id): 32\n",
            "nulos en ingest_ts: 0\n",
            "Resultado: revisar data por posibles duplicados \n",
            "\u001b[92m[2025-12-08 22:25:04] [OK] Auditoría Bronze finalizada.\u001b[0m\n",
            "\u001b[96m[2025-12-08 22:25:04] [RUN] Iniciando Auditoría de Calidad Silver...\u001b[0m\n",
            "\n",
            " Chequeop Silver:\n",
            "Total: 758\n",
            "Aceptados (Silver): 755\n",
            "Rechazados (cuarentena): 3 (0.40%)\n",
            "CALIDAD: ACEPTABLE\n",
            "ejemplo de rechazo:\n",
            "+----------------+-------------------------+\n",
            "|event_id        |quarantine_reason        |\n",
            "+----------------+-------------------------+\n",
            "|evt_faubjbtabmwl|cost_negative_or_null_org|\n",
            "+----------------+-------------------------+\n",
            "only showing top 1 row\n",
            "\n",
            "\n",
            "Calidad de Datos (Silver Batch)\n",
            "\n",
            " Estadisticas:\n",
            "Total Procesado: 758\n",
            "Aceptados (Silver): 755 (99.60%)\n",
            "Rechazados (Quarantine): 3 (0.40%)\n",
            "\n",
            "resultado:\n",
            "Aceptable- rechazo  bajo y esperado.\n",
            "\n",
            " Muestra de registros en Cuarentena (top 5):\n",
            "+----------------+------------------+------------+-------------------------+\n",
            "|event_id        |cost_usd_increment|org_id      |quarantine_reason        |\n",
            "+----------------+------------------+------------+-------------------------+\n",
            "|evt_faubjbtabmwl|-0.0602           |org_cvs4f8cg|cost_negative_or_null_org|\n",
            "|evt_qniow8ymxwd6|-0.2446           |org_i7p5tb94|cost_negative_or_null_org|\n",
            "|evt_bbmth9hzpa6e|-0.3656           |org_n9j2qp89|cost_negative_or_null_org|\n",
            "+----------------+------------------+------------+-------------------------+\n",
            "\n",
            "\u001b[92m[2025-12-08 22:25:11] [OK] Auditoría Silver finalizada.\u001b[0m\n",
            "\u001b[96m[2025-12-08 22:25:11] [RUN] Iniciando Auditoría de Marts Gold...\u001b[0m\n",
            "\n",
            " Chequeo Gold: org_daily_usage_by_service\n",
            "registros Totales (Agregados): 727\n",
            "Costos Negativos detectados: 0\n",
            "\n",
            " Chequeo Gold: org_daily_support_metrics\n",
            "registros Totales (Agregados): 944\n",
            "Costos Negativos detectados: 0\n",
            "\n",
            " Chequeo Gold: org_daily_genai_usage\n",
            "registros Totales (Agregados): 77\n",
            "Costos Negativos detectados: 0\n",
            "\u001b[92m[2025-12-08 22:25:16] [OK] Auditoría Gold finalizada.\u001b[0m\n",
            "\u001b[92m[2025-12-08 22:25:16] [OK] Fin demo Batch Layer (Bronze CSV → Silver → Gold)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#Chequeo de quality\n",
        "log(\"Haciendo quality control...\", \"RUN\")\n",
        "run_full_bronze_audit(spark)\n",
        "run_full_silver_audit(spark)\n",
        "run_full_gold_audit(spark)\n",
        "log(\"Fin demo Batch Layer (Bronze CSV → Silver → Gold)\", \"OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szSUhws8Zj4p"
      },
      "source": [
        "# Demo de Speed Layer → Gold\n",
        "\n",
        "En un despliegue real, el pipeline de streaming se ejecutaría como servicio/orquestación aparte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S94XmoANYnJC",
        "outputId": "3221e211-5c8b-4b4a-d34f-cd29c36133a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Comenzando Speed Layer...\n",
            "[INFO] Dimensión Organizaciones cacheada: 80 registros.\n",
            "[INFO] Streaming ejecutandose -> /content/datalake/gold/org_daily_usage_by_service_speed\n",
            "Streaming Speed → Gold\n",
            "ID: 28a4747d-2c66-4638-8f3a-682094bef6cd\n",
            "Nombre: None\n",
            "Activo: True\n",
            "[STREAM 0] Reporte \n",
            " Input: 360 eventos\n",
            "Validos: 359\n",
            "Dropped (Cost < -0.01): 1 (0.3%)\n",
            "todo pasado a Gold de Speed layer\n",
            "[STREAM 1] Reporte \n",
            " Input: 360 eventos\n",
            "Validos: 358\n",
            "Dropped (Cost < -0.01): 2 (0.6%)\n",
            "todo pasado a Gold de Speed layer\n",
            "[STREAM 2] Reporte \n",
            " Input: 11 eventos\n",
            "Validos: 11\n",
            "todo pasado a Gold de Speed layer\n",
            " Progreso del streaming\n",
            "{'id': '28a4747d-2c66-4638-8f3a-682094bef6cd', 'runId': '13a993ac-7115-463b-9a26-1621d08e6e18', 'name': None, 'timestamp': '2025-12-08T22:25:25.164Z', 'batchId': 2, 'numInputRows': 360, 'inputRowsPerSecond': 110.12542061792597, 'processedRowsPerSecond': 184.6153846153846, 'durationMs': {'addBatch': 1746, 'commitOffsets': 45, 'getBatch': 14, 'latestOffset': 48, 'queryPlanning': 44, 'triggerExecution': 1950, 'walCommit': 46}, 'eventTime': {'avg': '2025-08-01T03:31:43.833Z', 'max': '2025-08-31T20:47:00.000Z', 'min': '2025-07-03T14:16:00.000Z', 'watermark': '2025-08-30T23:51:00.000Z'}, 'stateOperators': [{'operatorName': 'dedupe', 'numRowsTotal': 2385, 'numRowsUpdated': 35, 'allUpdatesTimeMs': 280, 'numRowsRemoved': 0, 'allRemovalsTimeMs': 0, 'commitTimeMs': 770, 'memoryUsedBytes': 528176, 'numRowsDroppedByWatermark': 1136, 'numShufflePartitions': 13, 'numStateStoreInstances': 13, 'customMetrics': {'loadedMapCacheHitCount': 48, 'loadedMapCacheMissCount': 23, 'numDroppedDuplicateRows': 0, 'stateOnCurrentVersionSizeBytes': 438880}}], 'sources': [{'description': 'FileStreamSource[file:/content/datalake/landing/usage_events_stream]', 'startOffset': {'logOffset': 1}, 'endOffset': {'logOffset': 2}, 'latestOffset': None, 'numInputRows': 360, 'inputRowsPerSecond': 110.12542061792597, 'processedRowsPerSecond': 184.6153846153846}], 'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}}\n",
            "aparando stream...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:py4j.clientserver:There was an exception while executing the Python Proxy on the Python Side.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/py4j/clientserver.py\", line 617, in _call_proxy\n",
            "    return_value = getattr(self.pool[obj_id], method)(*params)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pyspark/sql/utils.py\", line 120, in call\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pyspark/sql/utils.py\", line 117, in call\n",
            "    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)\n",
            "  File \"/tmp/ipython-input-3725754330.py\", line 194, in process_microbatch\n",
            "    .parquet(str(dest_speed))\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pyspark/sql/readwriter.py\", line 1721, in parquet\n",
            "    self._jwrite.parquet(path)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
            "    return_value = get_return_value(\n",
            "                   ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\", line 179, in deco\n",
            "    return f(*a, **kw)\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/py4j/protocol.py\", line 326, in get_return_value\n",
            "    raise Py4JJavaError(\n",
            "py4j.protocol.Py4JJavaError: An error occurred while calling o808.parquet.\n",
            ": java.lang.InterruptedException\n",
            "\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1048)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n",
            "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:187)\n",
            "\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:342)\n",
            "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:980)\n",
            "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$4(FileFormatWriter.scala:307)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:271)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\n",
            "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\n",
            "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
            "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\n",
            "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:792)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.sendCommand(ClientServerConnection.java:244)\n",
            "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:384)\n",
            "\tat py4j.CallbackClient.sendCommand(CallbackClient.java:356)\n",
            "\tat py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)\n",
            "\tat jdk.proxy3/jdk.proxy3.$Proxy41.call(Unknown Source)\n",
            "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)\n",
            "\tat org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)\n",
            "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
            "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
            "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
            "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
            "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
            "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " cheque de Speed Layer ---\n",
            "Ruta: /content/datalake/gold/org_daily_usage_by_service_speed, Total acumulado en disco: 720\n",
            "funcionando todo OK (Datos persistidos correctamente)\n",
            "+------------+---------------+------------+--------------+--------------+---------------+----------+\n",
            "|org_id      |org_name       |service_name|daily_cost_usd|daily_requests|daily_carbon_kg|event_date|\n",
            "+------------+---------------+------------+--------------+--------------+---------------+----------+\n",
            "|org_pnsm43d8|Delta Labs 70  |compute     |11.6645       |130.0000      |0.026          |2025-08-13|\n",
            "|org_dhylurtp|Nimbus Cloud 76|compute     |11.9243       |133.0000      |0.0266         |2025-08-13|\n",
            "|org_5iqvnb4g|Gamma Labs 73  |networking  |0.0092        |0.0000        |2.05E-4        |2025-08-13|\n",
            "+------------+---------------+------------+--------------+--------------+---------------+----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "Streaming Speed → Gold parado.\n"
          ]
        }
      ],
      "source": [
        "# DEMO Speed → Gold\n",
        "import time\n",
        "\n",
        "query_speed_gold = start_gold_speed_stream(spark)\n",
        "\n",
        "print(\"Streaming Speed → Gold\")\n",
        "print(f\"ID: {query_speed_gold.id}\")\n",
        "print(f\"Nombre: {query_speed_gold.name}\")\n",
        "print(f\"Activo: {query_speed_gold.isActive}\")\n",
        "\n",
        "\n",
        "# pausa para dejar que procese\n",
        "\n",
        "time.sleep(15)\n",
        "\n",
        "print(\" Progreso del streaming\")\n",
        "print(query_speed_gold.lastProgress)\n",
        "\n",
        "print(\"aparando stream...\")\n",
        "\n",
        "'''\n",
        "El try que viene lo hice por si el stream se para mientras esta procesando algo y tira error java.lang.InterruptedException\n",
        "ese error que no para la ejecucion del colab y solo pasa aca porque el stream se para un momento arbitrario.\n",
        "en un deploy real no se haria.\n",
        "\n",
        "'''\n",
        "if query_speed_gold.isActive:\n",
        "    query_speed_gold.stop()\n",
        "    try:\n",
        "        query_speed_gold.awaitTermination(timeout=2)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "audit_speed_layer_results(spark)\n",
        "print(\"Streaming Speed → Gold parado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JZbvhzQWt-I"
      },
      "source": [
        "### DEMO - Carga de datos a Cassandra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "4bb17d049523426fbf147d6b8de2cbad",
            "e119458ef4cd48319eb3dded67dca87a",
            "793fbf063c79490fbef6e30fa0d63615",
            "def8e1c35473473eb68c3030832d5537",
            "5eec945787e64ea4a688a47e639265cc",
            "e644108490e94fdcbf7fc0337dc3fbb0",
            "aa798098eb654117bccebae9ffd5f7de",
            "efb4c31c67544574a536a8abb6ca0e74",
            "2a48dc8f08fa4e48965b8a2385dd9c15",
            "b880c3273b3e423d991d2dbf4e425249",
            "dea2ce6e57c2463db457cd0f4051bf73"
          ]
        },
        "id": "wDIovXdfoyH9",
        "outputId": "027edb19-877d-4edd-8e71-86fdf0881aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[SERVING] Iniciando carga masiva a AstraDB...\n",
            "[CASSANDRA] Creando esquema en keyspace 'Cloud_analytics_db'...\n",
            "[CASSANDRA] Esquema verificado: 3 Tablas listas.\n",
            "   -> cargando tabla 'org_daily_usage_by_service' (727 registros)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bb17d049523426fbf147d6b8de2cbad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Subiendo org_daily_usage_by_service:   0%|          | 0/727 [00:00<?, ?rows/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1989596537.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mupload_full_gold_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-781547998.py\u001b[0m in \u001b[0;36mupload_full_gold_layer\u001b[0;34m(spark)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mdf_finops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_finops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"event_date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"usage_date\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     load_df_to_cassandra(\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mdf_finops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"org_daily_usage_by_service\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-781547998.py\u001b[0m in \u001b[0;36mload_df_to_cassandra\u001b[0;34m(df, table_name, columns_map)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/cassandra/cluster.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, parameters, timeout, trace, custom_payload, execution_profile, paging_state, host, execute_as)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \"\"\"\n\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_payload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_profile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaging_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     def execute_async(self, query, parameters=None, trace=False, custom_payload=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/cassandra/cluster.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5043\u001b[0m         \"\"\"\n\u001b[0;32m-> 5044\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_NOT_SET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5046\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mResultSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "upload_full_gold_layer(spark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1KxlShlW4NQ"
      },
      "source": [
        "# DEMO - Queries de Cassandra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L555sppu2hJY",
        "outputId": "a7c38604-5986-45f5-88b0-0f2b5a99cf1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Queries de negocios \n",
            "\n",
            "Organizacion: org_axeqbnhl\n",
            "Fecha de Referencia: 2025-08-31\n",
            "------------------------------------------------------------\n",
            "\n",
            "1. [FinOps] Costos y requests diarios (Últimos 7 días)\n",
            "Fecha        | Servicio        | Costo ($)  | Requests\n",
            "2025-08-31   | analytics       | 1.59       | 0\n",
            "2025-08-31   | compute         | 10.29      | 117\n",
            "2025-08-31   | networking      | 1.17       | 132\n",
            "2025-08-31   | storage         | 2.53       | 119\n",
            "\n",
            "2. [FinOps] Top 3 Servicios más costosos (Desde 2025-08-17)\n",
            "Servicio        | Costo Acum. ($)\n",
            "compute         | 10.29\n",
            "storage         | 2.53\n",
            "analytics       | 1.59\n",
            "\n",
            "3. [Soporte] Tickets críticos y Tasa SLA Breach (Desde 2025-08-01)\n",
            "Fecha        | Críticos | Tasa Breach %\n",
            "2025-08-13   | 0        | 0.0%\n",
            "\n",
            "4. [Finanzas] Revenue Mensual Estimado (Mes actual: 2025-08-01)\n",
            "Subtotal Uso:    $25.24\n",
            "Impuestos (est): $5.30\n",
            "TOTAL REVENUE:   $30.54\n",
            "\n",
            "5. [Producto] Consumo GenAI (Tokens/Requests y Costo)\n",
            "(Esta organización no registra consumo de GenAI)\n",
            "\n",
            "6. [ESG] Huella de Carbono\n",
            "   Fecha        | Servicio        | Carbono (kgCO2)\n",
            "   --------------------------------------------------\n",
            "   2025-08-31   | analytics       | 0.0042         \n",
            "   2025-08-31   | compute         | 0.0234         \n",
            "   2025-08-31   | networking      | 0.0288         \n",
            "   2025-08-31   | storage         | 0.0238         \n",
            "   2025-08-14   | analytics       | 0.0000         \n"
          ]
        }
      ],
      "source": [
        "# cassandra_queries.py\n",
        "\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "import random\n",
        "\n",
        "def run_final_business_queries():\n",
        "    print(\"\\nQueries de negocios \\n\")\n",
        "    session = get_cassandra_session()\n",
        "\n",
        "    # aca agarro una org al azar para la demo\n",
        "    rows = session.execute(f'SELECT org_id FROM \"{KEYSPACE}\".org_daily_usage_by_service LIMIT 1000')\n",
        "    all_orgs = list(set([r.org_id for r in rows]))\n",
        "\n",
        "    if not all_orgs:\n",
        "        print(\"No hay datos en la tabla para consultar.\")\n",
        "        return\n",
        "\n",
        "    TARGET_ORG = (random.sample(all_orgs, 1))[0]\n",
        "\n",
        "    # fechas dinamicas para filtrar\n",
        "    # se usa una fecha fija de referencia (agosto 2025) por la data simulada\n",
        "    ref_date = datetime.date(2025, 8, 31)\n",
        "\n",
        "    date_14_days_ago = ref_date - timedelta(days=14)\n",
        "    date_30_days_ago = ref_date - timedelta(days=30)\n",
        "    start_of_month = ref_date.replace(day=1)\n",
        "\n",
        "    print(f\"Organizacion: {TARGET_ORG}\")\n",
        "    print(f\"Fecha de Referencia: {ref_date}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # (1) FinOps: Costos y requests diarios (rango de fechas)\n",
        "    print(\"\\n1. [FinOps] Costos y requests diarios (Últimos 7 días)\")\n",
        "    query_1 = f\"\"\"\n",
        "        SELECT usage_date, service_name, daily_cost_usd, daily_requests\n",
        "        FROM \"{KEYSPACE}\".org_daily_usage_by_service\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        AND usage_date >= '{ref_date - timedelta(days=7)}'\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_1)\n",
        "    print(f\"{'Fecha':<12} | {'Servicio':<15} | {'Costo ($)':<10} | {'Requests'}\")\n",
        "    for r in rows:\n",
        "        print(f\"{str(r.usage_date):<12} | {r.service_name:<15} | {r.daily_cost_usd:<10.2f} | {int(r.daily_requests)}\")\n",
        "\n",
        "\n",
        "    # (2) FinOps: Top 3 servicios mas costosos (ultimos 14 dias)\n",
        "    print(f\"\\n2. [FinOps] Top 3 Servicios más costosos (Desde {date_14_days_ago})\")\n",
        "    query_2 = f\"\"\"\n",
        "        SELECT service_name, daily_cost_usd\n",
        "        FROM \"{KEYSPACE}\".org_daily_usage_by_service\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        AND usage_date >= '{date_14_days_ago}'\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_2)\n",
        "\n",
        "    # agregacion client-side\n",
        "    cost_map = {}\n",
        "    for r in rows:\n",
        "        cost_map[r.service_name] = cost_map.get(r.service_name, 0.0) + r.daily_cost_usd\n",
        "\n",
        "    sorted_services = sorted(cost_map.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "\n",
        "    print(f\"{'Servicio':<15} | {'Costo Acum. ($)'}\")\n",
        "    for svc, cost in sorted_services:\n",
        "        print(f\"{svc:<15} | {cost:.2f}\")\n",
        "\n",
        "\n",
        "    # (3) Soporte: Tickets criticos y SLA breach rate (30 dias)\n",
        "    print(f\"\\n3. [Soporte] Tickets críticos y Tasa SLA Breach (Desde {date_30_days_ago})\")\n",
        "    query_3 = f\"\"\"\n",
        "        SELECT ticket_date, critical_tickets, sla_breach_rate\n",
        "        FROM \"{KEYSPACE}\".org_daily_support_metrics\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        AND ticket_date >= '{date_30_days_ago}'\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_3)\n",
        "\n",
        "    # manejo por si no hay tickets\n",
        "    if not rows:\n",
        "        print(\"(Sin tickets en este periodo para esta org)\")\n",
        "\n",
        "    print(f\"{'Fecha':<12} | {'Críticos':<8} | {'Tasa Breach %'}\")\n",
        "    for r in rows:\n",
        "        rate_pct = r.sla_breach_rate * 100 if r.sla_breach_rate else 0.0\n",
        "        print(f\"{str(r.ticket_date):<12} | {r.critical_tickets:<8} | {rate_pct:.1f}%\")\n",
        "\n",
        "\n",
        "    # (4) Finanzas: Revenue mensual estimado (con tax)\n",
        "    # nota: tomo desde usage\n",
        "    print(f\"\\n4. [Finanzas] Revenue Mensual Estimado (Mes actual: {start_of_month})\")\n",
        "\n",
        "    query_4 = f\"\"\"\n",
        "        SELECT daily_cost_usd\n",
        "        FROM \"{KEYSPACE}\".org_daily_usage_by_service\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        AND usage_date >= '{start_of_month}'\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_4)\n",
        "\n",
        "    monthly_subtotal = sum([r.daily_cost_usd for r in rows])\n",
        "    taxes = monthly_subtotal * 0.21 # 21% tax -tome el IVA como ejemplo, eso lo decide finanzas\n",
        "    credits = 0.0\n",
        "    total_revenue = monthly_subtotal + taxes - credits\n",
        "\n",
        "    print(f\"Subtotal Uso:    ${monthly_subtotal:.2f}\")\n",
        "    print(f\"Impuestos (est): ${taxes:.2f}\")\n",
        "    print(f\"TOTAL REVENUE:   ${total_revenue:.2f}\")\n",
        "\n",
        "\n",
        "    # (5) Producto: Consumo GenAI (tokens y costo)\n",
        "    print(\"\\n5. [Producto] Consumo GenAI (Tokens/Requests y Costo)\")\n",
        "    query_5 = f\"\"\"\n",
        "        SELECT event_date, service_name, genai_requests_count, genai_daily_cost\n",
        "        FROM \"{KEYSPACE}\".org_daily_genai_usage\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        LIMIT 5\n",
        "    \"\"\"\n",
        "    rows = list(session.execute(query_5))\n",
        "\n",
        "    if not rows:\n",
        "        print(\"(Esta organización no registra consumo de GenAI)\")\n",
        "    else:\n",
        "        print(f\"{'Fecha':<12} | {'Servicio':<12} | {'Tokens/Reqs':<12} | {'Costo ($)'}\")\n",
        "        for r in rows:\n",
        "            print(f\"{str(r.event_date):<12} | {r.service_name:<12} | {int(r.genai_requests_count):<12} | {r.genai_daily_cost:.2f}\")\n",
        "\n",
        "  # (6) Sustentabilidad\n",
        "    print(\"\\n6. [ESG] Huella de Carbono\")\n",
        "    query_4 = f\"\"\"\n",
        "        SELECT usage_date, service_name, daily_carbon_kg\n",
        "        FROM \"{KEYSPACE}\".org_daily_usage_by_service\n",
        "        WHERE org_id = '{TARGET_ORG}'\n",
        "        LIMIT 5\n",
        "    \"\"\"\n",
        "    rows = session.execute(query_4)\n",
        "    print(f\"   {'Fecha':<12} | {'Servicio':<15} | {'Carbono (kgCO2)'}\")\n",
        "    print(\"   \" + \"-\"*50)\n",
        "    for r in rows:\n",
        "        print(f\"   {str(r.usage_date):<12} | {r.service_name:<15} | {f'{r.daily_carbon_kg:.4f}' if r.daily_carbon_kg is not None else 'None':<15}\")\n",
        "\n",
        "    session.shutdown()\n",
        "\n",
        "run_final_business_queries()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjX0ejjhFOTS"
      },
      "source": [
        "# Chequeo de Idempotencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576,
          "referenced_widgets": [
            "80fc0a8112744e24affd2d01a1fa32bd",
            "5c1a0326d75e42909b0e39e8d7700b0a",
            "65d2263986da4d439c6124069e816c35",
            "8d55e6e82eea49caa926d4dae660c001",
            "2d7080849d1242f1a4c001206062858a",
            "b066b9437f7b49cab9b712a46a11a240",
            "0dc58940497543d2a9713abc2eb42b85",
            "5a3014dbf4fc47e680132ffe0aaeed6c",
            "fcdba86feac24183aa4b63ab605b928f",
            "36d71d92553143afa6e6ee444288d438",
            "15dc67a603b7437c9074fbce37aac52e",
            "5c1dc479409d47d6afd0e6e91af94e89",
            "c7e93219d6cd4893860c2141909c410c",
            "fd2b5273bb90460b939679e614fc4f0e",
            "3ad9d5c5d3844ac4b48d627e598e4221",
            "0bf333b303eb4c9b85ef681c47598f2f",
            "c4d99de261f0472bbf8421732b88e144",
            "8894c05810904f30bf06a159f8ee261f",
            "c00b38d68e3c435283894a009804e68b",
            "82d0b37cdbfc4564b281a2e484e4df15",
            "589b0811a7c14d1d8bdbe22310820a1a",
            "54311a2351b04a9fb1e7f41e08eec21d",
            "c81b1cc5275e4980a2b3d341dbd70b7f",
            "d44cde759745412abc73ee78c1edf06c",
            "5e632746cf0546b2b802633df96fe913",
            "c8a16b9a97db48f6946b364f670c7e87",
            "62de1cabc5ab434b9e4b21d98cb254d5",
            "89b6029debc8496a8ad1c8f0ac5045fe",
            "e4f53c58dd794395906ca63c696982ff",
            "5b51a095d5d448748a898e0d11ed30a6",
            "d7471c35e4b14ea795bf6b443c94d2f3",
            "0a19aceffa17434e8e5666468ee7e080",
            "9929d568190349758a50d482d91a4885"
          ]
        },
        "id": "Stz62wvHsS0r",
        "outputId": "8951e695-144c-4c44-a43b-a52d71befbd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Prueba de idempotencia \n",
            "\n",
            "[1] Contando registros actuales...\n",
            "    - org_daily_usage_by_service: 876\n",
            "    - org_daily_support_metrics: 944\n",
            "    - org_daily_genai_usage: 92\n",
            "\n",
            "[2] >>> Re-ejecutando Carga (Gold -> Cassandra)...\n",
            "\n",
            "[SERVING] Iniciando carga masiva a AstraDB...\n",
            "[CASSANDRA] Creando esquema en keyspace 'Cloud_analytics_db'...\n",
            "[CASSANDRA] Esquema verificado: 3 Tablas listas.\n",
            "   -> cargando tabla 'org_daily_usage_by_service' (727 registros)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80fc0a8112744e24affd2d01a1fa32bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Subiendo org_daily_usage_by_service:   0%|          | 0/727 [00:00<?, ?rows/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      [OK] Carga completada.\n",
            "   -> cargando tabla 'org_daily_support_metrics' (944 registros)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c1dc479409d47d6afd0e6e91af94e89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Subiendo org_daily_support_metrics:   0%|          | 0/944 [00:00<?, ?rows/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      [OK] Carga completada.\n",
            "   -> cargando tabla 'org_daily_genai_usage' (77 registros)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c81b1cc5275e4980a2b3d341dbd70b7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Subiendo org_daily_genai_usage:   0%|          | 0/77 [00:00<?, ?rows/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      [OK] Carga completada.\n",
            "\n",
            "[3] Verificando consistencia...\n",
            "    - org_daily_usage_by_service: 876 -> 876 [OK]\n",
            "    - org_daily_support_metrics: 944 -> 944 [OK]\n",
            "    - org_daily_genai_usage: 92 -> 92 [OK]\n",
            "--------------------------------------------------\n",
            "Resultado: 0 Duplicados generados.\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "logging.getLogger('cassandra.protocol').setLevel(logging.ERROR)\n",
        "\n",
        "# Validacion de idempotencia\n",
        "print(\"\\nPrueba de idempotencia \\n\")\n",
        "\n",
        "tables_to_check = [\n",
        "    \"org_daily_usage_by_service\",\n",
        "    \"org_daily_support_metrics\",\n",
        "    \"org_daily_genai_usage\"\n",
        "]\n",
        "\n",
        "session = get_cassandra_session()\n",
        "counts_before = {}\n",
        "\n",
        "# 1. medicion inicial\n",
        "print(\"[1] Contando registros actuales...\")\n",
        "for table in tables_to_check:\n",
        "    # Nota: El warning de agregación es esperado en esta demo\n",
        "    count = session.execute(f'SELECT count(*) FROM \"{KEYSPACE}\".{table}').one()[0]\n",
        "    counts_before[table] = count\n",
        "    print(f\"    - {table}: {count}\")\n",
        "\n",
        "session.shutdown()\n",
        "\n",
        "# 2. re ejecucion (Simulacro Re-intento)\n",
        "print(\"\\n[2] >>> Re-ejecutando Carga (Gold -> Cassandra)...\")\n",
        "upload_full_gold_layer(spark)\n",
        "\n",
        "# 3. medicion Final y comparación\n",
        "print(\"\\n[3] Verificando consistencia...\")\n",
        "session = get_cassandra_session()\n",
        "all_pass = True\n",
        "\n",
        "for table in tables_to_check:\n",
        "    count_after = session.execute(f'SELECT count(*) FROM \"{KEYSPACE}\".{table}').one()[0]\n",
        "    count_initial = counts_before[table]\n",
        "\n",
        "    status = \"OK\" if count_after == count_initial else \"FAIL\"\n",
        "    print(f\"    - {table}: {count_initial} -> {count_after} [{status}]\")\n",
        "\n",
        "    if count_after != count_initial:\n",
        "        all_pass = False\n",
        "\n",
        "session.shutdown()\n",
        "\n",
        "print(\"-\" * 50)\n",
        "if all_pass:\n",
        "    print(\"Resultado: 0 Duplicados generados.\")\n",
        "else:\n",
        "    print(\"Resultado:Se detectaron cambios en los conteos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bhlIlEt8ANK"
      },
      "source": [
        "# Chequeo de tablas en Cassandra -para informe final-\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRT2yeXX3S2e",
        "outputId": "c1bac0cd-4728-4021-9dc6-a15cb3438bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "chequeo de carga en Cassandra (Keyspace: Cloud_analytics_db)\n",
            "\n",
            "Tabla: `org_daily_usage_by_service`\n",
            "- Total de registros : 876\n",
            "\n",
            "Muestra de datos:\n",
            "\n",
            "| org_id       | usage_date   | service_name   |   carbon_per_dollar |   cost_per_request |   daily_carbon_kg |   daily_cost_usd |   daily_requests |\n",
            "|:-------------|:-------------|:---------------|--------------------:|-------------------:|------------------:|-----------------:|-----------------:|\n",
            "| org_c11ertj5 | 2025-08-31   | compute        |          0.00329223 |          0.0607492 |          0.024    |           7.2899 |              120 |\n",
            "| org_c11ertj5 | 2025-08-31   | database       |          0.00411957 |          0.0485487 |          0.0238   |           5.7773 |              119 |\n",
            "| org_c11ertj5 | 2025-08-31   | genai          |          0.00157653 |          0.127047  |          0.049072 |          31.1266 |              245 |\n",
            "| org_c11ertj5 | 2025-08-18   | compute        |          0.00292469 |        nan         |          0.000167 |           0.0571 |                0 |\n",
            "| org_c11ertj5 | 2025-08-13   | database       |          0.00418779 |        nan         |          0.000446 |           0.1065 |                0 |\n",
            "\n",
            "---\n",
            "\n",
            "Tabla: `org_daily_support_metrics`\n",
            "- Total de registros : 944\n",
            "\n",
            "Muestra de datos:\n",
            "\n",
            "| org_id       | ticket_date   |   avg_csat |   critical_tickets |   sla_breach_rate |   sla_breached_count |   total_tickets |\n",
            "|:-------------|:--------------|-----------:|-------------------:|------------------:|---------------------:|----------------:|\n",
            "| org_c11ertj5 | 2025-08-30    |          3 |                  0 |                 0 |                    0 |               1 |\n",
            "| org_c11ertj5 | 2025-08-16    |          3 |                  0 |                 0 |                    0 |               1 |\n",
            "| org_c11ertj5 | 2025-08-07    |          5 |                  0 |                 1 |                    1 |               1 |\n",
            "| org_c11ertj5 | 2025-08-03    |          2 |                  0 |                 0 |                    0 |               1 |\n",
            "| org_c11ertj5 | 2025-07-23    |        nan |                  0 |                 0 |                    0 |               1 |\n",
            "\n",
            "---\n",
            "\n",
            "Tabla: `org_daily_genai_usage`\n",
            "- Total de registros : 92\n",
            "\n",
            "Muestra de datos:\n",
            "\n",
            "| org_id       | event_date   | service_name   |   genai_daily_cost |   genai_requests_count |\n",
            "|:-------------|:-------------|:---------------|-------------------:|-----------------------:|\n",
            "| org_c11ertj5 | 2025-08-31   | genai          |            31.1266 |                    245 |\n",
            "| org_c11ertj5 | 2025-08-07   | genai          |             0.2865 |                      0 |\n",
            "| org_c11ertj5 | 2025-07-21   | genai          |            12.6785 |                    110 |\n",
            "| org_w3zp08j3 | 2025-08-31   | genai          |             0.3548 |                      0 |\n",
            "| org_kdgigatj | 2025-07-15   | genai          |             0      |                      0 |\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "logging.getLogger('cassandra.protocol').setLevel(logging.ERROR)\n",
        "\n",
        "try:\n",
        "    from cassandra_utils import get_cassandra_session, KEYSPACE\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "def generate_cassandra_evidence_md():\n",
        "    print(f\"\\nchequeo de carga en Cassandra (Keyspace: {KEYSPACE})\\n\")\n",
        "    session = get_cassandra_session()\n",
        "\n",
        "    tables_to_audit = [\n",
        "        \"org_daily_usage_by_service\",\n",
        "        \"org_daily_support_metrics\",\n",
        "        \"org_daily_genai_usage\"\n",
        "    ]\n",
        "\n",
        "    for table in tables_to_audit:\n",
        "        print(f\"Tabla: `{table}`\")\n",
        "\n",
        "        # 1. Obtener Conteo\n",
        "        try:\n",
        "            count_row = session.execute(f'SELECT count(*) FROM \"{KEYSPACE}\".{table}').one()\n",
        "            count = count_row[0]\n",
        "            print(f\"- Total de registros : {count}\")\n",
        "        except Exception as e:\n",
        "            print(f\"- Error obteniendo conteo: {e}\")\n",
        "\n",
        "        # 2. Obtener Muestra y convertir a Markdown\n",
        "        try:\n",
        "            rows = session.execute(f'SELECT * FROM \"{KEYSPACE}\".{table} LIMIT 5')\n",
        "            data = [r._asdict() for r in rows]\n",
        "\n",
        "            if data:\n",
        "                df = pd.DataFrame(data)\n",
        "                print(\"\\nMuestra de datos:\\n\")\n",
        "                # Aquí está la magia: to_markdown genera el formato para tu reporte\n",
        "                print(df.to_markdown(index=False))\n",
        "            else:\n",
        "                print(\"\\nLa tabla está vacía.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError leyendo filas: {e}\")\n",
        "\n",
        "        print(\"\\n---\\n\")\n",
        "\n",
        "    session.shutdown()\n",
        "\n",
        "# Ejecutar\n",
        "generate_cassandra_evidence_md()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqf22BEowNeE"
      },
      "source": [
        "# DEMO - Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "dg5cIF3nStUx",
        "outputId": "981c14e4-da04-426c-dbbc-f872ecfecfb2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1864189761.py:109: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b3a3d662036cfafd4b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b3a3d662036cfafd4b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[UI] Creando Dashboard de: org_pnsm43d8...\n",
            "[UI] Creando Dashboard de: org_uzfk8ut0...\n",
            "[UI] Creando Dashboard de: org_uzfk8ut0...\n",
            "[UI] Creando Dashboard de: org_c11ertj5...\n",
            "[UI] Creando Dashboard de: org_pvs7hzio...\n",
            "[UI] Creando Dashboard de: org_teiyzcot...\n",
            "[UI] Creando Dashboard de: org_c11ertj5...\n",
            "[UI] Creando Dashboard de: org_g8sbi4q2...\n",
            "[UI] Creando Dashboard de: org_uzfk8ut0...\n",
            "[UI] Creando Dashboard de: org_teiyzcot...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b3a3d662036cfafd4b.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "\n",
        "# --- FUNCION DE DATOS ---\n",
        "def get_premium_dashboard_data(org_id, date_start, date_end):\n",
        "    print(f\"[UI] Creando Dashboard de: {org_id}...\")\n",
        "\n",
        "    # validacion de fechas\n",
        "    if not date_start or not date_end:\n",
        "        date_start = \"2020-01-01\"\n",
        "        date_end = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "    session = get_cassandra_session()\n",
        "\n",
        "    # FINOPS\n",
        "    q_finops = f\"SELECT usage_date, service_name, daily_cost_usd FROM \\\"{KEYSPACE}\\\".org_daily_usage_by_service WHERE org_id = '{org_id}'\"\n",
        "    rows_finops = list(session.execute(q_finops))\n",
        "\n",
        "    # procesamiento en pandas\n",
        "    if rows_finops:\n",
        "        df_finops = pd.DataFrame([r._asdict() for r in rows_finops])\n",
        "        df_finops['usage_date'] = pd.to_datetime(df_finops['usage_date'].astype(str))\n",
        "        df_finops['daily_cost_usd'] = df_finops['daily_cost_usd'].astype(float)\n",
        "\n",
        "        #filtro de fecha\n",
        "        mask = (df_finops['usage_date'] >= pd.to_datetime(date_start)) & (df_finops['usage_date'] <= pd.to_datetime(date_end))\n",
        "        df_finops = df_finops.loc[mask]\n",
        "\n",
        "        # graf1: Area Chart acumulada (Plotly)\n",
        "        fig_finops_trend = px.area(df_finops, x=\"usage_date\", y=\"daily_cost_usd\", color=\"service_name\",\n",
        "                                   title=\"Evolución de costos por servicio\",\n",
        "                                   labels={\"daily_cost_usd\": \"Costo (USD)\", \"usage_date\": \"Fecha\"})\n",
        "\n",
        "        # graf2: Donut Chart\n",
        "        df_grouped = df_finops.groupby(\"service_name\")[\"daily_cost_usd\"].sum().reset_index()\n",
        "        fig_finops_dist = px.pie(df_grouped, values=\"daily_cost_usd\", names=\"service_name\", hole=0.4,\n",
        "                                 title=\"distribucion del Gasto Total\")\n",
        "    else:\n",
        "        fig_finops_trend = px.line(title=\"sin datos de costos\")\n",
        "        fig_finops_dist = px.pie(title=\"sin datos\")\n",
        "\n",
        "    # SUPPORT\n",
        "    q_supp = f\"SELECT ticket_date, total_tickets, sla_breached_count, critical_tickets FROM \\\"{KEYSPACE}\\\".org_daily_support_metrics WHERE org_id = '{org_id}'\"\n",
        "    rows_supp = list(session.execute(q_supp))\n",
        "\n",
        "    if rows_supp:\n",
        "        df_supp = pd.DataFrame([r._asdict() for r in rows_supp])\n",
        "        df_supp['ticket_date'] = pd.to_datetime(df_supp['ticket_date'].astype(str))\n",
        "\n",
        "        # Filtro fecha\n",
        "        mask = (df_supp['ticket_date'] >= pd.to_datetime(date_start)) & (df_supp['ticket_date'] <= pd.to_datetime(date_end))\n",
        "        df_supp = df_supp.loc[mask].sort_values(\"ticket_date\")\n",
        "\n",
        "        # Graf Combinado\n",
        "        fig_supp = go.Figure()\n",
        "        # graf total tickets\n",
        "        fig_supp.add_trace(go.Bar(x=df_supp['ticket_date'], y=df_supp['total_tickets'], name='Total Tickets', marker_color='lightblue'))\n",
        "        # graf SLA Breaches\n",
        "        fig_supp.add_trace(go.Scatter(x=df_supp['ticket_date'], y=df_supp['sla_breached_count'], name='SLA Breaches', line=dict(color='red', width=3)))\n",
        "\n",
        "        fig_supp.update_layout(title=\"Volumen de soporte vs calidad\", xaxis_title=\"Fecha\", yaxis_title=\"Cantidad\")\n",
        "    else:\n",
        "        fig_supp = px.bar(title=\"Sin datos de soporte\")\n",
        "\n",
        "    # GENAI\n",
        "\n",
        "    q_genai = f\"SELECT event_date, service_name, genai_daily_cost, genai_requests_count FROM \\\"{KEYSPACE}\\\".org_daily_genai_usage WHERE org_id = '{org_id}'\"\n",
        "    rows_genai = list(session.execute(q_genai))\n",
        "\n",
        "    if rows_genai:\n",
        "        df_genai = pd.DataFrame([r._asdict() for r in rows_genai])\n",
        "        df_genai['event_date'] = pd.to_datetime(df_genai['event_date'].astype(str))\n",
        "\n",
        "        # Filtro fecha\n",
        "        mask = (df_genai['event_date'] >= pd.to_datetime(date_start)) & (df_genai['event_date'] <= pd.to_datetime(date_end))\n",
        "        df_genai = df_genai.loc[mask]\n",
        "\n",
        "        # Scatter Plot: Relación Costo vs Requests\n",
        "        # Tamaño de burbuja = Costo\n",
        "        fig_genai = px.scatter(df_genai, x=\"event_date\", y=\"genai_requests_count\", size=\"genai_daily_cost\", color=\"service_name\",\n",
        "                               title=\"IA: requests vs costo\",\n",
        "                               labels={\"genai_requests_count\": \"Cant. Requests\", \"event_date\": \"Fecha\"})\n",
        "    else:\n",
        "        fig_genai = px.scatter(title=\"sin datos de GenAI\")\n",
        "\n",
        "    session.shutdown()\n",
        "\n",
        "    summary = f\"### analizando {org_id}\\ndesde {date_start} hasta {date_end}.\"\n",
        "\n",
        "    return summary, fig_finops_trend, fig_finops_dist, fig_supp, fig_genai\n",
        "\n",
        "\n",
        "# ui\n",
        "\n",
        "# Carga inicial de lista de orgs (si no existe)\n",
        "try:\n",
        "    if not unique_orgs: raise ValueError\n",
        "except:\n",
        "    print(\"[UI] cargando clientes...\")\n",
        "    session = get_cassandra_session()\n",
        "    rows = session.execute(f'SELECT org_id FROM \\\"{KEYSPACE}\\\".org_daily_usage_by_service LIMIT 300')\n",
        "    unique_orgs = sorted(list(set([r.org_id for r in rows])))\n",
        "    session.shutdown()\n",
        "\n",
        "# layout\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"#Cloud Analytics Dashboard\")\n",
        "    gr.Markdown(\"Visión integral: Finanzas, Operaciones e Innovación.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # panel de control del dashboard\n",
        "        with gr.Column(scale=1, variant=\"panel\"):\n",
        "            gr.Markdown(\"###Filtros\")\n",
        "            dd_org = gr.Dropdown(choices=unique_orgs, label=\"cliente\", value=unique_orgs[0] if unique_orgs else None)\n",
        "            # selectores de fecha\n",
        "            date_start = gr.Textbox(label=\"Fecha Inicio (YYYY-MM-DD)\", value=\"2025-06-01\")\n",
        "            date_end = gr.Textbox(label=\"Fecha Fin (YYYY-MM-DD)\", value=\"2025-12-31\")\n",
        "\n",
        "            btn_run = gr.Button(\"actualizar\", variant=\"primary\")\n",
        "            lbl_status = gr.Markdown(\"Listo para consultar.\")\n",
        "\n",
        "        # Panel de grafsl\n",
        "        with gr.Column(scale=4):\n",
        "            with gr.Tabs():\n",
        "                with gr.TabItem(\"FinOps\"):\n",
        "                    with gr.Row():\n",
        "                        plot_finops_trend = gr.Plot(label=\"tendencia\")\n",
        "                        plot_finops_dist = gr.Plot(label=\"fistribucion\")\n",
        "\n",
        "                with gr.TabItem(\"Soporte & SLAs\"):\n",
        "                    plot_supp = gr.Plot(label=\"metricas de soporte\")\n",
        "                    gr.Markdown(\"*Nota: La línea roja indica incumplimientos de contrato (SLA Breaches).*\")\n",
        "\n",
        "                with gr.TabItem(\"GenAI \"):\n",
        "                    plot_genai = gr.Plot(label=\"consumo IA\")\n",
        "\n",
        "\n",
        "    btn_run.click(\n",
        "        fn=get_premium_dashboard_data,\n",
        "        inputs=[dd_org, date_start, date_end],\n",
        "        outputs=[lbl_status, plot_finops_trend, plot_finops_dist, plot_supp, plot_genai]\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a19aceffa17434e8e5666468ee7e080": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf333b303eb4c9b85ef681c47598f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc424fca3524b01ba96bf68f295e53e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc58940497543d2a9713abc2eb42b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15dc67a603b7437c9074fbce37aac52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a48dc8f08fa4e48965b8a2385dd9c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d7080849d1242f1a4c001206062858a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3052d4e9309346b7baf4f87221f76078": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_819bf30a317d41899b480e2e87dbc572",
              "IPY_MODEL_a4b21664e8374b8e85671bf45d9061a1",
              "IPY_MODEL_69cb5613a4764a2bb409937f06481957"
            ],
            "layout": "IPY_MODEL_5c29043f72904c29a2512d3d245d2d95"
          }
        },
        "36d71d92553143afa6e6ee444288d438": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ad9d5c5d3844ac4b48d627e598e4221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589b0811a7c14d1d8bdbe22310820a1a",
            "placeholder": "​",
            "style": "IPY_MODEL_54311a2351b04a9fb1e7f41e08eec21d",
            "value": " 944/944 [00:55&lt;00:00, 17.11rows/s]"
          }
        },
        "4bb17d049523426fbf147d6b8de2cbad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e119458ef4cd48319eb3dded67dca87a",
              "IPY_MODEL_793fbf063c79490fbef6e30fa0d63615",
              "IPY_MODEL_def8e1c35473473eb68c3030832d5537"
            ],
            "layout": "IPY_MODEL_5eec945787e64ea4a688a47e639265cc"
          }
        },
        "4f936ed048a3471697813851b96615f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54311a2351b04a9fb1e7f41e08eec21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "589b0811a7c14d1d8bdbe22310820a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3014dbf4fc47e680132ffe0aaeed6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b51a095d5d448748a898e0d11ed30a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1a0326d75e42909b0e39e8d7700b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b066b9437f7b49cab9b712a46a11a240",
            "placeholder": "​",
            "style": "IPY_MODEL_0dc58940497543d2a9713abc2eb42b85",
            "value": "Subiendo org_daily_usage_by_service: 100%"
          }
        },
        "5c1dc479409d47d6afd0e6e91af94e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7e93219d6cd4893860c2141909c410c",
              "IPY_MODEL_fd2b5273bb90460b939679e614fc4f0e",
              "IPY_MODEL_3ad9d5c5d3844ac4b48d627e598e4221"
            ],
            "layout": "IPY_MODEL_0bf333b303eb4c9b85ef681c47598f2f"
          }
        },
        "5c29043f72904c29a2512d3d245d2d95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e632746cf0546b2b802633df96fe913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b51a095d5d448748a898e0d11ed30a6",
            "max": 77,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7471c35e4b14ea795bf6b443c94d2f3",
            "value": 77
          }
        },
        "5eec945787e64ea4a688a47e639265cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62de1cabc5ab434b9e4b21d98cb254d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d2263986da4d439c6124069e816c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3014dbf4fc47e680132ffe0aaeed6c",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcdba86feac24183aa4b63ab605b928f",
            "value": 727
          }
        },
        "69cb5613a4764a2bb409937f06481957": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6edf298594694aa6987d6414e01ed56e",
            "placeholder": "​",
            "style": "IPY_MODEL_4f936ed048a3471697813851b96615f4",
            "value": " 7/7 [00:17&lt;00:00,  1.57s/tablas]"
          }
        },
        "6edf298594694aa6987d6414e01ed56e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "712d789a5ab840cd8ed6401a705f6c67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "793fbf063c79490fbef6e30fa0d63615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb4c31c67544574a536a8abb6ca0e74",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a48dc8f08fa4e48965b8a2385dd9c15",
            "value": 163
          }
        },
        "80fc0a8112744e24affd2d01a1fa32bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c1a0326d75e42909b0e39e8d7700b0a",
              "IPY_MODEL_65d2263986da4d439c6124069e816c35",
              "IPY_MODEL_8d55e6e82eea49caa926d4dae660c001"
            ],
            "layout": "IPY_MODEL_2d7080849d1242f1a4c001206062858a"
          }
        },
        "819bf30a317d41899b480e2e87dbc572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc424fca3524b01ba96bf68f295e53e",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6905d429fb42e8802671fe04291cd6",
            "value": "Procesando Archivos: 100%"
          }
        },
        "82d0b37cdbfc4564b281a2e484e4df15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8894c05810904f30bf06a159f8ee261f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89b6029debc8496a8ad1c8f0ac5045fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d55e6e82eea49caa926d4dae660c001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36d71d92553143afa6e6ee444288d438",
            "placeholder": "​",
            "style": "IPY_MODEL_15dc67a603b7437c9074fbce37aac52e",
            "value": " 727/727 [00:42&lt;00:00, 16.85rows/s]"
          }
        },
        "9929d568190349758a50d482d91a4885": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0feaf5c47fb41dba2695f38114bbfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4b21664e8374b8e85671bf45d9061a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_712d789a5ab840cd8ed6401a705f6c67",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0feaf5c47fb41dba2695f38114bbfea",
            "value": 7
          }
        },
        "aa798098eb654117bccebae9ffd5f7de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae6905d429fb42e8802671fe04291cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b066b9437f7b49cab9b712a46a11a240": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b880c3273b3e423d991d2dbf4e425249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00b38d68e3c435283894a009804e68b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d99de261f0472bbf8421732b88e144": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e93219d6cd4893860c2141909c410c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d99de261f0472bbf8421732b88e144",
            "placeholder": "​",
            "style": "IPY_MODEL_8894c05810904f30bf06a159f8ee261f",
            "value": "Subiendo org_daily_support_metrics: 100%"
          }
        },
        "c81b1cc5275e4980a2b3d341dbd70b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d44cde759745412abc73ee78c1edf06c",
              "IPY_MODEL_5e632746cf0546b2b802633df96fe913",
              "IPY_MODEL_c8a16b9a97db48f6946b364f670c7e87"
            ],
            "layout": "IPY_MODEL_62de1cabc5ab434b9e4b21d98cb254d5"
          }
        },
        "c8a16b9a97db48f6946b364f670c7e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a19aceffa17434e8e5666468ee7e080",
            "placeholder": "​",
            "style": "IPY_MODEL_9929d568190349758a50d482d91a4885",
            "value": " 77/77 [00:04&lt;00:00, 17.02rows/s]"
          }
        },
        "d44cde759745412abc73ee78c1edf06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b6029debc8496a8ad1c8f0ac5045fe",
            "placeholder": "​",
            "style": "IPY_MODEL_e4f53c58dd794395906ca63c696982ff",
            "value": "Subiendo org_daily_genai_usage: 100%"
          }
        },
        "d7471c35e4b14ea795bf6b443c94d2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dea2ce6e57c2463db457cd0f4051bf73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "def8e1c35473473eb68c3030832d5537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b880c3273b3e423d991d2dbf4e425249",
            "placeholder": "​",
            "style": "IPY_MODEL_dea2ce6e57c2463db457cd0f4051bf73",
            "value": " 163/727 [00:10&lt;00:32, 17.13rows/s]"
          }
        },
        "e119458ef4cd48319eb3dded67dca87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e644108490e94fdcbf7fc0337dc3fbb0",
            "placeholder": "​",
            "style": "IPY_MODEL_aa798098eb654117bccebae9ffd5f7de",
            "value": "Subiendo org_daily_usage_by_service:  22%"
          }
        },
        "e4f53c58dd794395906ca63c696982ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e644108490e94fdcbf7fc0337dc3fbb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb4c31c67544574a536a8abb6ca0e74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcdba86feac24183aa4b63ab605b928f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd2b5273bb90460b939679e614fc4f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c00b38d68e3c435283894a009804e68b",
            "max": 944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82d0b37cdbfc4564b281a2e484e4df15",
            "value": 944
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
